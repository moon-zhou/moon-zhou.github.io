{"meta":{"title":"弦 博客","subtitle":"keep doing","description":"never stop","author":"moon zhou","url":"https://moon-zhou.github.io","root":"/"},"pages":[{"title":"标签","date":"2019-09-07T12:42:37.000Z","updated":"2019-09-08T07:32:00.555Z","comments":true,"path":"tags/index.html","permalink":"https://moon-zhou.github.io/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2017-12-02T13:01:24.000Z","updated":"2019-09-08T08:49:32.160Z","comments":false,"path":"categories/index.html","permalink":"https://moon-zhou.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"20200731生产问题记录-XSS","slug":"20200731生产问题记录-XSS","date":"2020-07-31T01:09:09.000Z","updated":"2020-08-02T14:11:05.332Z","comments":true,"path":"2020/07/31/20200731生产问题记录-XSS/","link":"","permalink":"https://moon-zhou.github.io/2020/07/31/20200731生产问题记录-XSS/","excerpt":"20200731生产问题记录-XSS 由上传文件格式校验漏洞引起的XSS攻击 问题产生发现及处理过程问题发现微信公众号很多页面不可访问，被微信拦截，提示链接有风险，链接如下： 1https://paypassport.suning.com/ids/login?service=http://oss.suning.com/yunxin/yunxin_video/e98fd27a-6876-4eb1-acc7-ff7022b7276f1595575675930.jpg?zoozJMzQgBPdReEgkgEYavBxuQN4IzMweiEGcwJiOiUGNiR2YlVmMyETO4gaN4UaYyITMlhDZaIaNiVTM1IWYjRjIsIibh1WZiojIah2b3JCLiQXZtBHbhRXZJRkI6ICMiwiI0lHclJiOioWdtBnIsIyZfVXzkJiOaMaNygDMsIyZf5WYtVmI6IycoFmclJCLiQWY0FmI6Qnc1VWfQN4IzMItfkGYQhFTGcpvFLn&amp;loginTheme=wap_new&amp;gateway=true&amp;loginTheme=wap 将此域名生成二维码之后，直接用微信扫一扫，发现是跳转广告网站，充斥各种诈骗的信息。PC浏览器打开无跳转效果，可见是针对微信场景做的攻击。 问题是由微信小程序和公众号的运营发现，因为很多页面，使用的链接是接入了我们的单点登录系统的，所以但凡涉及到这一点的功能，均被微信拦截提示有风险，无法访问。 通过链接域名，发现是我们负责的单点登录系统的域名。","text":"20200731生产问题记录-XSS 由上传文件格式校验漏洞引起的XSS攻击 问题产生发现及处理过程问题发现微信公众号很多页面不可访问，被微信拦截，提示链接有风险，链接如下： 1https://paypassport.suning.com/ids/login?service=http://oss.suning.com/yunxin/yunxin_video/e98fd27a-6876-4eb1-acc7-ff7022b7276f1595575675930.jpg?zoozJMzQgBPdReEgkgEYavBxuQN4IzMweiEGcwJiOiUGNiR2YlVmMyETO4gaN4UaYyITMlhDZaIaNiVTM1IWYjRjIsIibh1WZiojIah2b3JCLiQXZtBHbhRXZJRkI6ICMiwiI0lHclJiOioWdtBnIsIyZfVXzkJiOaMaNygDMsIyZf5WYtVmI6IycoFmclJCLiQWY0FmI6Qnc1VWfQN4IzMItfkGYQhFTGcpvFLn&amp;loginTheme=wap_new&amp;gateway=true&amp;loginTheme=wap 将此域名生成二维码之后，直接用微信扫一扫，发现是跳转广告网站，充斥各种诈骗的信息。PC浏览器打开无跳转效果，可见是针对微信场景做的攻击。 问题是由微信小程序和公众号的运营发现，因为很多页面，使用的链接是接入了我们的单点登录系统的，所以但凡涉及到这一点的功能，均被微信拦截提示有风险，无法访问。 通过链接域名，发现是我们负责的单点登录系统的域名。 问题分析 分析链接本身，确认是否存在风险。发现链接里无非法字符，客观上无问题。 访问链接之后，是302到oss上的文件。即 1http://oss.suning.com/yunxin/yunxin_video/e98fd27a-6876-4eb1-acc7-ff7022b7276f1595575675930.jpg 分析该文件，发现该文件并不是一个jpg图片，而是一个js脚本。详细如下： 1&lt;!DOCTYPE html&gt;&lt;html lang=en&gt;&lt;head&gt;&lt;meta charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=&quot;IE=edge&quot;&gt;&lt;meta name=viewport content=&quot;width=device-width,initial-scale=1&quot;&gt;&lt;title&gt;&lt;/title&gt;&lt;link rel=icon href=https://cdn.w7.cc/favicon.ico type=image/x-icon&gt;&lt;meta name=keywords content=???????????????????&gt;&lt;meta name=description content=?????????????????????????????????????????????&gt;&lt;script src=//b-b-cn.oss-cn-beijing.aliyuncs.com/x&gt;&lt;/script&gt;&lt;script src=//cdn.w7.cc/ued/vue/vue.min.js&gt;&lt;/script&gt;&lt;script src=//cdn.w7.cc/ued/plugins/release/w7Plugins.umd.min.js&gt;&lt;/script&gt;&lt;script src=//cdn.w7.cc/ued/vue/element-ui.js&gt;&lt;/script&gt;&lt;script src=//cdn.w7.cc/ued/vue/vue-router.min.js&gt;&lt;/script&gt;&lt;script src=//cdn.w7.cc/ued/vue/vuex.min.js&gt;&lt;/script&gt;&lt;script src=//cdn.w7.cc/ued/vue/axios.min.js&gt;&lt;/script&gt;&lt;link href=/oauth/css/login.c31a599d.css rel=prefetch&gt;&lt;link href=/oauth/js/login.93f7725b.js rel=prefetch&gt;&lt;link href=/oauth/css/chunk-common.c103f795.css rel=preload as=style&gt;&lt;link href=/oauth/js/chunk-common.9f8f4bb7.js rel=preload as=script&gt;&lt;link href=/oauth/js/chunk-vendors.5330a510.js rel=preload as=script&gt;&lt;link href=/oauth/js/web.3669336d.js rel=preload as=script&gt;&lt;link href=/oauth/css/chunk-common.c103f795.css rel=stylesheet&gt;&lt;/head&gt;&lt;body/hidden&gt;&lt;noscript&gt;&lt;strong&gt;We&apos;re sorry but ued_oauth2 doesn&apos;t work properly without JavaScript enabled. Please enable it to continue.&lt;/strong&gt;&lt;/noscript&gt;&lt;div id=app&gt;&lt;/div&gt;&lt;script&gt;window.js_ticket=&quot;RLVhFivvF769Euil5P9F3y96l6FIYE56ffE5uk0A9VZZyYKipl9fL5u7LLaF0a0P6996iarEr9fLYhf6LuYVUyLZL6657H6P6ZAH&quot;;&lt;/script&gt;&lt;script src=/oauth/js/chunk-vendors.5330a510.js&gt;&lt;/script&gt;&lt;script src=/oauth/js/chunk-common.9f8f4bb7.js&gt;&lt;/script&gt;&lt;script src=/oauth/js/web.3669336d.js&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 至此，问题原因基本明了。 修改脚本文件后缀（js-&gt;jpg），通过某些业务场景，利用文件校验漏洞，上传至公司的分布式文件存储系统。而在该场景，文件上传之后，把对外访问链接（http）返回到前端进行了展示（至此攻击者获取到了刚刚上传脚本的外网访问路径，且是使用的公司域名）。 扫描我司公网可访问的域名，筛选会执行http链接请求的域名及对应请求（类似targetUrl，backUrl会被浏览器等执行进行跳转），然后将这个攻击脚本文件链接拼接到该请求后面进行攻击。 最终，我们的单点登录系统，登录完302到目标地址被利用。 问题修复 联系分布式文件存储系统的系统负责人，排查该bucket属于哪个业务系统在使用 联系该脚本被上传的业务系统负责人，明确该文件存在风险，进行文件删除 联系运营人员，在微信平台进行申请恢复访问 针对单点登录系统，对于目标地址的跳转虽然做了白名单跳转，但是都是公司的一些一级域名。所以单纯的分布式文件存储系统虽然在业务上没有接入我们的单点登录，所以依然是可以通过我们系统进行跳转的。所以临时修改代码，针对CAS做的单点登录系统的service和targetUrl做限制登录。临时修改，联系测试，当晚发版。 service做域名黑名单配置，有些明显没有接入单点登录系统的域名，是不能跳转的。 targetUrl做配置域名白名单，配置的域名里，必须将该域名能够访问的url配置起来。 针对的是微信的UA做上述校验。 其他 业务系统后续还需要确认该文件上传的业务场景，严格文件的校验，不仅仅只根据文件后缀进行文校验，还需要根据文件头进行文件格式校验：详细参考 12345678910111213141516171819202122232425262728293031JPEG (jpg)，文件头：FFD8FFPNG (png)，文件头：89504E47GIF (gif)，文件头：47494638TIFF (tif)，文件头：49492A00Windows Bitmap (bmp)，文件头：424DCAD (dwg)，文件头：41433130Adobe Photoshop (psd)，文件头：38425053Rich Text Format (rtf)，文件头：7B5C727466XML (xml)，文件头：3C3F786D6CHTML (html)，文件头：68746D6C3EEmail [thorough only] (eml)，文件头：44656C69766572792D646174653AOutlook Express (dbx)，文件头：CFAD12FEC5FD746FOutlook (pst)，文件头：2142444EMS Word/Excel (xls.or.doc)，文件头：D0CF11E0MS Access (mdb)，文件头：5374616E64617264204AWordPerfect (wpd)，文件头：FF575043Postscript (eps.or.ps)，文件头：252150532D41646F6265Adobe Acrobat (pdf)，文件头：255044462D312EQuicken (qdf)，文件头：AC9EBD8FWindows Password (pwl)，文件头：E3828596ZIP Archive (zip)，文件头：504B0304RAR Archive (rar)，文件头：52617221Wave (wav)，文件头：57415645AVI (avi)，文件头：41564920Real Audio (ram)，文件头：2E7261FDReal Media (rm)，文件头：2E524D46MPEG (mpg)，文件头：000001BAMPEG (mpg)，文件头：000001B3Quicktime (mov)，文件头：6D6F6F76Windows Media (asf)，文件头：3026B2758E66CF11MIDI (mid)，文件头：4D546864 由文件头校验，联想到.class的16进制文件头魔数cafebebe。","categories":[{"name":"问题记录","slug":"问题记录","permalink":"https://moon-zhou.github.io/categories/问题记录/"}],"tags":[]},{"title":"生产问题：从setex异常看指令重排序问题","slug":"生产问题：从setex异常看指令重排序问题","date":"2020-07-05T01:09:09.000Z","updated":"2020-07-05T12:15:54.577Z","comments":true,"path":"2020/07/05/生产问题：从setex异常看指令重排序问题/","link":"","permalink":"https://moon-zhou.github.io/2020/07/05/生产问题：从setex异常看指令重排序问题/","excerpt":"生产问题：从setex异常看指令重排序问题背景现在公司整体架构是基础/公共组件，以及各个业务线。业务线根据不同的领域，自建对应系统（前台-中台-后台），通过一些公共（技术）组件如rpc服务，redis服务等；一些公共（业务）组件，如短信系统，推送系统，单点登录系统等，进行关联。另外一部分是研发过程的工具组件，如持续集成，日志管理。而本次涉及的就是异常治理部分。 异常治理属于日志管理系统的下的所属业务，各个业务系统的日志，统一接入，使用ELK架构，告别终端直连机器查看日志（尤其是集群里机器贼多的情况尤为有利）。而异常治理就是将日志里的异常信息，统一进行收集，各业务系统需要按月进行异常的分析，处理。当然异常也是分等级的，分分钟跟kpi挂钩。","text":"生产问题：从setex异常看指令重排序问题背景现在公司整体架构是基础/公共组件，以及各个业务线。业务线根据不同的领域，自建对应系统（前台-中台-后台），通过一些公共（技术）组件如rpc服务，redis服务等；一些公共（业务）组件，如短信系统，推送系统，单点登录系统等，进行关联。另外一部分是研发过程的工具组件，如持续集成，日志管理。而本次涉及的就是异常治理部分。 异常治理属于日志管理系统的下的所属业务，各个业务系统的日志，统一接入，使用ELK架构，告别终端直连机器查看日志（尤其是集群里机器贼多的情况尤为有利）。而异常治理就是将日志里的异常信息，统一进行收集，各业务系统需要按月进行异常的分析，处理。当然异常也是分等级的，分分钟跟kpi挂钩。 问题发现在异常治理时，发现了redis操作的setex出现异常，异常信息如下： 1234567891011121314com.suning.framework.sedis.exception.RedisClientException: redis.clients.jedis.exceptions.JedisDataException: ERR invalid expire time in setex at com.suning.framework.sedis.impl.ShardedJedisClientImpl.execute(ShardedJedisClientImpl.java:43) ~[snf-redis-client-2.5.3.jar:2.5.3] at com.suning.epps.fmsms.infrastructure.cache.GenericShardedRedisOperatorImpl.setex(GenericShardedRedisOperatorImpl.java:62) ~[fmsms-server-infrastructure-1.0.0.jar:na] at com.suning.epps.fmsms.infrastructure.cache.GenericRedisPrefixOperator.setEx(GenericRedisPrefixOperator.java:577) ~[fmsms-server-infrastructure-1.0.0.jar:na] at com.suning.epps.fmsms.infrastructure.cache.GenericRedisPrefixOperator$$FastClassBySpringCGLIB$$f49e6640.invoke(&lt;generated&gt;) ~[spring-core-4.1.7.RELEASE.jar:na] at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) [spring-core-4.1.7.RELEASE.jar:4.1.7.RELEASE] at com.suning.epps.fmsms.infrastructure.cache.GenericRedisPrefixOperator$$EnhancerBySpringCGLIB$$92769d90.setEx(&lt;generated&gt;) [spring-core-4.1.7.RELEASE.jar:na] at com.suning.epps.fmsms.application.subsequent.sign.SignPushRedisSubsequentImpl.subSequent(SignPushRedisSubsequentImpl.java:24) [fmsms-server-application-1.0.0.jar:na] at com.suning.epps.fmsms.application.subsequent.sign.SignPushRedisSubsequentImpl$$FastClassBySpringCGLIB$$f4c52a72.invoke(&lt;generated&gt;) [spring-core-4.1.7.RELEASE.jar:na] at com.suning.epps.fmsms.application.subsequent.sign.SignPushRedisSubsequentImpl$$EnhancerBySpringCGLIB$$8b851a5a.subSequent(&lt;generated&gt;) [spring-core-4.1.7.RELEASE.jar:na] at com.suning.epps.fmsms.facade.factory.SubsequentFactory.subsequent(SubsequentFactory.java:21) [fmsms-server-facade-1.0.0.jar:na] at com.suning.epps.fmsms.facade.shared.ManagerFacadeHandle.execute(ManagerFacadeHandle.java:49) [fmsms-server-facade-1.0.0.jar:na] at com.suning.epps.fmsms.facade.impl.manager.sign.SignFacadeImpl.execute(SignFacadeImpl.java:36) [fmsms-server-facade-1.0.0.jar:na] at com.suning.epps.fmsms.facade.impl.manager.sign.SignFacadeImpl$$FastClassBySpringCGLIB$$c73c241c.invoke(&lt;generated&gt;) [spring-core-4.1.7.RELEASE.jar:na] 查询此报错原因为，setex设置redis值时，带有的过期时间参数值&lt;=0，因此着重分析为什么会出现过期时间&lt;=0的情况。 问题分析一开始，直接看报错的代码部分，如何计算出过期时间为负值的： 1234567891011121314151617181920212223/** * 获取当天剩余的时间并加十分钟缓冲之间，单位：秒 * * @return */ public static int getTodayRemainSecondNumAndPlus600Second() &#123; //当前时间毫秒数 long current = System.currentTimeMillis(); Calendar calendar = Calendar.getInstance(); calendar.add(Calendar.DAY_OF_MONTH, 1); calendar.set(Calendar.HOUR_OF_DAY, 0); calendar.set(Calendar.MINUTE, 0); calendar.set(Calendar.SECOND, 0); calendar.set(Calendar.MILLISECOND, 0); long tomorrowZero = calendar.getTimeInMillis(); // long current = System.currentTimeMillis(); 重排序到这里 long remainSecond = (tomorrowZero - current) / 1000; Random random = new Random(); int cacheTime =random.nextInt(180); return (int) remainSecond + cacheTime; &#125; 结合上述代码，认为只能是重排序才能出现计算为负值的情况，于是分析其字节码，验证是否是as-if-serial引起的重排序问题。 分析字节码：javap -c DateUtils 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public static int getTodayRemainSecondNumAndPlus600Second(); Code: 0: invokestatic #32 // Method java/lang/System.currentTimeMillis:()J 3: lstore_0 4: invokestatic #8 // Method java/util/Calendar.getInstance:()Ljava/util/Calendar; 7: astore_2 8: aload_2 9: iconst_5 10: iconst_1 11: invokevirtual #11 // Method java/util/Calendar.add:(II)V 14: aload_2 15: bipush 11 17: iconst_0 18: invokevirtual #15 // Method java/util/Calendar.set:(II)V 21: aload_2 22: bipush 12 24: iconst_0 25: invokevirtual #15 // Method java/util/Calendar.set:(II)V 28: aload_2 29: bipush 13 31: iconst_0 32: invokevirtual #15 // Method java/util/Calendar.set:(II)V 35: aload_2 36: bipush 14 38: iconst_0 39: invokevirtual #15 // Method java/util/Calendar.set:(II)V 42: aload_2 43: invokevirtual #33 // Method java/util/Calendar.getTimeInMillis:()J 46: lstore_3 47: lload_3 48: lload_0 49: lsub 50: ldc2_w #17 // long 1000l 53: ldiv 54: lstore 5 56: new #34 // class java/util/Random 59: dup 60: invokespecial #35 // Method java/util/Random.\"&lt;init&gt;\":()V 63: astore 7 65: aload 7 67: sipush 180 70: invokevirtual #36 // Method java/util/Random.nextInt:(I)I 73: istore 8 75: lload 5 77: l2i 78: iload 8 80: iadd 81: ireturn static &#123;&#125;; Code: 0: ldc #3 // class com/suning/epps/fmsms/util/DateUtils 2: invokestatic #37 // Method org/slf4j/LoggerFactory.getLogger:(Ljava/lang/Class;)Lorg/slf4j/Logger; 5: putstatic #28 // Field LOGGER:Lorg/slf4j/Logger; 8: return 从字节码看出，并没有进行重排序，于是从日志系统里拉取备份日志，发现过期时间是0引发的该异常，而非小于0引起： 12020-06-21 23:59:59,507|RequestTaskExecutor-thread-22561|0c95dfd68997481ca20568e64f48680d|INFO|GenericRedisPrefixOperator|enter key arg:0000000000220488786,huiyuan,value arg:1,2020-06-21,expire arg:0 因此结合现有情况，分析是否为精度问题导致。 12345678910111213141516171819202122/** * 获取当天剩余的时间并加十分钟缓冲之间，单位：秒 * * @return */ public static int getTodayRemainSecondNumAndPlus600Second() &#123; //当前时间毫秒数 long current = System.currentTimeMillis(); Calendar calendar = Calendar.getInstance(); calendar.add(Calendar.DAY_OF_MONTH, 1); calendar.set(Calendar.HOUR_OF_DAY, 0); calendar.set(Calendar.MINUTE, 0); calendar.set(Calendar.SECOND, 0); calendar.set(Calendar.MILLISECOND, 0); long tomorrowZero = calendar.getTimeInMillis(); // 此处如果是2020-07-05 23:59:59:333，那么距离2020-07-06 0:0:0:000，除以1000，取整数为0 long remainSecond = (tomorrowZero - current) / 1000; Random random = new Random(); int cacheTime =random.nextInt(180); return (int) remainSecond + cacheTime; &#125; 编写测试代码进行验证： 123456789101112131415161718192021222324252627282930313233343536private static void simplifyProblem() throws ParseException &#123; // 模拟临界值时间（签到时间） SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss:SSS\"); Date date = sdf.parse(\"2020-07-05 23:59:59:333\"); long time = date.getTime(); // 模拟到下一天的24点 Calendar calendar = Calendar.getInstance(); long calendarInMills = calendar.getTimeInMillis(); calendar.add(Calendar.DAY_OF_MONTH, 1); calendar.set(Calendar.HOUR_OF_DAY, 0); calendar.set(Calendar.MINUTE, 0); calendar.set(Calendar.SECOND, 0); calendar.set(Calendar.MILLISECOND, 0); calendar.set(Calendar.MILLISECOND, 0); long end = calendar.getTimeInMillis(); // 模拟计算缓存时间，通过放大循环次数，看随机到0的情况 for (int i = 0; i &lt; 2000; i++) &#123; // 原意为当前时间到明天零点还有多少秒，此处存在的问题为，如果小于1秒，此处精度丢失，变为0 long remainSecond = (end - time) / 1000; Random random = new Random(); // 如果随机的3分钟，也就是180秒，如果变成0，那么整体的缓存时间就为0， int cacheTime = random.nextInt(180); int result = (int) remainSecond + cacheTime; if (result &lt; 0) &#123; System.out.println(\"less than 0\"); &#125; else if (result == 0) &#123; System.out.println(\"equal 0\"); &#125;/* else &#123; System.out.println(\"more than 0\"); &#125;*/ &#125; &#125; 结果也显而易见，因为放大了该时间段的请求量，equal 0的情况次数挺多。其实时间0点后签到的人数目比较多，23点59分的比较少，因此此类异常不多。 解决方案核心问题就是避免操作jedis的setEx方法里，过期时间设置为&lt;=0的情况，此处只需要考虑不为0的情况。也就是remainSecond + cacheTime有一个不为0的情况。 修改计算算法，不要到0点，适时往后延几分钟。也就是remainSecond计算出来不可能为0。 为避免出现随机出0的情况，适当加个常量值。","categories":[{"name":"问题记录","slug":"问题记录","permalink":"https://moon-zhou.github.io/categories/问题记录/"}],"tags":[]},{"title":"【反思录】2020年6月底迭代回顾","slug":"2020年6月底迭代回顾","date":"2020-07-04T01:09:09.000Z","updated":"2020-07-05T13:29:41.888Z","comments":true,"path":"2020/07/04/2020年6月底迭代回顾/","link":"","permalink":"https://moon-zhou.github.io/2020/07/04/2020年6月底迭代回顾/","excerpt":"","text":"2020年6月底迭代回顾6月，大促月，早早的就开始安排值班计划，同时我们组的也有小伙伴的离去，多少对版本迭代还是有些许的影响。 按照惯例，依然是上旬和下旬各一个版本。上旬版本循规蹈矩，没有什么问题。下旬在研发过程里，因为研发任务上，本身没有什么难度的内容，没有过多投入，从侧面上也是希望小伙伴能够更多的投入到开发任务里面，更多的承担一点。从23号晚上发布来看，本次版本的开发内容，验证都没有问题。但是发布第二天下午，发现华为钱包里核身流程无法打开，且问题必现。打开页面发现脚本报错，为减小问题影响，里面通过发布平台回滚前一晚的发布。同时组织前端进行问题分析，说是缺少某某方法，加上之后，当前方法的确不报错了。同时拉了紧急版本进行问题修复。很快前端修改完成，组织测试回归时，发现当前场景已经修复，但是因为测试环境是与华为pay有交互，而华为pay的app无法及时更新，无法联系上华为侧开发（24号晚，后面端午3天小长假），无法验证该流程的全部场景。为减小上线风险，组织前端进行代码修改评估，脚本此次变动的需求，只加了一个获取设备id的逻辑，同时修复最前面报错，往后的逻辑没有修改，因此确认可以不回归后面的场景。本以为晚上可以顺利发布，而往往事与愿违。当晚发布，前面的流程验证时跟测试环境一致，都正常。但是最后提交时，始终报错。也就是测试场景无法回归的场景，当时心里就是一万头CNM奔驰而过。。。因为发布已经是晚上0点，业务量很低，因此暂时未操作止损步骤（回滚）。开启常规问题操作开始，连VPN，打开代码，分析日志，提取用户操作轨迹，比较用户操作不同的地方。因为小伙伴离职，此业务代码本身未接触过，经过接近1个小时，发现前端代码里的请求在上个版本和这个版本有不一样的地方。结合两个请求的注释，发现上个版本的请求是解决某个交互问题，而此次的版本居然又请求到老的的方法上，而本次版本并未有这个需求的变更。因此结合现有情况，只有一种可能，前端上个版本之后，代码未及时提交到master分支，导致本次开发使用的分支不是最新的（前后端代码库分离，前端的版本控制，其实后端无法知道，而且最近人员变更多，很可能存在此情况）。得出最可能的结论之后，拉领导开会讨论解决方案，在无法联系到前端修改发布的情况下，只能再一次进行回滚。待节后再进行修复。 节后来了，确认了问题的确是代码分支使用的问题。再一次组织前端修复，同时联系产品协调华为侧提供最新的安装包，避免再次出现场景回归不全的问题。因为华为侧联调的问题，此问题在节后第二天才在测试环境复现以及修复确认。当晚就将修复后的代码发布到生产。 版本过程之曲折，基本上可以和接收该系统时有的一比。主要体现在版本控制混乱，当然此次是前端部门，而前端部门则因为是人员流失多，交接过程不完全导致。而这个对于门户系统来说，前端更多时候，对于我们是个黑盒，无法完整的把握住。而且，该门户系统的开发即将都要离职，对于该问题，只能从客观上，让领导协调开发。而且后面的迭代版本，注定了不会十分流畅的上线。新接手必然有一个试错过程，无法避免。因此后续迭代，只能更多的关注修改点和回归场景的覆盖。 6月，该来的都来了，现阶段还没有看到停止的趋势。版本问题也是逐步显现，且有逐步扩大之势。愿补血及时到来。 PS：有意者可联系我内推。","categories":[{"name":"总结反思录","slug":"总结反思录","permalink":"https://moon-zhou.github.io/categories/总结反思录/"}],"tags":[]},{"title":"生产问题：由CDN缓存引发的外网业务不可用问题","slug":"生产问题：由CDN缓存引发的外网业务不可用问题","date":"2020-06-30T01:09:09.000Z","updated":"2020-06-30T12:40:22.249Z","comments":true,"path":"2020/06/30/生产问题：由CDN缓存引发的外网业务不可用问题/","link":"","permalink":"https://moon-zhou.github.io/2020/06/30/生产问题：由CDN缓存引发的外网业务不可用问题/","excerpt":"生产问题：由CDN缓存引发的外网业务不可用问题背景623版本发布之后，因为前端代码出现问题进行回滚，修复后第二天重发，相关业务仍然不可用（5月版本前端代码未合并master，6月版本是基于4月版本进行的开发），回滚后，进行了第三次修复发布。修复发布后，产品确认相关业务都已经没有问题。","text":"生产问题：由CDN缓存引发的外网业务不可用问题背景623版本发布之后，因为前端代码出现问题进行回滚，修复后第二天重发，相关业务仍然不可用（5月版本前端代码未合并master，6月版本是基于4月版本进行的开发），回滚后，进行了第三次修复发布。修复发布后，产品确认相关业务都已经没有问题。 问题发现6.30发布后，早上9点，产品发现无卡签约业务无法正常使用，最后一步无法提交。 止损操作本系统内，该业务相关入口，通过分布式配置中心的开关，将入口的都关闭，因为是H5流程，链接无法关闭，如果用户通过pc记录了访问链接，依然是可以访问的，此部分不纳入考虑范围。 系统外使用到的地方，只会业务方，将相关入口下掉。 问题复现 因为H5是以传统web链接对外提供的服务（http），所以pc浏览器直接访问链接，发现业务流程操作正常，没有复现问题。 因为产品是从实际业务场景里回归时发现功能不可用，是从易购app里打开的该页面，因为现在业务场景入口已关，所以直接通过链接生成二维码，使用易购app扫描二维码打开相关页面流程，发现问题复现，的确不可使用。 为避免是单纯的兼容性问题，同时在苏宁金融app里也使用该方式进行验证，发现问题也能复现。 分析原因 通过pc可以操作的流程日志以及app上操作不可用流程的日志。发现以下不同点： 流程可用：日志均正常且完成：公共拦截日志，业务流程日志 流程不可用：日志缺失：仅仅只有公共拦截日志，无业务流程日志 单从日志上的差异点，无法分析出原因。因此寻找操作业务上的差异点，发现pc操作时，是走的内网，而app操作，走的的公网。因此，手机打开热点，使用pc连接，通过公网来验证功能，发现此时流程也不能走下去。此时可以缩小范围，是网络区域不同，导致的业务不可用。但依然未找到原因，无法解决问题。 没有思路时，接着操作相关业务，一步步比对： 网络请求是否存在差异 页面效果是否存在差异 通过第三步，发现最后提交页面上，展示存在差异，有一个自动勾选框，配置的是不勾选，但是出问题的时候，他是勾选了的。而勾选是需要发出请求来获取配置的，因为拉出抓包的网络请求，印证了出问题的流程里没有发送该网络请求。比对两次请求的js脚本，发现对于该请求的发起，代码的确不一样。 到此，答案几乎呼之欲出了：因为公网CDN缓存了静态资源服务器上的js脚本，没有回源导致的。 解决 联系运维，将相关系统目录下的静态资源重新推CDN缓存。 产品验证业务场景进行确认，确认ok（删除手机本地缓存）。 通过分布式配置中心的开关，重新打开先关场景的入口（开关是分布式配置中心里设置的，具有一定的代码侵入性）。","categories":[{"name":"问题记录","slug":"问题记录","permalink":"https://moon-zhou.github.io/categories/问题记录/"}],"tags":[]},{"title":"由JSONP引发的安全问题","slug":"由JSONP引发的安全问题","date":"2020-06-20T01:09:09.000Z","updated":"2020-06-20T13:12:36.422Z","comments":true,"path":"2020/06/20/由JSONP引发的安全问题/","link":"","permalink":"https://moon-zhou.github.io/2020/06/20/由JSONP引发的安全问题/","excerpt":"由JSONP引发的安全问题前言 跨域基本概念，什么是同源策略 由于html标签规范本身，以下标签加载资源时不受跨域限制，也就是下列标签是可以加载非同源的资源（get方式）。 1234567&lt;script src=&quot;...&quot;&gt;`//加载图片到本地执行&lt;img src=&quot;...&quot;&gt; //图片&lt;link href=&quot;...&quot;&gt;//css&lt;iframe src=&quot;...&quot;&gt;//任意资源 由于不同系统使用不同域名，或者协议（不同端口造成不同源的情况很少，暂未遇到过），但是又经常需要通过http请求获取数据，因而都会遇到跨域问题。而获取数据，对获取的数据进行处理这个过程，结合跨越标签，与script的能力完美契合。因而使用script标签进行跨域的实现。 存在的问题：jsonp劫持 分析网站请求/源码，找到jsonp请求。 模拟jsonp，自定义回调，执行返回数据，如果请求返回里面包含敏感数据，就会出现数据泄露，即使不包含敏感数据，回调执行脚本时，依然存在xss问题。","text":"由JSONP引发的安全问题前言 跨域基本概念，什么是同源策略 由于html标签规范本身，以下标签加载资源时不受跨域限制，也就是下列标签是可以加载非同源的资源（get方式）。 1234567&lt;script src=&quot;...&quot;&gt;`//加载图片到本地执行&lt;img src=&quot;...&quot;&gt; //图片&lt;link href=&quot;...&quot;&gt;//css&lt;iframe src=&quot;...&quot;&gt;//任意资源 由于不同系统使用不同域名，或者协议（不同端口造成不同源的情况很少，暂未遇到过），但是又经常需要通过http请求获取数据，因而都会遇到跨域问题。而获取数据，对获取的数据进行处理这个过程，结合跨越标签，与script的能力完美契合。因而使用script标签进行跨域的实现。 存在的问题：jsonp劫持 分析网站请求/源码，找到jsonp请求。 模拟jsonp，自定义回调，执行返回数据，如果请求返回里面包含敏感数据，就会出现数据泄露，即使不包含敏感数据，回调执行脚本时，依然存在xss问题。 基本概念 什么是jsonp？为什么要用jsonp? JSONP(JSON with Padding)是JSON的一种“使用模式”，可用于解决主流浏览器的跨域数据访问的问题。利用 &lt;script&gt; 元素的这个开放策略，网页可以得到从其他来源动态产生的 JSON 资料，而这种使用模式就是所谓的 JSONP。用 JSONP 抓到的资料并不是 JSON，而是任意的JavaScript，用 JavaScript 直译器执行而不是用 JSON 解析器解析。 原理 利用没有跨域限制的 script 标签加载预设的 callback 将内容传递给 js。一般来说我们约定通过一个参数来告诉服务器 JSONP 返回时应该调用的回调函数名，然后拼接出对应的 js。 示例123456789101112131415161718192021222324252627282930313233343536// A网站提供了可支持跨域的请求// 任意X网站发起jsonp请求获取数据：// 静态加载请求，动态更灵活// &lt;script src=&quot;https://prepay.cnsuning.com/epp-epw/authStatus?callback=jsonpCallback&quot;&gt;&lt;\\/script&gt;// 定义回调函数function jsonpCallback(json) &#123; alert(JSON.stringify(json));&#125;// 动态构造jsonp请求，返回的数据为// jsonpCallback(&#123;&quot;authStatusResponse&quot;:true,&quot;hasLogin&quot;:true,&quot;userName&quot;:&quot;100******16&quot;,&quot;principal&quot;:&quot;0000000001312******&quot;&#125;);// 改数据直接调用上面定义的js方法，输出了相关数据var htmm =document.getElementsByTagName(&quot;html&quot;)[0];var scri = document.createElement(&quot;script&quot;);scri.src=&quot;https://prepay.cnsuning.com/epp-epw/authStatus?callback=jsonpCallback&quot;;htmm.appendChild(scri);// 简单的ajax封装提交$.ajax(&#123; url: &apos;https://prepay.cnsuning.com/epp-epw/authStatus&apos;, type: &apos;post&apos;, dataType:&apos;jsonp&apos;, jsonp: &quot;callback&quot;, success:function(data)&#123; alert(JSON.stringify(data)); &#125;, error:function(data)&#123; $(&apos;#sname&apos;).html(&quot;获取验证码失败，请重试！&quot;); &#125;&#125;); 解决问题 因为天然的csrf漏洞，因此需要进行相关校验：Referer校验，一次性token校验。 jsonp接口返回数据时进行敏感数据脱敏，严格输出数据的json格式application/json;charset=UTF-8。 严格过滤 callback 函数名及 JSON 里数据的输出（脱敏）。 严格限制对 JSONP 输出 callback 函数名的长度(如防御上面 flash 输出的方法) 其他一些比较“猥琐”的方法：如在 Callback 输出之前加入其他字符(如：/**/、回车换行)这样不影响 JSON 文件加载，又能一定程度预防其他文件格式的输出。还比如 Gmail 早起使用 AJAX 的方式获取 JSON，听过在输出 JSON 之前加入 while(1) ;这样的代码来防止 JS 远程调用。 结合一次性token和函数名验证，可以将这两种方式合并，及函数名里包含上一次性token，如回调函数明文为jsonpCallback + 一次性token值。 传输参数加密（aes、rsa），更严格的采用一次一密。 局限jsonp方式只支持get方式。 跨域的其他解决方案123456789以下是CORS协议规定的HTTP头，用来进行浏览器发起跨域资源请求时进行协商：1. Origin。HTTP请求头，任何涉及CORS的请求都必需携带。2. Access-Control-Request-Method。HTTP请求头，在带预检(Preflighted)的跨域请求中用来表示真实请求的方法。3. Access-Control-Request-Headers。HTTP请求头，在带预检(Preflighted)的跨域请求中用来表示真实请求的自定义Header列表。4. Access-Control-Allow-Origin。HTTP响应头，指定服务器端允许进行跨域资源访问的来源域。可以用通配符*表示允许任何域的JavaScript访问资源，但是在响应一个携带身份信息(Credential)的HTTP请求时，Access-Control-Allow-Origin必需指定具体的域，不能用通配符。5. Access-Control-Allow-Methods。HTTP响应头，指定服务器允许进行跨域资源访问的请求方法列表，一般用在响应预检请求上。6. Access-Control-Allow-Headers。HTTP响应头，指定服务器允许进行跨域资源访问的请求头列表，一般用在响应预检请求上。7. Access-Control-Max-Age。HTTP响应头，用在响应预检请求上，表示本次预检响应的有效时间。在此时间内，浏览器都可以根据此次协商结果决定是否有必要直接发送真实请求，而无需再次发送预检请求。8. Access-Control-Allow-Credentials。HTTP响应头，凡是浏览器请求中携带了身份信息，而响应头中没有返回Access-Control-Allow-Credentials: true的，浏览器都会忽略此次响应。 参考 jsonp和jsonpcallback的使用 jsonp跨域请求详解——从繁至简 JSONP绕过CSRF防护token","categories":[{"name":"问题记录","slug":"问题记录","permalink":"https://moon-zhou.github.io/categories/问题记录/"}],"tags":[]},{"title":"给这个烦躁且不安的五月的总结","slug":"给这个烦躁且不安的五月的总结","date":"2020-05-31T01:09:09.000Z","updated":"2020-06-20T13:20:46.392Z","comments":true,"path":"2020/05/31/给这个烦躁且不安的五月的总结/","link":"","permalink":"https://moon-zhou.github.io/2020/05/31/给这个烦躁且不安的五月的总结/","excerpt":"","text":"给这个烦躁且不安的五月的总结项目迭代5月的迭代，前期还是并行了会员中心的业务，新建了会员权益前台系统。正常的迭代整体还算稳定，其他生产问题有穿插操作，搞了个生产问题。老的机器扩容，公网域名解析，接入waf存在问题，删除重做时，waf因为提示误解，直接把域名移除，导致域名无法正常访问。其中门户这块单独的有小伙伴去处理，也为我空余了一些时间。后面会继续扩大小伙伴们的日常工作范围，不局限于编码及日常的系统业务问题处理。小伙伴们需要更广大的事业及成长。 日常这个疫情，让原本的离职浪潮来的晚了一些，但是该来的终究还是会来的。从4月以来，已经走了不少人了。尤其是最近，人心浮动。论一个工作的最终目的，个人始终认为，总得有所图。工资，职位，前景，或多或少，总得占上。即使受疫情影响，经济不景气，也在最近跟随着炎热的天气，都在逐渐好转。起初的求稳，目前来看，也开始逐渐松动。我们小组也有小伙伴即将从这里毕业，踏入新的社会小学校。 从整体来看，一直在优化外包小伙伴，同时部门组织结构的变更，有些东西，已经不是那么充满阳光了，终归还是笼罩了一些阴影。 矛盾的日益凸显，加油，每一位小伙伴。 祝愿每一个小伙伴都能有一个好的成长，收获。没有毕业的小伙伴，也好好学习。","categories":[{"name":"总结反思录","slug":"总结反思录","permalink":"https://moon-zhou.github.io/categories/总结反思录/"}],"tags":[]},{"title":"【反思录】2020年4月底迭代回顾","slug":"2020年4月底迭代回顾","date":"2020-04-30T09:56:34.000Z","updated":"2020-05-01T09:09:46.229Z","comments":true,"path":"2020/04/30/2020年4月底迭代回顾/","link":"","permalink":"https://moon-zhou.github.io/2020/04/30/2020年4月底迭代回顾/","excerpt":"会员中心相关业务的系统，也逐渐让我们会员门户开发组进行承担。原因无他，会员的业务相对独立，领域比较明确，因此本身的分工也比较明确。根据开发里的层次进行切分，有负责底层服务的服务端开发组，有数据分析的开发组，以及前置门户系统。因为人员流动，营销域的相关系统分配到了会员进行负责，而营销系统往往直面用户的，因此更适合我们门户开发组进行承接。","text":"会员中心相关业务的系统，也逐渐让我们会员门户开发组进行承担。原因无他，会员的业务相对独立，领域比较明确，因此本身的分工也比较明确。根据开发里的层次进行切分，有负责底层服务的服务端开发组，有数据分析的开发组，以及前置门户系统。因为人员流动，营销域的相关系统分配到了会员进行负责，而营销系统往往直面用户的，因此更适合我们门户开发组进行承接。 涉及多条产品线，且版本不一致这个月里面，除了会员域本身的业务，也夹杂了营销域系统的版本开发，而且各自的上线版本日期不一致，导致人员安排无法进行同步。比如这个版本先发，小伙伴结束之后，后续版本在开发中，也不适合中途加入。所以人员的工作安排是个挑战。基本发布如下： 408发布了签到系统 423发布了会员门户系统 426发布了签到系统 需求变更这个版本的另一个问题是需求的变更，安全改造类的需求确定范围周期长，比如国密改造。初步梳理出的改造范围很大，后又砍掉了一部分。那么释放出的人力如何安排？已经进行的迭代排期如何进行调整？ 额外需要投入的工作第三个问题是额外的工作项，IPV6改造，穿拆在迭代版本里，虽然有立项，有ITP，但是ITP与实际工作的脱节目前是一个比较严重的问题，目前ITP评估的实际工作量，但是日常迭代版本又不进行妥协。必然只能开发进行自我消化。因此额外工作的去内容拆解极为重要。 发布后系统监控日常发布后的常规操作是，产品进行业务验证，确认功能是否与原始需求一致。开发发布完之后，需要结合各大平台，关注发布后系统的运行情况是否良好。比如RPC接口是否注册成功，网络访问是否正常，异常管理平台里系统是否新增了异常类别，是否新增了大量的异常等，redis内存的增长是否有波动，JVM内存是否正常等。 此次还有个额外需要关注的地方，就是对签到数据的补偿job优化。原先job上加了@Transactional注解，事务有默认的执行超时时间，即事务最大的执行时间，超过了就进行回滚。随着补偿表里的数据递增，执行补偿的时间肯定会超过事务的最大执行时间，导致事务回滚，这也是我们异常治理时发现的问题（消息推送job也发生过相同的问题，根本原因还是代码的拷贝，没有思考是否需要事务）。因为当数据量大到处理的时间超过事务最大执行时间后，补偿job必然每次都会失败，因而会造成补偿数据只增不减（补偿成功会删除补偿数据），数据量目前大约200万（存储补偿调用RPC接口的参数），按照补偿时，调用RPC接口的超时时间，0.3s超时需要3~4天完成，如果是1s超时，则需要10天左右。因此需要关注下这段期间的后台服务器运行情况，尤其是每天10点推送Job，如果是两个job都落到了一台服务器的情况，尤其需要关注。 补偿job的配置修改是另一个问题 2小时跑一次 并发执行 因为有@Transactional限制了执行时间，所有以上配置没有暴露出问题，如果放开事务注解，并发配置就会出现问题，因为一次执行就需要好几天，到时候会出现每隔2小时就会增加一个job调用线程，服务器的压力可想而知。因此提前将并发配置修改为不支持并发。 产品经理对产品的价值缺乏思考和规划关于产品的价值，一直是被忽略的。废了老大劲上的功能，不对外开放。或者设计之初存在的缺陷，没有引起足够的关注，导致功能被关闭的。比如给某个场景做的绑卡，比如做的签到提醒ABTest，因为其中一个方案引发客诉，导致直接关闭，依然沿用原先的全量远程推送。 日常问题关注关于异常治理的问题，按照self4j，正常打印错误日志，同时输出异常堆栈信息，公司的日志采集平台，就会自动统计异常的日志，根据类别分类。平台提供了异常日志管理平台，对异常进行分级，每月进行标记处理，标记时需要分析该异常产生的原因，是否为代码bug，是否需要后期进行发版修复。 本月异常主要涉及一下几个方面： 超时类异常 sql数据库类型异常 事务回滚型异常 数据库DML语句异常 对于超时类异常，其中有一种情况是需要引起关注的。即签到推送提醒接口超时。推送的job发起是在签到后台系统，发起侧进行推送数据的筛选，然后根据一定的速率调用签到服务端系统进行推送（服务端系统接着调用下游推送系统进行具体的操作）。其实推送本身的job对于超时以及响应的实时性与否是不关注的，但是从效果来看，服务端接口报了很多消费方调用超时，也就意味着job串行调用的时候，这个接口依然承受着一定的并发。虽然服务器运行平稳，但是为了以防万一，加长了服务接口的超时时间，也就也为这job发起请求的时候，必须等候足够长的时间来等超时，也就从源头减少了接口的压力。从结果来看，job的执行时长虽然加了两倍，但是当前场景是可以接收到，推送的消息本身不需要实时性，机器的平稳运行才是我们追求的目标。 DML异常则是发现推送消息的设置接口，数据库设置的是0/1存储，类型char(2)，结果前端给了个true/false，导致数据库更新/插入时报错。追根溯源，这个问题还跟前端反馈过，但依然没有修改。Be professional！！！当然，我们本身对于该字段也没有进行强制性0/1校验，也是导致该问题出现的一个原因。所以这也是下一个版本优化点。 总结挺忙！！！ 2-8法则，保持底线。 多学习，多进步。 Github每周至少提交三次，继续保持。","categories":[{"name":"总结反思录","slug":"总结反思录","permalink":"https://moon-zhou.github.io/categories/总结反思录/"}],"tags":[]},{"title":"签到礼品展示问题","slug":"签到礼品展示问题","date":"2020-04-18T06:14:34.000Z","updated":"2020-04-18T06:33:04.663Z","comments":true,"path":"2020/04/18/签到礼品展示问题/","link":"","permalink":"https://moon-zhou.github.io/2020/04/18/签到礼品展示问题/","excerpt":"问题发现 4.13早晨，因为4.12晚上客户端进行了发布，前端进行相关业务场景的确认时，发现签到完之后，仅仅展示了签到成功，并未明确展示奖品明细，遂和我们（服务端）反馈该问题。","text":"问题发现 4.13早晨，因为4.12晚上客户端进行了发布，前端进行相关业务场景的确认时，发现签到完之后，仅仅展示了签到成功，并未明确展示奖品明细，遂和我们（服务端）反馈该问题。 问题复现与分析 确认各渠道（会员中心，养猫，微信小程序）的签到情况，发现均是签到成功，但是没有展示奖品明细。进入具体的礼品信息页面，发现奖品已经正常发放。得出结论，该问题不影响用户实际的签到和奖品领取。问题严重级别没有特别大。（可以放心好好定位了~） 因为我们签到最近也发了一次版本，首先猜测是否是上一版本变动引起的。排查代码，未发现问题。排除上一版本的问题引入。 分析刚刚操作的签到日志，初步定位发现调用下游的接口的确返回了相关的礼品信息。于是思考为什么返回给我们系统的礼品信息为什么没有返回给用户。此时定位问题的重点聚焦在数据转换上。（此处浪费时间较多，且不是该原因） 从调用下游系统返回数据之后，重新一行行排查代码，发现拿到结果之后，不是立马进行了数据转换，而是先进行了数据格式的基本确认。 确认接口返回的是否成功 确认接口的礼品列表字段是否存在 12345678910111213141516171819202122232425262728293031323334353637383940414243private List&lt;SignPrize&gt; fmsTask(Map&lt;String, Object&gt; requestMap) &#123; Map&lt;String, Object&gt; response = null; try &#123; response = fmsIntegration.taskJoinWrapV4(requestMap); &#125; catch (Exception ex) &#123; LOGGER.error(\"sign error: \", ex); // 任务平台超时，认为成功 return null; &#125; if (ResultCodeConstants.FMS_SIGN_CSI_ERROR_CODE.equals(ResultHandle.getResponseCode(response))) &#123; // 如果是返回风控错误D826，认为失败，透传，网关封装错误文案 throw new AppException(ResultCodeConstants.FMS_TASK_RISK_ERROR, \"任务平台发放礼包遭风控拦截\"); &#125; if (!ResultHandle.isSuccess(response)) &#123; // 如果返回失败，但是非风控失败，则认为成功 return null; &#125; String tunnelField = (String) response.get(\"tunnelField\"); if (StringUtils.isEmpty(tunnelField)) &#123; throw new AppException(ResultCodeConstants.FMS_TASK_ERROR, \"任务平台发放礼包结果无tunnelField\"); &#125; Map taskInfo = JSON.parseObject(tunnelField, Map.class); if (MapUtils.isEmpty(taskInfo)) &#123; throw new AppException(ResultCodeConstants.FMS_TASK_ERROR, \"任务平台发放礼包结果tunnelField格式不对\"); &#125; List&lt;JSONObject&gt; giftList = (List&lt;JSONObject&gt;) taskInfo.get(\"giftList\"); if (CollectionUtils.isEmpty(giftList)) &#123; throw new AppException(ResultCodeConstants.FMS_TASK_ERROR, \"任务平台发放礼包结果无giftList\"); &#125; List&lt;SignPrize&gt; awardDetailList = new ArrayList&lt;&gt;(); for (JSONObject gift : giftList) &#123; SignPrize awardDetail = new SignPrize(); awardDetail.setAwardCode(String.valueOf(gift.get(\"awardCode\"))); awardDetail.setAwardName(String.valueOf(gift.get(\"awardName\"))); awardDetail.setAwardType(String.valueOf(gift.get(\"awardType\"))); awardDetail.setAwardAmount(getAwardAmount(gift)); awardDetail.setImgUrl(String.valueOf(gift.get(\"imgUrl\"))); awardDetailList.add(awardDetail); &#125; return awardDetailList; &#125; 结合报文，发现报文缺少了“返回码”字段 1&#123;tunnelField=&#123;\"giftList\":[&#123;\"awardAmount\":\"\",\"awardCode\":\"156864318070700019\",\"awardDetail\":&#123;\"responseCode\":\"0000\",\"responseMsg\":\"成功\"&#125;,\"awardName\":\"第四天签到\",\"awardType\":\"15\",\"extMessage\":\"\",\"imgUrl\":\"\"&#125;],\"responseCode\":\"0000\",\"responseMsg\":\"\"&#125;&#125; 查询历史日志（因为实时日志系统只能查询3天，更早的需要从备份里去找），发现的确是数据结构发生了变更 1&#123;tunnelField=&#123;&quot;giftList&quot;:[&#123;&quot;awardAmount&quot;:&quot;&quot;,&quot;awardCode&quot;:&quot;156864320806100018&quot;,&quot;awardDetail&quot;:&#123;&quot;responseCode&quot;:&quot;0000&quot;,&quot;responseMsg&quot;:&quot;成功&quot;&#125;,&quot;awardName&quot;:&quot;第五天签到&quot;,&quot;awardType&quot;:&quot;15&quot;,&quot;extMessage&quot;:&quot;&quot;,&quot;imgUrl&quot;:&quot;&quot;&#125;],&quot;responseCode&quot;:&quot;0000&quot;,&quot;responseMsg&quot;:&quot;&quot;&#125;, responseCode=0000, responseMsg=业务处理成功&#125; 前面发生过接口幂等的问题，应该是他们在做接口幂等改造时，做了变更，导致了该问题。找下游服务方确认，起初他们反馈接口没有问题。此时发挥准实时日志查询系统的功能就体现出来了（ELK），作为服务调用方，知道了服务提供方的系统名称，直接根据报文，查询服务提供方的返回。发现我们打印的日志和他们的输出的日志内容是一致的。至此问题确认，下游系统接口数据结构变更（而他们反馈的没有问题，应该也是因为幂等调用的时候返回的结构正确，但是第一次调用不正确） 问题确认 下游系统接口数据结构变更，导致我们无法解析出礼品详情。 副作用 次日发现所有签到统计数据均为0，数据补偿做完之后发现数据依然为0，后发现，还是因为签到系统里面，数据统计时，根据礼品字段判断是否签到成功了。本身的签到数据已经落库，在业务上，属于“签到成功”。但是在统计维度，不属于。 其他问题 如果按照以前的设计，下游系统确定成功（超时情况），我们签到服务，也认为用户是签到成功的。记录调用的异常参数，后续补偿调用下游系统。此次的问题第一次调用数据结构变了，按设计第二次补偿应该是没有问题的。但是实际情况是，查询补偿数据发现未进行补偿，且统计数据也都是失败的。 分析补偿日志 方法开始和结束日志正常打印了，但是数据没有补偿完成？？？ 有异常。应该是和事务有关。 12342020-04-14 16:05:04,946 INFO [stdout] (pool-4-thread-1) Caused by: java.sql.SQLException: Transaction cannot proceed STATUS_ROLLEDBACK2020-04-14 16:05:04,947 WARN [com.arjuna.ats.arjuna] (pool-4-thread-1) ARJUNA012077: Abort called on already aborted atomic action 0:ffff0a6445d9:5a4fcfd7:5e835468:8faa 分析补偿代码，发现@Transactional注解，于是原因显而易见。和之前推送的job是一样的。因为for循环处理的数据过多，执行时间超过了事务的超时时间，所以抛出异常。 代码优化 去掉@Transactional for循环遍历补偿表处理时，每一批次的长度修改为可动态修改（分布式配置中心进行配置，现在固定每次1000） 日志优化：正确打印错误日志，打印批量调用的日志。 每批次执行完成，线程sleep，减少下游系统的调用压力。 接入snf-log：统一日志处理 总结 接口优化时，尤其是要注意接口数据变更的修改，一定要知会调用方进行评估。同时本系统也需要进行单独的接口测试。 系统上线后，需要持续关注某些功能，随着数据的增长，可能出现意想不到的问题。比如此处的补偿表的设计问题。后续随着数据的增长，单表的设计也会是优化的地方。 业务的监控，告警还是需要完善。尤其是新接口上线，都需要在相关监控平台进行配置。","categories":[{"name":"问题记录","slug":"问题记录","permalink":"https://moon-zhou.github.io/categories/问题记录/"}],"tags":[]},{"title":"【反思录】2020年3月底迭代回顾","slug":"2020年3月底迭代回顾","date":"2020-04-04T09:56:34.000Z","updated":"2020-04-18T06:34:02.182Z","comments":true,"path":"2020/04/04/2020年3月底迭代回顾/","link":"","permalink":"https://moon-zhou.github.io/2020/04/04/2020年3月底迭代回顾/","excerpt":"迭代周期纵观整个3月，发布了两个版本，其中319是长周期版本，整体的开发任务都比较协调，即使临时任务也可以在长周期里面消化掉。 3月底的需求，周期短，中间并行的版本较多（fastjson升级，安全问题修复XSS），而且还夹杂着生产操作及相关验证。比如板桥机器迁移（Mysql），比如签到日活提高abTest，比如会员中心需求分析及评审等等。其中还包含核心功能的延期，如华为sdk加密算法优化，账户解冻添加kba流程。","text":"迭代周期纵观整个3月，发布了两个版本，其中319是长周期版本，整体的开发任务都比较协调，即使临时任务也可以在长周期里面消化掉。 3月底的需求，周期短，中间并行的版本较多（fastjson升级，安全问题修复XSS），而且还夹杂着生产操作及相关验证。比如板桥机器迁移（Mysql），比如签到日活提高abTest，比如会员中心需求分析及评审等等。其中还包含核心功能的延期，如华为sdk加密算法优化，账户解冻添加kba流程。 其中生产机器的迁移和维修，必然带来人员留守验证，意味着第二天无法投入开发，对短期迭代影响很大。因此需要借助大部门人员共同留守来消化掉这部分工作量。共同留人验证的前提条件是，小伙伴必须交代清楚需要验证的东西，留守人员必须清楚每一个验证的步骤，出现问题的解决方案等。但往往突发情况较多，还是需要小伙伴本身结合自身日常工作里的积累，临时变通来解决问题。从实际操作来看，效果并不好，要么出现问题无法解决，要么还搞出点问题。因此核心在于，小伙伴日常工作的总结，经验的积累，能力的提升。单纯的编码已经不能满足现阶段的工作完成，尤其是在团队人员客观/主观离开的情况下，每一个小伙伴都需要进化成编码之外，解决问题能力超强的多面手。日常版本里，结合小伙伴自身特点和医院，尽量让小伙伴尝试不同的角色，做更多不一样的事情，让小伙伴自身切身感受到自己的成长，才能促进正向推动力。除了能力上的引导和培养，另一个就是做事的责任心，敬畏心和细致。几次的生产问题也都体现出来了： 机器迁移未做完全：完整的机器迁移列表清晰的列出（包含ip），还出现两台机器遗漏未迁移的情况 发布单生产环境选错的情况，导致无法通过发布单发布（小伙伴提错单子，留守小伙伴又发现不了原因） 为降低成本，机器缩容，小伙伴直接缩到只剩一台(不符合高可用，至少保留两台) 除了生产操作类的工作，日常迭代版本里，出现临时的加入的安全整改部分。包括fastjson安全升级，系统xss漏洞修复等问题。对于前台系统影响偏大，都需要协调开发测试进行评估工作量进行完成。固定的需求如单点登录里提供的一些服务接口，其实讨论过程偏长，投入实际效率不高，导致后期拼命赶工。整体的代码没有任何设计，单纯的垒业务。虽然先天的代码结构要想撼动难度很大，但我们因此不对他进行任何的思考和优化。 多版本分支并行，一周发布三次，我在其中更多的是查漏补缺，再最初版本任务确认之后，分配完小伙伴开始编码后，后续的功能添加，如签到版本，kba需求变更等，都是先做完设计，小伙伴去实施编码，在编码过程中如果需求多次再次变更和讨论的，就需要小伙伴及时讨论和反馈，这一过程里，我们团队的小伙伴表现的很好。人力充分投入版本开发后，紧急的安全问题则有我统一协调，再次消化。整个过程的协调能力得到了很大的提升。PS:备忘录即时记录，是并行开发过程中至关重要的手段。 发布过程3.30，3.31，4.3，再这一周发布了三次。 发布过程验证ab方案的过程，不提前准备好账号，ab测试引擎也不提前配置网关接口，功能有问题直接找服务端。完全没有章法，没有套路，想到哪就是哪儿。 发布之后有部分功能的验证需要等到次日，果然，如签到推送功能不可用，发现是产品配置模板有问题。哎~关于签到的产品，专业性，细致性都感觉还有待提高。因为是跨平台的配置，明明是可以通过发布前的checklist来进行确认避免，一看也是没有这个流程。出了问题，协调能力差，看个问题半小时没响应。最后我还是猜测了可能的原因，才推动产品往相关方向进行推动分析。 总结 此次版本并行多，生产操作多，小伙伴的开发协调能够有秩序的进行，对我也是一种考验，至少后面遇到这种情况，也可以化繁为简，制定合理的开发计划。 小伙伴的能力急需提高，给有意愿改变和提升的小伙伴做不一样的东西(如版本管理方面，新系统搭建，分布式技术栈的学习)。 对于签到系统，后续必须规范起来，产品客观上能力的问题，站的靠后，那只能开发往前再走一走。","categories":[{"name":"总结反思录","slug":"总结反思录","permalink":"https://moon-zhou.github.io/categories/总结反思录/"}],"tags":[]},{"title":"TCP三次握手四次挥手","slug":"TCP三次握手四次挥手","date":"2020-02-22T06:00:34.000Z","updated":"2020-02-22T09:49:08.171Z","comments":true,"path":"2020/02/22/TCP三次握手四次挥手/","link":"","permalink":"https://moon-zhou.github.io/2020/02/22/TCP三次握手四次挥手/","excerpt":"如果页面样式有缺，点击传送门 背景 基础技术栈知识 网络编程需要了解 rpc需要了解 三次握手思考为什么是三次握手？ 次数上：2次太少？4次没必要？ 目的：确认客户端和服务端之间的通信能力没有问题（双方发送和接收消息）","text":"如果页面样式有缺，点击传送门 背景 基础技术栈知识 网络编程需要了解 rpc需要了解 三次握手思考为什么是三次握手？ 次数上：2次太少？4次没必要？ 目的：确认客户端和服务端之间的通信能力没有问题（双方发送和接收消息） 步骤分解 第一次握手：客户端向服务端发送数据包（syn），目的是为了确认客户端发送消息的能力（服务端接收到，说明能力ok） 第二次握手：服务端向客户端发送消息（ack+syn），告诉客户端，你发的消息我收到了，目的是验证服务端的数据发送能力（当然这一步产生了，也就验证了客户端的发送能力和服务端的接收能力是没有问题的） 第三次握手：客户端向服务端发送消息（ack），反馈你发送给我的消息我收到了（第二次握手时），因为客户端已经验证了服务端的数据接收和发送能力了，所以客户端此时认为可以建立连接，进入established。当服务端接收到此消息时，也确认了客户单的数据发送和接收能力，认为可以建立里数据传输的链接，也进入established。这一步的目的是服务端验证客户端的数据发送能力ok。 步骤解读 第一次握手，确认了==客户端的数据发送==能力ok（服务端的角度，也就是数据送达到服务端） 第二次握手，确认了==服务端的数据接收和发送==能力ok（客户端的角度，也就是反馈数据送达客户端） 第三步握手，确认了==客户端的数据接收==能力ok（服务端的角度，也就是建立连接的数据到达服务端，确认后，服务端确认可以与之建立起连接） 总结由此可见2次握手不行，确认客户端数据接收的确认。4次握手又没必要，因为第三次握手时已经确认客户端和服务端的接收和发送数据能力了。 图例 数据传输图例 步骤 客户端向服务端发送数据（data） 服务端向客户端发送已经收到数据（ack），也就是给予反馈 如果客户端没有收到服务端的反馈（ack），则认为是服务端没有收到数据，则会进行==重传==（有可能服务端收到了，发送反馈数据时丢失，也有可能真的是服务端没有收到，如果是第一种情况，那么服务端就会收到两条一样的数据，就需要对数据进行==去重==） ==「重传」== 和 ==「去重」== 工作操作系统的网络内核模块都已经帮我们处理好了，用户层是不用关心的。 当然，这里的数据发送和接收都是双向的，服务端也可以给客户端发送数据。也就是TCP链接是==双工==的。不过无论是哪方发送数据，都需要收到对方的确认才能认为对方收到了自己的数据。 同理，客户端发送数据时，服务端不可能每接收一次就进行一次反馈，可以接收多次之后，批量反馈（ack）。当然，客户端和服务端需要协调好发送和接收的速率，这就是==TCP窗口大小。== 数据的发送是顺序的，但是因为网络传输时延问题，数据到达服务端被接收时，不一定是发送数据的顺序，可能存在==乱序==的情况。操作系统的网络内核模块会负责对数据包进行排序，到用户层时顺序就已经完全一致了。 四次挥手图例 步骤 第一次挥手(FIN=1，seq=u) Client 想要关闭连接，Client 会发送一个FIN标志位置为1，当前序列号为u的包，表示需要关闭连接了。Client进入 FIN_WAIT_1 状态。 第二次挥手(ACK=1，seq=v，ack=u+1) Server收到Client的FIN包之后，会发送一个确认序号为收到的序列号u+1的包，表明自己接受到了Client关闭连接的请求，但还未准备好关闭连接。Server进入 CLOSE_WAIT 状态，Client进入 FIN_WAIT_2 状态。 第三次挥手(FIN=1，ACK=1，seq=w，ack=u+1) 当Server将剩余数据发送完之后，会发送一个自己的FIN包，序列号为u+1。Server进入 LAST_ACK 状态，等待来自Client的最后一个ACK。 第四次挥手(ACK=1，seq=u+1，ack=w+1) Client接收到来自Server端的关闭请求之后，发送最后一个ACK确认包，确认序号设置为收到序号加1。Client进入 TIME_WAIT状态，等待可能出现的要求重传的 ACK 包。Server接收到这个确认包之后，关闭连接，进入CLOSED状态。(Client会等待2MSL之后，没有收到Server的ACK ，就确认Server进入CLOSED状态，自己也关闭进入CLOSED状态。) 为什么建立连接是三次握手，而关闭连接却是四次挥手呢？这是因为服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，当收到对方的FIN报文时，==仅仅表示对方不再发送数据了但是还能接收数据，己方也未必全部数据都发送给对方了==，所以己方可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送。 核心 需要确认双方都已经不能够发送和接收数据 一方发起关闭，对另一方而言是被动关闭。 参考 https://juejin.im/post/5b29d2c4e51d4558b80b1d8c https://juejin.im/post/5a0444d45188255ea95b66bc https://juejin.im/post/5d58dbfae51d4561ba48fdd8 https://juejin.im/post/5e4ca85ef265da572e4f2227","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://moon-zhou.github.io/categories/分布式技术栈/"}],"tags":[]},{"title":"JDK升级","slug":"JDK升级","date":"2020-01-18T12:14:34.000Z","updated":"2020-01-18T12:08:02.681Z","comments":true,"path":"2020/01/18/JDK升级/","link":"","permalink":"https://moon-zhou.github.io/2020/01/18/JDK升级/","excerpt":"背景Oracle JDK即将收费，为了节约软件成本，公司将使用Open JDK代替Oracle JDK。","text":"背景Oracle JDK即将收费，为了节约软件成本，公司将使用Open JDK代替Oracle JDK。 升级步骤 原JDK里第三方依赖需要备份（升级过程会安装新的jdk包,自定义添加的第三方包会丢失） 第三方依赖升级 检查spring 版本，如果是3.x版本，目前确认最低支持3.2.9，请先将spring 版本升级至3.2.9及以上 业务代码修改 LOGGER.info(String, T)使用时，泛型值会命中两个方法LOGGER.info(String, Object…)及LOGGER.info(String, Throwable)需要修改为具体值 修改配置代码 spring升级，使用到springMVC，会产生返回406的问题，即请求的是application/json，返回的是text/html; charset=utf-8，如果请求后缀为.htm或者.html还需要额外处理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;!-- 原配置 --&gt;http://www.springframework.org/schema/mvc/spring-mvc-3.0.xsd&lt;mvc:annotation-driven conversion-service=&quot;conversionService&quot;/&gt;&lt;bean class=&quot;org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter&quot;&gt; &lt;property name=&quot;messageConverters&quot;&gt; &lt;list&gt; &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt; &lt;property name=&quot;supportedMediaTypes&quot;&gt; &lt;list&gt; &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.http.converter.json.MappingJacksonHttpMessageConverter&quot;&gt; &lt;property name=&quot;supportedMediaTypes&quot;&gt; &lt;list&gt; &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;!-- 修改配置 --&gt;http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd&lt;mvc:annotation-driven content-negotiation-manager=&quot;contentNegotiationManager&quot; /&gt;&lt;!-- 以.htm为后缀名访问，默认返回数据类型是 text/html， 所以要修改返回的数据类型 --&gt;&lt;bean id=&quot;contentNegotiationManager&quot; class=&quot;org.springframework.web.accept.ContentNegotiationManagerFactoryBean&quot;&gt; &lt;property name=&quot;mediaTypes&quot;&gt; &lt;map&gt; &lt;entry key=&quot;htm&quot; value=&quot;application/json;charset=UTF-8&quot;/&gt; &lt;/map&gt; &lt;/property&gt;&lt;/bean&gt; &lt;!--JDK升级 解决返回json数据格式问题--&gt;&lt;mvc:annotation-driven conversion-service=&quot;conversionService&quot;&gt; &lt;mvc:message-converters&gt; &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt; &lt;property name=&quot;supportedMediaTypes&quot;&gt; &lt;list&gt; &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt; &lt;value&gt;application/json;charset=UTF-8&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.http.converter.json.MappingJacksonHttpMessageConverter&quot;&gt; &lt;property name=&quot;supportedMediaTypes&quot;&gt; &lt;list&gt; &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt; &lt;value&gt;application/json;charset=UTF-8&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt; 暂未引入jackson-core，jackson-databind，jackson-annotations 重要问题分析 406分析 123org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite#getReturnValueHandlerorg.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter#invokeHandleMethod 升级问题 如果系统中使用了fastjson,请检查是否使用了SerializeConfig与ParseConfig，如果这两个类会创建大量实例（例如在每次请求中 new SerializeConfig）,升级后可能会造成Metaspace占用过大，GC缓慢等问题，请务必检查代码中是否存在此风险 如果存在后端生成验证码，导出excel，word等后端文字渲染的功能，请测试务必覆盖到，升级后字体引擎变更,可能出现字体引擎未安装，字体缺失等问题（VM默认情况下已安装引擎及字体） spring 3.2.3版本的代码，在升级jdk之后，重启容器，无法初始化spring上下文。整个系统会不可用。如果紧接着发一版升级后3.2.9版本的包，就可以正常启动。为防止出现系统不可用的情况，只能修改升级方案，拆分升级步骤。 升级spring版本至3.2.9，发一版，此时jdk仍为7 再进行jdk升级至8，此时启动正常 JVM参数调整 openJDK堆内存建议与oracleJDK 1.7保持一致，即不大于16G的机器，建议堆内存不大于1/2的系统内存，32G/64G的机器建议不大于80%，最大最小堆内存大小一致 GC策略建议CMS+perNewGC组合或者G1GC,G1正常情况下不建议指定年轻代大小或者比例 java8已移除perm区，相关配置（MaxPermSize，Perm）已无效；新增metaspace，由JDK7升级后未配置metaspace相关参数，运行过程中会随着使用量大小自增，建议配置最大不超过系统内存1/4 TODO依赖框架升级问题，很多时候需要分析框架源码，需要提升这部分能力。406的部分后续会从源码层面进行分析。参考 https://www.cnblogs.com/qinning/p/11070784.html http://www.itkeyword.com/doc/5820456446178610x877/springmvc-mvcannotation-driven-AnnotationMethodHand","categories":[{"name":"代码考古","slug":"代码考古","permalink":"https://moon-zhou.github.io/categories/代码考古/"}],"tags":[]},{"title":"【反思录】20年的第一个版本（20200116版本总结）","slug":"【反思录】20年的第一个版本（20200116版本总结）","date":"2020-01-17T02:56:34.000Z","updated":"2020-01-18T12:06:38.014Z","comments":true,"path":"2020/01/17/【反思录】20年的第一个版本（20200116版本总结）/","link":"","permalink":"https://moon-zhou.github.io/2020/01/17/【反思录】20年的第一个版本（20200116版本总结）/","excerpt":"关于版本作为20年的第一个版本，开发的过程很是曲折，转测延期，功能无法上线，都发生了。作为版本迭代管理者，的确存在管理疏漏的地方。原因总结如下： 参与的开发任务占比过大，分心较多 临时插入很多其他任务，如TSL整改，IPV6整改配合等 需求变更频繁","text":"关于版本作为20年的第一个版本，开发的过程很是曲折，转测延期，功能无法上线，都发生了。作为版本迭代管理者，的确存在管理疏漏的地方。原因总结如下： 参与的开发任务占比过大，分心较多 临时插入很多其他任务，如TSL整改，IPV6整改配合等 需求变更频繁 后续版本关于如何避免本次发生的问题，也是针对上述原因做一一修正： 基本不能作为开发的主力去参与功能的开发，后面基本上按照成慧，涛涛和铕强为核心点，分别承担pc/wap,paysso，签到/合规相关系统的核心功能开发，问题收集与分配。 开发任务参与度降低，留出部分buffer防止外部配合操作的工作项。 提高需求变更的门槛，以及这次操作继续保持（需求变更新增部分，但同时删掉部分需求） 关于开发工作开发是不需要具备“想象力”？个人观点：是需要具备“想象力”的，也可以说是“合理的猜测”。他是基于开发各自以往职业生涯经验的积累，在遇到问题时（bug异常分析，用研问题分析，源码分析）根据经验合理推导出问题分析方向及步骤，推进问题朝正确方向被处理。 这很需要各自对于技术的积累，设计的思考。 然而对于业务线的开发，是很容易被忽略的。整天泡在业务逻辑里，思考点完这个按钮往哪儿跳转。if-else，for，copy，done。很容易就满足于功能完成的现状，满满的“成就感”。 个人认为，这就是为什么业务线的开发很容易达到瓶颈，局限性很大的原因。（业务线本身是一个很大的温水池，虽说除了中间件部门的技术要求高之外，其余的大部分都是业务线） 所以，每一次的任务计划，我都会比实际工作量预留部分buffer出来，目的是希望大家优先把工作完成，再多思考现有代码的改进点，工作高质量完成之后再进行技术技能的提升。但从实际情况来看，效果并不是特别理想。虽然较以前发布成功率得到了保证，但是代码质量上，还有很大进步空间（目前还是一味的堆逻辑，done is done）。发布成功率也是因为相对的开发工作量少的原因。对比其他的小组，大家有兴趣可以看看他们每个迭代版本的工作量是多少（比我们多不少）。 关于期望“希望”大家 be better “引导”大家 be better “不强制”大家 be better","categories":[{"name":"总结反思录","slug":"总结反思录","permalink":"https://moon-zhou.github.io/categories/总结反思录/"}],"tags":[]},{"title":"SPI","slug":"SPI","date":"2020-01-11T12:14:34.000Z","updated":"2020-01-12T14:57:44.480Z","comments":true,"path":"2020/01/11/SPI/","link":"","permalink":"https://moon-zhou.github.io/2020/01/11/SPI/","excerpt":"如果无法正确查看流程图， 点击传送门 背景 框架源码阅读（JDBC,Springboot以及DUBBO使用到） 博文推荐 相关概念 全称Service Provider Interface Java提供的一套用来被第三方实现或者扩展的API","text":"如果无法正确查看流程图， 点击传送门 背景 框架源码阅读（JDBC,Springboot以及DUBBO使用到） 博文推荐 相关概念 全称Service Provider Interface Java提供的一套用来被第三方实现或者扩展的API 机制 “基于接口的编程＋策略模式＋配置文件”组合实现的动态加载机制为某个接口寻找服务实现的机制。归根结底还是“解耦”。 1234graph LR调用方--&gt;标准服务接口标准服务接口--&gt;实现类A标准服务接口--&gt;实现类B 使用步骤 定义接口 src/main/resource/META-INF/services目录下添加名为接口类路径的文件（无后缀，idea里copy接口的reference） 对第一步的接口进行实现 第二步新建的文件里添加实现类的类路径（reference）, 使用的时候，使用相关类加载实现类 详细见小Demo里代码 源码分析 java.util.ServiceLoader（），核心是内部类抽象，关于遍历和实例化的部分均在内部类里实现，类比创建者模式里的Builder 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596类属性：//配置文件的路径private static final String PREFIX = &quot;META-INF/services/&quot;;//加载的服务类或接口private final Class&lt;S&gt; service;//已加载的服务类集合（缓存）private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;();//类加载器private final ClassLoader loader;//内部类，真正加载服务类private LazyIterator lookupIterator;// 调用load方法实际是进行实例化的过程，最终掉的是私有构造方法public void reload() &#123; providers.clear(); lookupIterator = new LazyIterator(service, loader);&#125;private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) &#123; service = Objects.requireNonNull(svc, &quot;Service interface cannot be null&quot;); loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; reload();&#125;// 遍历实现类，实际都是通过重写java.util.Iterator的hasNext(),next(),remove()，最终还是调用到内部类LazyIterator进行实现的public Iterator&lt;S&gt; iterator() &#123; return new Iterator&lt;S&gt;() &#123; Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders = providers.entrySet().iterator(); public boolean hasNext() &#123; if (knownProviders.hasNext()) return true; // 调用内部类判断是否有下一个实现类 return lookupIterator.hasNext(); &#125; public S next() &#123; if (knownProviders.hasNext()) return knownProviders.next().getValue(); // 调用内部类判断获取下一个实现类 return lookupIterator.next(); &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125;;&#125;// 内部内实现部分private class LazyIterator implements Iterator&lt;S&gt;&#123; Class&lt;S&gt; service; ClassLoader loader; Enumeration&lt;URL&gt; configs = null; Iterator&lt;String&gt; pending = null; String nextName = null; // 遍历实现类判断 private boolean hasNextService() &#123; //第二次调用的时候，已经解析完成了，直接返回 if (nextName != null) &#123; return true; &#125; if (configs == null) &#123; //META-INF/services/ 加上接口的全限定类名，就是文件服务类的文件 //META-INF/services/com.viewscenes.netsupervisor.spi.SPIService String fullName = PREFIX + service.getName(); //将文件路径转成URL对象 configs = loader.getResources(fullName); &#125; while ((pending == null) || !pending.hasNext()) &#123; //解析URL文件对象，读取内容，最后返回 pending = parse(service, configs.nextElement()); &#125; //拿到第一个实现类的类名 nextName = pending.next(); return true; &#125; // 创建实例，它通过反射的方式，创建实现类的实例并返回。 private S nextService() &#123; //全限定类名 String cn = nextName; nextName = null; //创建类的Class对象 Class&lt;?&gt; c = Class.forName(cn, false, loader); //通过newInstance实例化 S p = service.cast(c.newInstance()); //放入集合，本地缓存，返回实例 providers.put(cn, p); return p; &#125;&#125; sun.misc.Service 实际应用场景 调用者根据实际使用需要，启用、扩展、或者替换框架的实现策略 JDBC:JDBC标准主要提供一套api规范，第三方应用通过实现JDBC的接口并提供一个jar包给应用程序调用。如Mysql驱动，Oracle驱动等。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119基本使用，核心关注驱动的加载过程：String url = &quot;jdbc:mysql:consult?serverTimezone=UTC&quot;;String user = &quot;root&quot;;String password = &quot;root&quot;;// jdbc4.0之后可以不需要显示注册驱动，spi机制会自动找到相关的驱动实现Class.forName(&quot;com.mysql.jdbc.Driver&quot;);Connection connection = DriverManager.getConnection(url, user, password);// java.sql.DriverManager静态块初始执行，其中使用spi机制加载jdbc具体实现/** * Load the initial JDBC drivers by checking the System property * jdbc.properties and then use the &#123;@code ServiceLoader&#125; mechanism */static &#123; // 静态代码块加载驱动 loadInitialDrivers(); println(&quot;JDBC DriverManager initialized&quot;);&#125;private static void loadInitialDrivers() &#123; String drivers; try &#123; drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() &#123; public String run() &#123; return System.getProperty(&quot;jdbc.drivers&quot;); &#125; &#125;); &#125; catch (Exception ex) &#123; drivers = null; &#125; // 如果spi 存在将使用spi方式完成提供的Driver的加载 // If the driver is packaged as a Service Provider, load it. // Get all the drivers through the classloader // exposed as a java.sql.Driver.class service. // ServiceLoader.load() replaces the sun.misc.Providers() AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; // SPI加载驱动，Driver.class为jdbc规范，各厂商实现自己的驱动 ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); /* Load these drivers, so that they can be instantiated. * It may be the case that the driver class may not be there * i.e. there may be a packaged driver with the service class * as implementation of java.sql.Driver but the actual class * may be missing. In that case a java.util.ServiceConfigurationError * will be thrown at runtime by the VM trying to locate * and load the service. * * Adding a try catch block to catch those runtime errors * if driver not available in classpath but it&apos;s * packaged as service and that service is there in classpath. */ try&#123; while(driversIterator.hasNext()) &#123; // 加载并初始化实现类 driversIterator.next(); &#125; &#125; catch(Throwable t) &#123; // Do nothing &#125; return null; &#125; &#125;); println(&quot;DriverManager.initialize: jdbc.drivers = &quot; + drivers); if (drivers == null || drivers.equals(&quot;&quot;)) &#123; return; &#125; String[] driversList = drivers.split(&quot;:&quot;); println(&quot;number of Drivers:&quot; + driversList.length); for (String aDriver : driversList) &#123; try &#123; println(&quot;DriverManager.Initialize: loading &quot; + aDriver); Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); &#125; catch (Exception ex) &#123; println(&quot;DriverManager.Initialize: load failed: &quot; + ex); &#125; &#125;&#125;com.mysql.cj.jdbc.Driver// 实例化的时候，会加载静态代码块public class Driver extends NonRegisteringDriver implements java.sql.Driver &#123; // // Register ourselves with the DriverManager // static &#123; try &#123; // 调用jdbc规范里的manage，将当前driver注册进去 java.sql.DriverManager.registerDriver(new Driver()); &#125; catch (SQLException E) &#123; throw new RuntimeException(&quot;Can&apos;t register driver!&quot;); &#125; &#125; ...&#125;java.sql.DriverManager#registerDriver(java.sql.Driver, java.sql.DriverAction)// 将外部驱动添加到注册变量public static synchronized void registerDriver(java.sql.Driver driver, DriverAction da) throws SQLException &#123; /* Register the driver if it has not already been added to our list */ if(driver != null) &#123; registeredDrivers.addIfAbsent(new DriverInfo(driver, da)); &#125; else &#123; // This is for compatibility with the original DriverManager throw new NullPointerException(); &#125; println(&quot;registerDriver: &quot; + driver);&#125; 总结优点 使用Java SPI机制的优势是实现解耦，使得第三方服务模块的装配控制的逻辑与调用者的业务代码分离，而不是耦合在一起。应用程序可以根据实际业务情况启用框架扩展或替换框架组件。 相比使用提供接口jar包，供第三方服务模块实现接口的方式，SPI的方式使得源框架，不必关心接口的实现类的路径，可以不用通过下面的方式获取接口实现类： 代码硬编码import 导入实现类 指定类全路径反射获取：例如在JDBC4.0之前，JDBC中获取数据库驱动类需要通过Class.forName(“com.mysql.jdbc.Driver”)，类似语句先动态加载数据库相关的驱动，然后再进行获取连接等的操作 第三方服务模块把接口实现类实例注册到指定地方，源框架从该处访问实例 缺点 虽然ServiceLoader也算是使用的延迟加载，但是基本只能通过遍历全部获取，也就是接口的实现类全部加载并实例化一遍。如果你并不想用某些实现类，它也被加载并实例化了，这就造成了浪费。获取某个实现类的方式不够灵活，只能通过Iterator形式获取，不能根据某个参数来获取对应的实现类。 多个并发多线程使用ServiceLoader类的实例是不安全的。 Talk is cheap, Show my hub 小Demo TODO 针对driver的扩展 DUBBO里是SPI分析 SLF4J里SPI分析 Spring里SPI分析 参考 https://www.jianshu.com/p/46b42f7f593c https://www.jianshu.com/p/3a3edbcd8f24 https://blog.csdn.net/lemon89/article/details/79189475 https://www.cnblogs.com/jy107600/p/11464985.html","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://moon-zhou.github.io/categories/JAVA/"}],"tags":[]},{"title":"跨域那些事","slug":"跨域那些事","date":"2020-01-10T12:29:34.000Z","updated":"2020-01-12T15:07:04.944Z","comments":true,"path":"2020/01/10/跨域那些事/","link":"","permalink":"https://moon-zhou.github.io/2020/01/10/跨域那些事/","excerpt":"跨域那些事 概念 浏览器同源策略，凡是发送请求url的协议、域名、端口三者之间任意一个与当前页面地址不同即为跨域。 URL 说明 是否允许通信 http://www.a.com/a.js http://www.a.com/b.js 同一域名下 允许 http://www.a.com/lab/a.js http://www.a.com/script/b.js 同一域名下不同文件夹 允许 http://www.a.com:8000/a.js http://www.a.com/b.js 同一域名，不同端口 不允许 http://www.a.com/a.js https://www.a.com/b.js 同一域名，不同协议 不允许 http://www.a.com/a.js http://210.22.106.134/b.js 域名和域名对应ip 不允许 http://www.a.com/a.js http://script.a.com/b.js 主域名相同，子域名不同 不允许 http://www.a.com/a.js http://a.com/b.js 同一域名，不同二级域名 不允许（此时cookie也不允许） http://www.a.com/a.js http://www.b.com/b.js 不同域名 不允许","text":"跨域那些事 概念 浏览器同源策略，凡是发送请求url的协议、域名、端口三者之间任意一个与当前页面地址不同即为跨域。 URL 说明 是否允许通信 http://www.a.com/a.js http://www.a.com/b.js 同一域名下 允许 http://www.a.com/lab/a.js http://www.a.com/script/b.js 同一域名下不同文件夹 允许 http://www.a.com:8000/a.js http://www.a.com/b.js 同一域名，不同端口 不允许 http://www.a.com/a.js https://www.a.com/b.js 同一域名，不同协议 不允许 http://www.a.com/a.js http://210.22.106.134/b.js 域名和域名对应ip 不允许 http://www.a.com/a.js http://script.a.com/b.js 主域名相同，子域名不同 不允许 http://www.a.com/a.js http://a.com/b.js 同一域名，不同二级域名 不允许（此时cookie也不允许） http://www.a.com/a.js http://www.b.com/b.js 不同域名 不允许 同源策略 同源策略/SOP（Same origin policy）是一种约定，由Netscape公司1995年引入浏览器，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，浏览器很容易受到XSS、CSFR等攻击。所谓同源是指”协议+域名+端口”三者相同，即便两个不同的域名指向同一个ip地址，也非同源。 同源策略限制以下几种行为： Cookie、LocalStorage 和 IndexDB 无法读取 DOM 和 Js对象无法获得 AJAX 请求不能发送 广义跨域 一个域下的文档或脚本试图去请求另一个域下的资源 资源跳转： A链接、重定向、表单提交 资源嵌入： &lt;link&gt;、&lt;script&gt;、&lt;img&gt;、&lt;frame&gt;等dom标签，还有样式中background:url()、@font-face()等文件外链 脚本请求： js发起的ajax请求、dom和js对象的跨域操作等 解决方案 JSONP 通过动态插入一个script标签。浏览器对script的资源引用没有同源限制，同时资源加载到页面后会立即执行 Proxy代理 首先将请求发送给后台服务端，服务端构造HTTP请求调用，然后将请求的结果传递给前端。 CORS(现代浏览器支持跨域资源请求的一种方式) 当你使用XMLHttpRequest发送请求时，浏览器发现该请求不符合同源策略，会给该请求加一个请求头：Origin，后台进行一系列处理，如果确定接受请求则在返回结果中加入一个响应头：Access-Control-Allow-Origin;浏览器判断该相应头中是否包含Origin的值，如果有则浏览器会处理响应，我们就可以拿到==响应数据==，如果不包含浏览器直接驳回，这时我们无法拿到响应数据。 document.domain+iframe的设置 HTML5的postMessage 使用window.name来进行跨域 参考 https://www.cnblogs.com/dojo-lzz/p/4265637.html https://segmentfault.com/a/1190000011145364","categories":[{"name":"分布式","slug":"分布式","permalink":"https://moon-zhou.github.io/categories/分布式/"}],"tags":[]},{"title":"创建者-Builder","slug":"创建者-Builder","date":"2020-01-04T06:16:00.000Z","updated":"2020-01-05T06:20:02.485Z","comments":true,"path":"2020/01/04/创建者-Builder/","link":"","permalink":"https://moon-zhou.github.io/2020/01/04/创建者-Builder/","excerpt":"背景刷设计模式","text":"背景刷设计模式 问题引入在日常开发中总是会遇到多参数的情况,那么对于多参数,尤其是可选参数众多的情况,通常情况下都是重叠构造器模式，根据需要的参数，选择合适的方法。 1234567891011public Configuration(Integer maxConnect) &#123; this(maxConnect, 0);&#125;public Configuration(Integer maxConnect, Integer minConnect) &#123; this(&quot;default&quot;, maxConnect, minConnect);&#125;public Configuration(String password, Integer maxConnect, Integer minConnect) &#123; this(...)&#125; 但是该方法也存在如下缺点： 层层嵌套，导致整个实例化过程其实是一条直线，也就注定了其过程不够灵活。 对于参数较少的构造函数不得不弄一堆的默认值填充,，导致其看起来不是很优雅。 参数扩展不友好，需要从底到上一层一层修改，且一旦参数过多，代码不仅变的难以阅读且参数顺序也格外容易出错。 思考 如何不需要知道过程就能创建复杂对象 如何继续保持代码的复用性和封装性 不太好的方式（JavaBean） 只有空的构造方法 赋值过程通过set方法进行 1234Configuration configuration = new Configuration();configuration.setPassword(&quot;default&quot;);configuration.setUrl(&quot;http://mrdear.cn&quot;);configuration.setUsername(&quot;default&quot;); 缺点 new的过程就是创建，剩下的一律不算创建，但这种模式下的创建实际上是两步，创建与填值。 对修改开放，该模式暴露了过多set方法，使得任意能获取到该实例的地方都可以随意修改器内容，对于全局性的config实例或者其他单例实例这是致命的缺点。 进一步思考加一层中间层来代理抽象，使用一个代理对象来主导创建与检验，兼顾了重叠器模式的安全性以及JavaBean模式的灵活性。相关概念 定义：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。（对象创建型模式） 方言：先构造复杂对象的每一个部件，指挥者的功能就是将这些部件以一定的步骤组装起来，形成一个具有一定功能的产品或者对象。当然这个步骤对于适用方而言是透明的。 主要作用：在用户不知道对象的建造过程和细节的情况下就可以直接创建复杂的对象。 如何使用：用户只需要给出指定复杂对象的类型和内容，建造者模式负责按顺序创建复杂对象（把内部的建造过程和细节隐藏起来） 解决的问题，也就是上面实例中引入的问题 方便用户创建复杂的对象（不需要知道实现过程） 代码复用性 &amp; 封装性（将对象构建过程和细节进行封装 &amp; 复用） 角色 抽象建造者（Builder） 创建一个产品（Product）对象各个部件的抽象接口，一般申明两类方法：buildPartX()用于创建各个组成部分；getResult()返回复杂对象 该抽象可以去掉，使用内部内直接实现具体建造者会显得更简洁 具体建造者（ConcreteBuilder） 实现Builder接口，实现里面定义的构建产品方法和返回结果 在没有Builder的情况下，直接实现该具体构建会显得更简洁（结构上为Product的内部内） 指挥者（Director） 负责安排负责对象的构造次序 指挥者与抽闲建造者之间存在关联关系 客户端只需要指挥者进行交互 产品（Product） 被构建的对象，包含多个组件部分 内部类实现具体建造 注意事项与工厂模式的区别是：建造者模式更加关注与零件装配的顺序，一般用来创建更为复杂的对象。优化 针对传统四角色建造层次过于复杂，不符合现在越来越脚本化编程的特点 优化实现 抽象各个部件 抽象产品 由各个部件组成（组合关系） 构造方法里的值，来源于内部Builder类里的值 无set方法，只有get方法（到此产品的值只能来源于Builder） 内部Builder类，构造方法定义必填字段，set方法（可重命名）返回当前Builder对象（可以链式脚本化编程），最终提供build方法调用产品构造方法，传入当前builder 优点 结构更扁平 脚本化编程更易理解 各部分功能更单一和安全，无法进行跨越式调用 Talk is cheap, Show my hub 传统四角色的方式建造一辆汽车 简化脚本化之后建一座房子 参考 https://www.jianshu.com/p/47329a94f5dc https://www.jianshu.com/p/bfd2f723c93f https://zhuanlan.zhihu.com/p/35687685 https://github.com/iluwatar/java-design-patterns/blob/master/builder/src/main/java/com/iluwatar/builder","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://moon-zhou.github.io/categories/设计模式/"}],"tags":[]},{"title":"模板模式-Template Method","slug":"模板模式-Template Method","date":"2019-12-29T13:16:00.000Z","updated":"2019-12-29T13:20:39.353Z","comments":true,"path":"2019/12/29/模板模式-Template Method/","link":"","permalink":"https://moon-zhou.github.io/2019/12/29/模板模式-Template Method/","excerpt":"背景 刷设计模式 现有系统里多处使用到，特此总结 概念 官方：模板模式（Template Method Pattern），又可叫模板方法，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。 方言：模板方法里定义具体的操作流程或步骤，其中部分或者全部延迟到子类进行实现。","text":"背景 刷设计模式 现有系统里多处使用到，特此总结 概念 官方：模板模式（Template Method Pattern），又可叫模板方法，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。 方言：模板方法里定义具体的操作流程或步骤，其中部分或者全部延迟到子类进行实现。 特点 行为型模式 基于继承的代码复用技术 包含模板方法(template method)和基本方法(primitive method)，基本方法一般用final/private修饰，保证其不会被子类修改，模板方法使用protected/abstract修饰，表面其可以/需要在子类里进行实现。 模板方法(template method) 一个模板方法是定义在抽象类中的，把基本操作方法组合在一起形成一个总算法或一个总行为的方法。 一个抽象类可以有任意多个模板方法，而不限于一个。每一个模板方法都可以调用任意多个具体方法。 基本方法(primitive method) 抽象方法(Abstract Method) 一个抽象方法由抽象类声明，由具体子类实现。在Java语言里抽象方法以abstract关键字标示。 具体方法(Concrete Method) 一个具体方法由抽象类声明并实现，而子类并不实现或置换。 钩子方法(Hook Method) 一个钩子方法由抽象类声明并实现，而子类会加以扩展。通常抽象类给出的实现是一个空实现，作为方法的默认实现。(Do nothing hook) 角色 抽象模板(Abstract Template) 定义了一个或多个抽象操作，以便让子类实现。这些抽象操作叫做基本操作，它们是一个顶级逻辑的组成步骤。(父抽象类里的抽象方法) 定义并实现了一个模板方法。这个模板方法一般是一个具体方法，它给出了一个顶级逻辑的骨架，而逻辑的组成步骤在相应的抽象操作中，推迟到子类实现。顶级逻辑也有可能调用一些具体方法。（父抽象类里的模板方法） 具体模板(Concrete Template) 实现父类所定义的一个或多个抽象方法，它们是一个顶级逻辑的组成步骤。（子类实现的抽象方法） 每一个抽象模板角色都可以有任意多个具体模板角色与之对应，而每一个具体模板角色都可以给出这些抽象方法（也就是顶级逻辑的组成步骤）的不同实现，从而使得顶级逻辑的实现各不相同。 优点 封装不变部分（提取到父类），扩展可变部分（子类实现） 行为由父类控制，具体实现交给子类 缺点 功能/场景的增多，必然会带来抽象类的管理和扩展问题（基于继承的复用共性，e.g.策略模式） 使用场景 有多个子类共有的方法，且逻辑相同。 方言：多个场景，整体的业务逻辑相同，但是针对不通的来源（场景），又有些微不同时，可以使用模板方法抽象整体的业务逻辑，具体的不同处，提取抽象方法，由各个来源子类来进行实现。 注意事项为防止恶意操作，一般模板方法都加上 final 关键词。实际使用 JDK中使用 123456789AbstractQueuedSynchronizerpublic final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;acquire()相当于模板方法，tryAcquire(arg)相当于基本方法。tryAcquire被多个子类实现 JavaEE中使用 123456789101112131415161718192021222324252627282930313233343536javax.servlet.http.HttpServletprotected void service(HttpServletRequest req, HttpServletResponse resp)throws ServletException, IOException&#123; String method = req.getMethod(); if (method.equals(METHOD_GET)) &#123; ... doGet(req, resp); ... &#125; else if (method.equals(METHOD_HEAD)) &#123; ... doHead(req, resp); &#125; else if (method.equals(METHOD_POST)) &#123; doPost(req, resp); &#125; else if (method.equals(METHOD_PUT)) &#123; doPut(req, resp); &#125; else if (method.equals(METHOD_DELETE)) &#123; doDelete(req, resp); &#125; else if (method.equals(METHOD_OPTIONS)) &#123; doOptions(req,resp); &#125; else if (method.equals(METHOD_TRACE)) &#123; doTrace(req,resp); &#125; else &#123; ... &#125;&#125;... Spring中使用 12SpringWeb部分，还是遵循Servlet规范的，DispatcherServlet的父类FrameworkServlet就对doGet、doPost等模板方法进行了重写。... Talk is cheap, Show my hub 基本模板 把大象放进冰箱，拢共分几步 How to be a programming master ? 参考 https://github.com/get-set/get-designpatterns/tree/master/template-method https://github.com/iluwatar/java-design-patterns/blob/master/template-method/src/main/java/com/iluwatar/templatemethod/SubtleMethod.java https://www.cnblogs.com/betterboyz/p/9377881.htm https://www.runoob.com/design-pattern/template-pattern.html https://blog.51cto.com/liukang/2048245","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://moon-zhou.github.io/categories/设计模式/"}],"tags":[]},{"title":"IPV6支持改造记录","slug":"IPV6支持改造记录","date":"2019-12-26T12:00:34.000Z","updated":"2019-12-26T12:44:56.475Z","comments":true,"path":"2019/12/26/IPV6支持改造记录/","link":"","permalink":"https://moon-zhou.github.io/2019/12/26/IPV6支持改造记录/","excerpt":"背景 某天，发现B乎上有个提示是“支持IPV6”。灵光一闪，心底一身呵呵，未来的某一天啊~ 2019.12月了，各种合规检查又来了。其中一项就是支持IPV6，作为PC门户，理所当然的需要进行升级。 重点工作复盘，反思。","text":"背景 某天，发现B乎上有个提示是“支持IPV6”。灵光一闪，心底一身呵呵，未来的某一天啊~ 2019.12月了，各种合规检查又来了。其中一项就是支持IPV6，作为PC门户，理所当然的需要进行升级。 重点工作复盘，反思。 预备知识鉴于公司的整套域名访问机制，有必要做一个简述，即浏览器访问一个域名，在我们服务系统里是如何进行解析，最后到你提供服务端机器上的。 浏览器输入域名、访问。e.g. https://ema.suning.com https://paypassport.suning.com DNS等等 我司CDN 我司负载均衡VIP 我司网络防火墙WAF 具体系统的反向代理服务器，e.g.nginx WEB容器，e.g.Jboss 升级步骤 排查CDN接入情况，V6必须支持CDN（业务系统提工单，CDN部门实施） 排查门户系统以及下游直接关联的业务系统（调用下游RPC接口），其实PC只是个web，任何业务都是需要相关系统提供服务的。 梳理业务场景（用于改造验证、回归） 梳理调用接口（尤其关注有ip作为参数传递的接口），下游确定相关系统ip如果从V4变成了V6是否能够支持（尤其是对ip做了持久化的，字段长度是否需要进行更新） 梳理页面前端组件依赖（js组件也是通过域名访问的，组件域名都挂在各自系统下，而V6是根据域名来进行改造升级的，所以提供的组件也需要确认同步支持IPV6）(==这一步是遗漏的，而且灰度期间没有发现，全网支持时才发现==) 根据组件支持也业务支持的梳理，开始着手测试环境改造，测试 生产进行灰度（江苏电信，江苏移动） 生产全网支持IPV6 改造细节 本来改造的域名是PC实名系统，ema.suning.com，但是该域名受限访问，所以单点登录系统paypassport.suning.com也需要改造。又因为使用了公用的静态资源服务器，所以静态资源域名也需要支持respay.suning.com ema.suning.com为结果CDN，但是paypassport.suning.com和respay.suning.com接过CDN，因此实施的方式还不一样（工单和线下邮件找CDN部门实施） IPV6网络的搭建，构建测试的环境 ema.suning.com的测试环境本来只能内网访问，但是搭建的V6网络属于外网，所以需要重新申请机器配额，搭建一套新的外网可访问的测试环境 业务梳理和确认相对来说比较耗时，尤其是调用链比较长的业务，跨越的系统较多，确认过程比较漫长 页面文案说明改造，某个地方文案显示“支持IPV6” 生产进行灰度（江苏电信，江苏移动） 验证V4以及V6下业务是否正常 监控日志是否都正常 生产全网支持IPV6 验证V4以及V6下业务是否正常 监控日志是否都正常 通过拨测平台，验证全国范围内网络IP支持情况 问题全网时发现访问受限链接到登录页时，登录方式无法加载。进一步定位发现依赖的外部js组件，其域名在V6下不支持，导致功能不可用。进一步分析发现该js会被缓存，如果有缓存，是可以正常登录的。这也是生产灰度时没发现的原因。但是测试环境一直没有出现该问题，还需要关注下。(12.27再进行确认) 总结V6支持，其实在8月份进行过一次排查改造，但是当时并没有安排验证，上线。所以这一次临时的安排，也是之前准备的充分，更多的是搭建环境和影响确认。 灰度到上线时间太短，目的性和任务性太强。开发作为实施角色，进度的话语权太弱，如果长此以往，对于团队的成长是不健康的。适时的说“不”，给出专业的建议。 Be Professional~~!","categories":[{"name":"日常工作","slug":"日常工作","permalink":"https://moon-zhou.github.io/categories/日常工作/"}],"tags":[]},{"title":"快速失败(fail-fast)和安全失败(fail-safe)","slug":"快速失败(fail-fast)和安全失败(fail-safe)","date":"2019-12-20T12:14:34.000Z","updated":"2019-12-26T09:51:11.456Z","comments":true,"path":"2019/12/20/快速失败(fail-fast)和安全失败(fail-safe)/","link":"","permalink":"https://moon-zhou.github.io/2019/12/20/快速失败(fail-fast)和安全失败(fail-safe)/","excerpt":"背景临时安排面试，看了下JDK源码，以及比较火的《吊打面试官》系列-ConcurrentHashMap &amp; Hashtable，里面提到了fail-safe概念，需要深入了解下。","text":"背景临时安排面试，看了下JDK源码，以及比较火的《吊打面试官》系列-ConcurrentHashMap &amp; Hashtable，里面提到了fail-safe概念，需要深入了解下。 快速失败(fail-fast)概念 一种系统设计方法 维基百科解释 在系统设计中，一个 fail-fast 的系统可以通过特定的接口快速报告系统中任何潜在的故障。fail-fast 系统在发现故障时不会尝试继续运行系统，而会立即停止当前的操作。在进行一个操作时，会在多个检查点检查系统的状态，所以出现故障可以被尽早发现。fail-fast 模块的职责就是检查是否有故障，发现故障后会尽快通知上层系统来处理故障。 In Java 在用迭代器(iterator)遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出Concurrent Modification Exception，终止遍历。 原理 迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。 HashMap里示例 123456789101112131415161718192021222324252627public final void forEach(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) &#123; Node&lt;K,V&gt;[] tab; if (action == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; // 先获取当前的modCount值 int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) action.accept(e); &#125; // 遍历完确认是否发生变化 if (modCount != mc) throw new ConcurrentModificationException(); &#125;&#125;public void clear() &#123; Node&lt;K,V&gt;[] tab; // 修改该值，同理以下方法也有该操作 putVal，remove--》removeNode，computeIfAbsent... modCount++; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; size = 0; for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; &#125;&#125; 注意点 这里异常的抛出条件是检测到 modCount！=expectedmodCount 这个条件。如果集合发生变化时修改modCount值刚好又设置为了expectedmodCount值，则异常不会抛出。因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的bug。 fail-fast虽然可以规避，但不建议那样操作。 联想 与注意点里类似的还有equals方法和hashCode()的关系，equals方法比对出两个值相对，那么hashCode()必然相对，反之则不一定成功 CAS（比较交换）简单版本里，，如果交换期间，比对的值发生了多次变换，最后变灰期望的值，那么依然会发生交换，但是严格来说，是不能够进行交换的，这种例外的情况与注意点如出一辙。 场景java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）code My Hub 重点关注==注意点==里提到的情况部分 安全失败(fail-safe)体现 在遍历容器时，即使容器的元素被修改，不会报异常，也不会停止遍历元素。 原理 采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。(基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。) ConcurrentHashMap示例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Returns a &#123;@link Set&#125; view of the mappings contained in this map. * [这里] The set is backed by the map,so changes to the map are * reflected in the set, and vice-versa. The set supports element * removal, which removes the corresponding mapping from the map, * via the &#123;@code Iterator.remove&#125;, &#123;@code Set.remove&#125;, * &#123;@code removeAll&#125;, &#123;@code retainAll&#125;, and &#123;@code clear&#125; * operations. * * &lt;p&gt;The view&apos;s iterators and spliterators are * &lt;a href=&quot;package-summary.html#Weakly&quot;&gt;&lt;i&gt;weakly consistent&lt;/i&gt;&lt;/a&gt;. * * &lt;p&gt;The view&apos;s &#123;@code spliterator&#125; reports &#123;@link Spliterator#CONCURRENT&#125;, * &#123;@link Spliterator#DISTINCT&#125;, and &#123;@link Spliterator#NONNULL&#125;. * * @return the set view */public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; EntrySetView&lt;K,V&gt; es; return (es = entrySet) != null ? es : (entrySet = new EntrySetView&lt;K,V&gt;(this));&#125;/** * A view of a ConcurrentHashMap as a &#123;@link Set&#125; of (key, value) * entries. This class cannot be directly instantiated. See * &#123;@link #entrySet()&#125;. */static final class EntrySetView&lt;K,V&gt; extends CollectionView&lt;K,V,Map.Entry&lt;K,V&gt;&gt; implements Set&lt;Map.Entry&lt;K,V&gt;&gt;, java.io.Serializable &#123; ... &#125;/** * Base class for views. */abstract static class CollectionView&lt;K,V,E&gt; implements Collection&lt;E&gt;, java.io.Serializable &#123; private static final long serialVersionUID = 7249069246763182397L; final ConcurrentHashMap&lt;K,V&gt; map; CollectionView(ConcurrentHashMap&lt;K,V&gt; map) &#123; this.map = map; &#125; /** * Returns the map backing this view. * * @return the map backing this view */ public ConcurrentHashMap&lt;K,V&gt; getMap() &#123; return map; &#125; ...&#125; CopyOnWriteArrayList示例 123456789101112131415161718192021222324/** * &#123;@inheritDoc&#125; * * &lt;p&gt;The returned iterator provides a snapshot of the state of the list * when the iterator was constructed. No synchronization is needed while * traversing the iterator. The iterator does &lt;em&gt;NOT&lt;/em&gt; support the * &#123;@code remove&#125;, &#123;@code set&#125; or &#123;@code add&#125; methods. */public ListIterator&lt;E&gt; listIterator() &#123; return new COWIterator&lt;E&gt;(getArray(), 0);&#125;static final class COWIterator&lt;E&gt; implements ListIterator&lt;E&gt; &#123; /** Snapshot of the array */ private final Object[] snapshot; /** Index of element to be returned by subsequent call to next. */ private int cursor; private COWIterator(Object[] elements, int initialCursor) &#123; cursor = initialCursor; snapshot = elements; &#125; ...&#125; 场景java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。codeMy Hub 参考 https://www.cnblogs.com/yonyong/p/9323244.html https://blog.csdn.net/Kato_op/article/details/80356618 https://juejin.im/post/5dfdd73ee51d45580359a651 https://juejin.im/post/5dd72dcee51d4535424fc2eb","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://moon-zhou.github.io/categories/JAVA/"}],"tags":[]},{"title":"策略模式-Strategy","slug":"策略模式-Strategy","date":"2019-12-14T12:14:34.000Z","updated":"2019-12-24T03:29:29.364Z","comments":true,"path":"2019/12/14/策略模式-Strategy/","link":"","permalink":"https://moon-zhou.github.io/2019/12/14/策略模式-Strategy/","excerpt":"背景 刷设计模式 blog里通过策略模式+Stream去除代码里的多if判断","text":"背景 刷设计模式 blog里通过策略模式+Stream去除代码里的多if判断 概念 行为型模式：一个类的行为或其算法可以在运行时更改 官方描述（Head-First）：定义了算法族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化独立于使用算法的客户。 方言：针对一组算法，将每一种算法都封装到具有共同接口的独立的类中，从而使它们可以相互替换。(通常体现为多if判断，抽象分支算法，简化业务主逻辑) 本质：JAVA的多态特性，少用继承，多用组合 角色设计 策略（Strategy）：一个接口，该接口定义算法标识。 具体策略（ConcreteStrategy）：实现策略接口的类。具体策略实现策略接口所定义的抽象方法，即给出算法标识的具体算法。 上下文（Context）：依赖于策略接口的类，即上下文包含有策略声明的变量。上下文中提供了一个方法，该方法委托策略变量调用具体策略所实现的策略接口中的方法。 优点 算法可以自由切换 避免使用多重条件判断 扩展性良好（面向接口编程） 缺点 策略类会增多(爆炸) 策略类都需要对外暴露，上层模块必须知道有哪些策略，然后才能决定使用哪一个策略，违法迪米特法则 还是存在分支判断if-else Thinking 结合分布式配置中心手动选择策略 结合机器学习，自动选择合适策略 实际使用 签到系统不同渠道的签到规则，使用不同策略实现 Spring Bean加载 1234567891011121314Context封装对象，在这里就是ApplicationContext——AbstractXmlApplicationContext里BeanNameGenerator(策略)AnnotationBeanNameGeneratorDefaultBeanNameGeneratorResourceLoader(策略)DefaultResourceLoaderResourcePatternResolverBeanDefinitionReader(策略)AbstractBeanDefinitionReader(一次抽象，抽取公共方法)PropertiesBeanDefinitionReaderXmlBeanDefinitionReader 事件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 spring提供监听接口以及上下文基类 EventListener ApplicationListener&lt;E extends ApplicationEvent&gt; 自定义 CommonEvent extends ApplicationEvent 监听配置（xml，bean） CommonEventListener implements ApplicationListener&lt;CommonEvent&gt; &lt;bean id=&quot;commonEventListener&quot;class=&quot;com.suning.epp.cm.infrastructure.event.listener.CommonEventListener&quot;&gt; &lt;property name=&quot;eventExecutorMap&quot;&gt; &lt;map&gt; &lt;entry key=&quot;UPDATE_EMS_AUTH_INFO&quot;&gt; &lt;list&gt; &lt;ref bean=&quot;notifyAuthInfoEventExecutor&quot; /&gt; &lt;/list&gt; &lt;/entry&gt; &lt;entry key=&quot;BATCH_UPDATE_EMS_AUTH_INFO&quot;&gt; &lt;list&gt; &lt;ref bean=&quot;notifyAuthInfoEventExecutor&quot; /&gt; &lt;/list&gt; &lt;/entry&gt; &lt;entry key=&quot;UPDATE_ACCOUNT_RELATION&quot;&gt; &lt;list&gt; &lt;ref bean=&quot;notifyAuthInfoEventExecutor&quot; /&gt; &lt;/list&gt; &lt;/entry&gt; ... &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt; 抽象策略： public interface EventExecutor &#123; /** * 功能描述: 事件处理&lt;br&gt; * 〈功能详细描述〉 * * @param eventContext * @see [相关类/方法](可选) * @since [产品/模块版本](可选) */ public void execute(EventContext&lt;? extends BaseEventModel&gt; eventContext); &#125; 抽象策略执行所需的自定义上下文 EventContext&lt;T extends BaseEventModel&gt; 各策略实现 NotifyAuthInfoEventExecutor SendAuthInfoEventExecutor ... ApplicationContextAware 通过ApplicationContext.publishEvent(CommonEvent);抛送事件给监听器（观察者模式，TODO...） 验证器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869验证器： ValidationUtils.invokeValidator(new UserValidator(), user, errors);ValidationUtils（context）public static void invokeValidator(Validator validator, Object obj, Errors errors) &#123; Assert.notNull(validator, &quot;Validator must not be null&quot;); Assert.notNull(errors, &quot;Errors object must not be null&quot;); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Invoking validator [&quot; + validator + &quot;]&quot;); &#125; if (obj != null &amp;&amp; !validator.supports(obj.getClass())) &#123; throw new IllegalArgumentException( &quot;Validator [&quot; + validator.getClass() + &quot;] does not support [&quot; + obj.getClass() + &quot;]&quot;); &#125; validator.validate(obj, errors); if (logger.isDebugEnabled()) &#123; if (errors.hasErrors()) &#123; logger.debug(&quot;Validator found &quot; + errors.getErrorCount() + &quot; errors&quot;); &#125; else &#123; logger.debug(&quot;Validator found no errors&quot;); &#125; &#125;&#125;策略抽象public interface Validator &#123; boolean supports(Class clazz); void validate(Object target, Errors errors);&#125;具体策略：public class UserValidator implements Validator &#123; @Override public boolean supports(Class clazz) &#123; return User.class.equals(clazz); &#125; @Override public void validate(Object target, Errors errors) &#123; User user = (User) target; if (!StringUtils.hasLength(user.getUsername())) &#123; errors.rejectValue(&quot;username&quot;, &quot;&quot;, &quot;登录编码必须填写！&quot;); &#125; if (!StringUtils.hasLength(user.getPassword())) &#123; errors.rejectValue(&quot;password&quot;, &quot;&quot;, &quot;登录密码必须填写！&quot;); &#125; if (!StringUtils.hasLength(user.getName())) &#123; errors.rejectValue(&quot;name&quot;, &quot;&quot;, &quot;用户姓名必须填写！&quot;); &#125; &#125;&#125;public class HarmlessHandleValidator implements Validator &#123; @Override public boolean supports(Class clazz) &#123; return HarmlessHandle.class.equals(clazz); &#125; @Override public void validate(Object target, Errors errors) &#123; HarmlessHandle harmlessHandle = (HarmlessHandle) target; if (!StringUtils.hasLength(harmlessHandle.getHandleNo())) &#123; errors.rejectValue(&quot;handleNo&quot;, &quot;&quot;, &quot;编码必须填写！&quot;); &#125; if (!StringUtils.hasLength(harmlessHandle.getHandleName())) &#123; errors.rejectValue(&quot;handleName&quot;, &quot;&quot;, &quot;名称必须填写！&quot;); &#125; &#125;&#125; Demo 典型策略模式 变种策略模式-去除if 参考 https://www.jianshu.com/p/422acad380dd https://blog.csdn.net/CoderBruis/article/details/98075158","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://moon-zhou.github.io/categories/设计模式/"}],"tags":[]},{"title":"日常问题汇总-2019.12.1","slug":"日常问题汇总-2019.12.1","date":"2019-12-01T08:17:34.000Z","updated":"2019-12-01T08:19:48.838Z","comments":true,"path":"2019/12/01/日常问题汇总-2019.12.1/","link":"","permalink":"https://moon-zhou.github.io/2019/12/01/日常问题汇总-2019.12.1/","excerpt":"如果页面样式有缺，点击传送门 背景11.30，晚17:30，接到电话说会员wap提供的一个服务接口，接口成功率偏低，影响客户在百货门店使用苏宁百货卡门店扫码支付，商场支付显示分摊失败。","text":"如果页面样式有缺，点击传送门 背景11.30，晚17:30，接到电话说会员wap提供的一个服务接口，接口成功率偏低，影响客户在百货门店使用苏宁百货卡门店扫码支付，商场支付显示分摊失败。 问题分析 根据业务方提供的接口，确认接口是否真的成功率偏低 公司的微服务治理平台，确认该rpc接口今天的成功率情况，发现成功率只有50% 确认该错误何时开始，按日期往前统计，发现11.27的时候已经有部分错误了 梳理接口对应的业务场景（交接的老系统，无法直接根据接口进行分析） wap系统，提供H5验证支付密码的页面及后端功能：页面上验证支付密码，验证结果放redis缓存，返回业务方token 业务方后面再通过token调用相关RPC接口获取redis的验证结果 因为这一祖传功能在系统交接后未进行过任何迭代，也就是业务本身是没有漏洞的（前期上线如果有漏洞，不可能一直到现在才报了）。找到有错误返回的接口，确认业务日志。 H5验证支付密码页面组件，调用后端接口验证，验证成功，且将结果成功写入了redis rpc接口在通过token获取redis的值时，却发现没有获取到值 联想redis最近的修改，只有前段时间的==多活==改造有涉及 确认redis写入和读取的对应的数据中心，发现写入的是江北，读取的却是在雨花 目前主机房在雨花，备机房在江北，主机房向备机房做数据复制 所以得出直接原因，写入和读取的redis所在的数据区不一致，并且数据时准备复制的，备机房写入的数据无法在主机房进行读取 确认代码bug 确认读写redis的方法，发现写的时候，使用了改造后的方法，通过rpc来进行分流，确认数据写入哪个数据区（rpc进行流量控制） 读redis的时候，是通过redis直连的方法，但由于其本身是rpc接口，也就是本身就已经通过正确的分流来进行数据的读取 既然都是通过rpc了，那为什么写和读出现数据区不一致的情况呢？再次分析业务代码，发现写仍然是直连来写的，没有通过rpc接口。因为当时redis的操作方法进行多活改造的时候，加了开关控制，是直连redis操作，还是通过rpc分流后，再使用直连来进行操作。 查询分布式配置中心，发现当前开关为关。测试环境的开关却是打开的。 修复 打开生产的redis操作开关，使其通过rpc之后再进行直连当前的数据中心进行数据的读写操作。 开关修改后，关注接口的成功率，发现之前的错误码已经消失。 总结 开关类操作，不建议使用。尤其是需要后期重新进行操作的开关，如果不做备忘提醒，99.9%会被遗忘。 与此类似的还有个快捷绑卡接口切换的功能，因为服务提供方和我们也无方上线版本不一致，我们线上，必须做开关切换，先上线关闭开关，等服务方上线后，我们再进行接口切换，测试环境可以同时进行验证。不出所料，开关未进行切换，导致最后又客服问题时才发现原因。 Later is never，能做的当时就做了，不要拖延。 咱不是记仇的人，有仇当场就报了。 其他回顾会员WAP门户系统介绍 环境基础设施架构 nginx（反向代理做负载均衡） jboss（web服务器） nginx（统一的静态资源服务器） 其他公司统一的接入组件，如网络防火墙等 系统设计架构 后台系统 负责业务相关的配置 数据持久化到mysql 同时缓存redis H5页面及流程（传统web系统） 公网服务，域名请求访问 wap页面实现相关业务流程 读取后台的配置（redis/mysql，目前存在缓存穿透的风险未修复） 同时部分业务的数据缓存redis供RPC使用 RPC接口 内网访问 提供特定H5页面流程缓存的结果查询 代码架构 后台：Freemarker + SpringMVC + Spring + Mybatis H5页面（web系统）：Freemarker + SpringMVC + Spring 没有持久化的部分，持久化有对应域的服务端完成，我们通过rpc进行调用即可。 RPC接口：Spring 业务描述 123sequenceDiagramH5页面流程-&gt;&gt;后台系统: 获取配置RPC接口-&gt;&gt;H5页面流程: 获取流程结果 多活改造 框架/架构层 同配置搭建江北环境（已有雨花环境） 流量划拨配置 H5页面（web系统） 域名多活：接CDN nginx分发多活：接waf（网络防火墙） RPC接口 统一微服务治理框架多活：RSF多活路由 数据复制 主机房–》备机房 多活任务切换平台（流量划拨操作） 代码层 redis读写不能进行直连，只能通过rpc路由后，再rpc接口内部进行直连 注意点 H5的多活流量划拨通过CDN和waf RPC则是通过RSF服务治理平台 两个不同的切换，要保证流量划拨一致，否则很容易出现上述的问题","categories":[{"name":"问题记录","slug":"问题记录","permalink":"https://moon-zhou.github.io/categories/问题记录/"}],"tags":[]},{"title":"ZK-基础篇","slug":"ZK-基础篇","date":"2019-11-30T06:00:34.000Z","updated":"2019-11-30T08:56:16.038Z","comments":true,"path":"2019/11/30/ZK-基础篇/","link":"","permalink":"https://moon-zhou.github.io/2019/11/30/ZK-基础篇/","excerpt":"如果页面样式有缺，点击传送门 背景 分布式协调技术：分布式锁的学习 分布式环境当中多个进程之间的同步控制，让他们有序的去访问某种临界资源，防止造成”脏数据”的后果。 注册中心的实现方式（公司分布式服务框架加rsf，dubbo的注册中心的实现方式之一） 基本介绍 一个分布式的，开放源码的分布式应用程序协调服务 一致、有头、数据树","text":"如果页面样式有缺，点击传送门 背景 分布式协调技术：分布式锁的学习 分布式环境当中多个进程之间的同步控制，让他们有序的去访问某种临界资源，防止造成”脏数据”的后果。 注册中心的实现方式（公司分布式服务框架加rsf，dubbo的注册中心的实现方式之一） 基本介绍 一个分布式的，开放源码的分布式应用程序协调服务 一致、有头、数据树 环境搭建（此案例为window环境） 下载 官网 镜像 本示例使用的是3.5.6 修改配置：将conf目录下的zoo_sample.cfg文件，复制一份，重命名为zoo.cfg dataDir：保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。 修改数据存储目录：dataDir=E:\\\\opt\\\\zk\\\\data 修改日志目录：dataLogDir=E:\\\\opt\\\\zk\\\\log tickTime：Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔（即每隔 tickTime 时间就会发送一个心跳） initLimit：配置 Zookeeper 接受客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 10 个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 10*2000=20 秒 syncLimit：Leader 与 Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是 5*2000=10 秒 clientPort：客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。1234567891011121314151617181920212223242526272829# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=E:\\\\opt\\\\zk\\\\datadataLogDir=E:\\\\opt\\\\zk\\\\log# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1 启动zookeeper 进入安装目录下的bin文件夹，运行zkServer.cmd（windows机器） 确认服务启动成功 启动日志提示绑定相关端口 1binding to port 0.0.0.0/0.0.0.0:2181 netstat -ano 确认相关端口是否已经被绑定 或直接运行zkCli.cmd，显示连接成功： 12Welcome to ZooKeeper!zk: localhost:2181(CONNECTED) 安装单机伪集群模式 配置文件修改 修改配置文件 zoo.cfg 创建奇数个集群机器（==防止脑裂==），简单起见选择3台 创建3个对应的配置文件，zoo1.cfg，zoo2.cfg，zoo3.cfg 修改对应的配置 12345678910111213141516171819202122232425# 说明：# 1. 每个节点配置不同的数据目录# 2. 每个节点配置不同的端口# 3. 配置集群机器及端口，因为是在同一台机器的伪集群，所以都是localhost，如果是生产实际的多机器集群，填写各机器的ip# 节点1：zoo1.cfg配置dataDir=E:\\\\opt\\\\zk\\\\data\\\\zoo1clientPort=2181server.1=localhost:2887:3887server.2=localhost:2888:3888server.3=localhost:2889:3889# 节点2：zoo2.cfg配置dataDir=E:\\\\opt\\\\zk\\\\data\\\\zoo2clientPort=2182server.1=localhost:2887:3887server.2=localhost:2888:3888server.3=localhost:2889:3889# 节点3：zoo3.cfg配置dataDir=E:\\\\opt\\\\zk\\\\data\\\\zoo3clientPort=2183server.1=localhost:2887:3887server.2=localhost:2888:3888server.3=localhost:2889:3889 启动服务端脚本文件 zkServer.cmd 因为模拟的是3台机器的集群，上一步配置了多个机器的配置文件，所以需要创建对应的3台server启动脚本zkServer1.cmd，zkServer2.cmd，zkServer3.cmd 修改对应的配置文件：启动时读到对应的配置文件 1234567891011121314# 说明# zkServer1.cmd读取zoo1.cfg# zkServer2.cmd读取zoo2.cfg# zkServer3.cmd读取zoo3.cfg# 所以只需要将配置变量修改为读到最新的自定义配置的即可# 节点1启动脚本（call命令之间的set变量位置）set ZOOCFG=..\\conf\\zoo1.cfg# 节点2启动脚本（call命令之间的set变量位置）set ZOOCFG=..\\conf\\zoo2.cfg# 节点3启动脚本（call命令之间的set变量位置）set ZOOCFG=..\\conf\\zoo3.cfg 修改数据存储目录配置文件 因为zoo1.cfg，zoo2.cfg，zoo3.cfg配置了各自集群节点的数据目录 实际的各个目录需要手动创建，并添加myid文件 文件名为myid，没有任何后缀，内容为zoo1.cfg，zoo2.cfg，zoo3.cfg里配置的server.后面的数值，如本例为server.1/server.2/server.3，所以对应的文件为1/2/3 如果遗漏改配置修改，就会在启动时报错，信息如下： 1234567891011122019-11-30 11:12:53,730 [myid:] - ERROR [main:QuorumPeerMain@89] - Invalid config, exiting abnormally org.apache.zookeeper.server.quorum.QuorumPeerConfig$ConfigException: Error processing ..\\conf\\zoo1.cfg at org.apache.zookeeper.server.quorum.QuorumPeerConfig.parse(QuorumPeerConfig.java:154) at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:113) at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:82) Caused by: java.lang.IllegalArgumentException: myid file is missing at org.apache.zookeeper.server.quorum.QuorumPeerConfig.checkValidity(QuorumPeerConfig.java:734) at org.apache.zookeeper.server.quorum.QuorumPeerConfig.setupQuorumPeerConfig(QuorumPeerConfig.java:605) at org.apache.zookeeper.server.quorum.QuorumPeerConfig.parseProperties(QuorumPeerConfig.java:420) at org.apache.zookeeper.server.quorum.QuorumPeerConfig.parse(QuorumPeerConfig.java:150) ... 2 more Invalid config, exiting abnormally 启动集群服务 命令行运行：zkServer1.cmd，zkServer2.cmd，zkServer3.cmd 如果只运行zkServer1.cmd而不运行其他的两台，会报如下错误 123456789101112131415162019-11-30 14:55:10,541 [myid:1] - WARN [QuorumPeer[myid=1](plain=/0:0:0:0:0:0:0:0:2181)(secure=disabled):QuorumCnxManager@679] - Cannot open channel to 3 at election address localhost/127.0.0.1:3889java.net.ConnectException: Connection refused: connect at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.net.Socket.connect(Socket.java:589) at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectOne(QuorumCnxManager.java:650) at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectOne(QuorumCnxManager.java:707) at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectAll(QuorumCnxManager.java:735) at org.apache.zookeeper.server.quorum.FastLeaderElection.lookForLeader(FastLeaderElection.java:910) at org.apache.zookeeper.server.quorum.QuorumPeer.run(QuorumPeer.java:1247)2019-11-30 14:55:10,548 [myid:1] - INFO [QuorumPeer[myid=1](plain=/0:0:0:0:0:0:0:0:2181)(secure=disabled):FastLeaderElection@919] - Notification time out: 3200 正常启动3台机器，就不会有这些报错。如果启动后关闭一台机器，会有如下错误 1234567891011121314151617182019-11-30 14:59:29,214 [myid:1] - WARN [RecvWorker:3:QuorumCnxManager$RecvWorker@1221] - Connection broken for id 3, my id = 1, error =java.net.SocketException: Connection reset at java.net.SocketInputStream.read(SocketInputStream.java:209) at java.net.SocketInputStream.read(SocketInputStream.java:141) at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) at java.io.BufferedInputStream.read(BufferedInputStream.java:265) at java.io.DataInputStream.readInt(DataInputStream.java:387) at org.apache.zookeeper.server.quorum.QuorumCnxManager$RecvWorker.run(QuorumCnxManager.java:1206)2019-11-30 14:59:29,216 [myid:1] - WARN [RecvWorker:3:QuorumCnxManager$RecvWorker@1224] - Interrupting SendWorker2019-11-30 14:59:29,219 [myid:1] - WARN [SendWorker:3:QuorumCnxManager$SendWorker@1137] - Interrupted while waiting for message on queuejava.lang.InterruptedException at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088) at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418) at org.apache.zookeeper.server.quorum.QuorumCnxManager.pollSendQueue(QuorumCnxManager.java:1288) at org.apache.zookeeper.server.quorum.QuorumCnxManager.access$700(QuorumCnxManager.java:80) at org.apache.zookeeper.server.quorum.QuorumCnxManager$SendWorker.run(QuorumCnxManager.java:1125)2019-11-30 14:59:29,223 [myid:1] - WARN [SendWorker:3:QuorumCnxManager$SendWorker@1147] - Send worker leaving thread id 3 my id = 1 再次启动关闭的机器，其他两台又可以自动连上，组成集群 123456789101112131415161718192021222324252627282930313233 # 集群信息（启动时） # 节点1 从节点 2019-11-30 15:18:07,828 [myid:1] - WARN [QuorumPeer[myid=1](plain=/0:0:0:0:0:0:0:0:2181)(secure=disabled):Follower@125]- Got zxid 0x300000001 expected 0x1 # 节点2 主节点 2019-11-30 15:17:37,049 [myid:2] - INFO [QuorumPeer[myid=2](plain=/0:0:0:0:0:0:0:0:2182)(secure=disabled):Leader@464] -LEADING - LEADER ELECTION TOOK - 53 MS # 节点3 从节点 2019-11-30 15:18:07,826 [myid:3] - WARN [QuorumPeer[myid=3](plain=/0:0:0:0:0:0:0:0:2183)(secure=disabled):Follower@125]- Got zxid 0x300000001 expected 0x1 # 断开主节点（自动选举节点3为主节点） # 节点1 2019-11-30 15:23:49,255 [myid:1] - INFO [QuorumPeer[myid=1](plain=/0:0:0:0:0:0:0:0:2181)(secure=disabled):QuorumPeer@1269] - FOLLOWING # 节点3 2019-11-30 15:23:49,295 [myid:3] - INFO [QuorumPeer[myid=3](plain=/0:0:0:0:0:0:0:0:2183)(secure=disabled):QuorumPeer@1281] - LEADING 2019-11-30 15:23:49,779 [myid:3] - INFO [LearnerHandler-/127.0.0.1:54104:LearnerHandler@406] - Follower sid: 1 : info : localhost:2887:3887:participant # 重新连接上节点2，自动加入Follower # 节点1（保持不变-Follower） 2019-11-30 15:26:56,671 [myid:1] - INFO [WorkerReceiver[myid=1]:FastLeaderElection@679] - Notification: 2 (message format version), 3 (n.leader), 0x300000001 (n.zxid), 0x2 (n.round), LOOKING (n.state), 2 (n.sid), 0x3 (n.peerEPoch), FOLLOWING (my state)0 (n.config version) # 节点2 2019-11-30 15:26:56,729 [myid:2] - INFO [QuorumPeer[myid=2](plain=/0:0:0:0:0:0:0:0:2182)(secure=disabled):Follower@69] - FOLLOWING - LEADER ELECTION TOOK - 29 MS # 节点3（LearnerHandler，新连接的节点2加入Follower） 2019-11-30 15:26:56,896 [myid:3] - INFO [LearnerHandler-/127.0.0.1:54247:LearnerHandler@708] - Synchronizing with Follower sid: 2 maxCommittedLog=0x300000001 minCommittedLog=0x100000001 lastProcessedZxid=0x400000000 peerLastZxid=0x300000001 启动客户端 命令行运行zkCli.cmd即可 如果在客户端启动之后，想连接具体的机器，可使用connect命令 12# connect ip:portconnect localhost:2182 也可以在连接之后关闭，使用close命令 以上是使用一个zk程序，通过添加配置和修改启动服务脚本来达到伪集群的效果，也可以直接拷贝多个zk，每一个单独进行配置 集群角色 Leader：主节点，就是我们平时所说的master节点，用于提供读写服务 Follower：从节点，就是我们平时所说的slaver节点，提供读服务、leader选举等 Observer：从节点，一种特殊的Follower, 提供读服务, 不参与leader的选举 CLI 创建Znodes：注意有序节点和临时节点，当客户端断开连接时，临时节点将被删除。 1234567891011121314151617// -s：有序 -e：临时create [-s/-e] /path value// 设置节点moon，无值create /moon// boy节点 值为moon1create /boy moon1// boy节点的儿子节点 值为moon2create /boy/sec-boy moon2// seq-node0000000001节点 值为node1，后续创建别的节点就是node0000000002create -s /seq-node node1// temp-node临时节点create -e /temp-node temp 获取数据 123456789101112131415161718get [-s] [-w] /path// 获取根节点的值get /// 获取boy节点数据get /boy// 展示改节点数据的详细信息（创建时间，修改时间，zxid，更新次数，子节点个数等）get -s /moonget -w /moon// 展示根节点下的子节点ls /// 展示boy节点下的子节点ls /boy 监视znode的变化：当指定的znode或znode的子数据更改时，监视器会显示通知。 1234567891011121314# 使用该方式获取数据后，下一次值发生变更会有通知get -w /pathe.g.[zk: localhost:2181(CONNECTED) 14] get -w /moonv2[zk: localhost:2181(CONNECTED) 15] set /moon v3WATCHER::WatchedEvent state:SyncConnected type:NodeDataChanged path:/moon# 另说printwatches [on|off]也可以，但未测试成功 设置(修改)数据 1234set /path data// 给moon节点设置值，可以多次执行set /moon handsomeboy 创建znode的子节点：必须带上父节点，且父节点必须存在 12345678910111213create /parent/parent/.../path [data]# 父节点不存在的情况[zk: localhost:2181(CONNECTED) 18] create /moon/moon-sub1/moon-sub2/moon-lastNode does not exist: /moon/moon-sub1/moon-sub2/moon-last# 正常情况，层级创建[zk: localhost:2181(CONNECTED) 19] create /moon/moon-sub1Created /moon/moon-sub1[zk: localhost:2181(CONNECTED) 21] create /moon/moon-sub1/moon-sub2Created /moon/moon-sub1/moon-sub2[zk: localhost:2181(CONNECTED) 22] create /moon/moon-sub1/moon-sub2/moon-lastCreated /moon/moon-sub1/moon-sub2/moon-last 列出znode的子节点：带上父节点（全路径） 12345678ls /parent/parent/.../path# 比ls命令多输出本节点信息(包含创建时间，修改时间等)，低版本为ls2命令，高版本已废弃使用ls -sls -s /...[zk: localhost:2181(CONNECTED) 27] ls /moon[moon-sub1][zk: localhost:2181(CONNECTED) 28] ls /moon/moon-sub1[moon-sub2] 检查状态：状态描述指定的znode的元数据。它包含时间戳，版本号，ACL，数据长度和子znode等细项。 1234stat /pathstat /moonstat /moon/moon-sub1/moon-sub2/moon-last 移除/删除znode：子节点是否需要递归删除 12345678910111213141516171819202122# 移除指定的znode并递归其所有子节点，注意rmr在高版本已被废弃，但是功能仍然可用rmr /pathdeleteall /pathcreate /aaa a1rmr /aaa[zk: localhost:2181(CONNECTED) 42] rmr /aaaThe command &apos;rmr&apos; has been deprecated. Please use &apos;deleteall&apos; instead.create /aaa a1deleteall /aaacreate /aaa a1create /aaa/bbbdeleteall /aaa# 删除没有子节点的znode，还可以使用deletedelete /lastnodedelete /parent/parent/.../lastnodecreate /aaa a1delete /aaa 退出客户端 1quit 查看历史 1history 帮助 1help 参考 https://blog.csdn.net/ring300/article/details/80446918 https://www.w3cschool.cn/zookeeper/zookeeper_cli.html https://blog.csdn.net/zixiao217/article/details/82683260","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://moon-zhou.github.io/categories/分布式技术栈/"}],"tags":[]},{"title":"【反思录】最近开发的一点思考  2019-11-26","slug":"【反思录】最近开发的一点思考  2019-11-26","date":"2019-11-26T08:56:34.000Z","updated":"2019-11-26T14:40:55.764Z","comments":true,"path":"2019/11/26/【反思录】最近开发的一点思考  2019-11-26/","link":"","permalink":"https://moon-zhou.github.io/2019/11/26/【反思录】最近开发的一点思考  2019-11-26/","excerpt":"最近做的工作，与以往有些不同，总觉得要总结写什么，但又不知道从哪个点来入手。刚好要整理开发周报，就从最近这一个月的周报内容开始。","text":"最近做的工作，与以往有些不同，总觉得要总结写什么，但又不知道从哪个点来入手。刚好要整理开发周报，就从最近这一个月的周报内容开始。 目前负责的系统主要包含会员pc，会员wap，门户passport以及签到相关的系统。最近的角色更多的是个“自由人”，没有安排到具体的迭代版本里。总结这几周的工作内容，主要包含： 环境问题（机器下线，jdk升级，外网环境搭建） 生产问题分析（超时、客诉问题） 业务需求确认（登出合规改造） 配合小伙伴解决各类问题（静态资源多活搭建，代码提交，codereview） 迭代版本进度与质量控制 部分需求变更内容的开发 最近的工作重点偏向“打杂”类，更多的是配合小伙伴，解决迭代版本中的各种问题，保障小伙伴无障碍进行版本的迭代开发。其中，环境相关问题处理占比很大。说到开发环境的问题处理，已经半自动化了，更多的时候，你需要了解的是软件系统的整体架构，各个部分的职责，整体过程中请求的分发。正所谓成也萧何败萧何，公司内的架构标准一直在变更。比如老的系统里，使用的IHS+WAS的架构，现有的系统使用的是NGINX+JBOSS。你的各个环境（dev/sit/pst/pre/xgpre）得与时俱进吧，那就各个环境来一套吧。那么老的机器得下线吧，那就接着来吧。为了简化各个系统的操作流程，降低运维的难度，所以有了运维管理平台。但是系统架构的越来越复杂，运维管理平台也越来越多，导致很多流程只能从现在出发，一个个流转，最后却无法完成下去，还得来线下运维手工操作。就比如： 下线灾备环境的redis机器时，原以为私有云服务平台可以销毁，提示不支持该流程。就去运维管理平台，发现也无法操作。最后到缓存服务平台下线。下线时，提示架构不对，原来的两台机器不是主从关系，还得先进行主从配置，同时配置哨兵，变成“现阶段”的标准架构，再升级redis版本，升级过程还需要提交审批流程。最后完成升级后才能进行升级。 下线was机器，提示绑定了vip需要删除。删除又只支持主机组方式，服务器方式还只能线下邮件通知操作。邮件通知后还得运维晚上删除vip，成功删除之后，再进行即系销毁。 我就是想销毁个机器，你给我一通操作，一通引导。在万千操作方法里，找到其中唯一一条成功的路，复杂，风险大。本身是自动化运维，随着各个运维平台的专一化，出现功能交叉的地方，功能遗漏的地方，功能变更的地方，只能一个一个把坑踩过去。而且这类环境架构技术知识是没有统一的宣讲，布道的。所以推崇体系小团队开发的理念，就好导致每一个团队都需要踩一次坑。其实类比到我们业务系统里的业务也是一样的，随着系统业务的膨胀，其中各个开放出去的功能，如何保持每次变更的兼容性与稳定性，功能的可扩展性，都是一个严峻的问题。其中还会随着组织架构调整而来的系统交接，人员更替等，必然导致业务功能的复杂性越来越大，软件的“熵”也就越来越大，到处都是“腐烂”的味道。而当“熵”达到一定的程度之后，你就会逐渐遗忘，主观上降低“熵”的值。尤其是系统在经过几次交接之后，很多功能都被遗忘，除了生产问题，没有任何其他方法能够证明其重要性。因此，如果不下线，那就在制造代码过程中，要少的引入“腐败”的东西。同时还要适时的进行重构，但就目前而言，小伙伴很多时候，都没有达到这种水平，都缺失一种对代码的追求。都是完成任务式的coding。 另一个方面就是系统交互时的一些也无需求讨论。从业务上来说，我们属于服务中台，偏向业务基础业务服务的开发，和客户端的交互更多。很多时候，业务讨论的时候，客户端更多的时候都只是从他们的角度思考问题，态度还强硬的不行。e.g. 你必须给我这个接口或者实现方式。 我们目前没有这种实现或服务，后续会增加，目前你们自己先进行实现。 有什么意义呢？？后面几个版本出了问题，还不是打你们自己的脸吗？e.g. 签到系统首签规则非要签到系统自己判断，不在任务平台处理，结果呢？普通签到任务平台做的隐形操作，在首签场景没做，还不是要签到系统来擦屁股吗？ 冻结账户非要只回传ticket，还要我们拼接好回传，真的是***，就这个规则，迟早是一个坑。 屁股决定大脑，思考方式太局限，稍微站在别人角度思考的意向都没有。看到的越多，发现固步自封的人还真不少。所以自己也要更加的小心，小心自己的思维方式，小心被带着走。 你，需要影响一些人，改变一些人，觉醒一些人。同时，还需要寻找一些人，一些合适的人。","categories":[{"name":"总结反思录","slug":"总结反思录","permalink":"https://moon-zhou.github.io/categories/总结反思录/"}],"tags":[]},{"title":"日常问题汇总-2019.11.21","slug":"日常问题汇总-2019.11.21","date":"2019-11-21T12:14:34.000Z","updated":"2019-11-21T13:50:49.164Z","comments":true,"path":"2019/11/21/日常问题汇总-2019.11.21/","link":"","permalink":"https://moon-zhou.github.io/2019/11/21/日常问题汇总-2019.11.21/","excerpt":"背景签到系统的上游业务场景（如养成类游戏签到），发现系统出现了大量异常。 定位发现签到周期展示数据超出了约定的大小，原来按一周7天的数据返回，今天发现返回了8条数据。","text":"背景签到系统的上游业务场景（如养成类游戏签到），发现系统出现了大量异常。 定位发现签到周期展示数据超出了约定的大小，原来按一周7天的数据返回，今天发现返回了8条数据。 问题分析 根据上游提供的用户唯一id，确认用户签到数据。当前周期数据如下： 用户id 场景 签到日期 奖品 moon 某养成游戏 2019-11-16 xx:xx:xx xx饲料 moon 某养成游戏 2019-11-17 xx:xx:xx xx饲料 moon 某养成游戏 2019-11-18 xx:xx:xx xx饲料 moon 某养成游戏 2019-11-19 xx:xx:xx xx饲料 moon 某养成游戏 2019-11-19 xx:xx:xx moon 某养成游戏 2019-11-20 xx:xx:xx xx饲料 moon 某养成游戏 2019-11-21 xx:xx:xx xx饲料 发现用户当天签到正常（11-21），本周期内签到历史有一天有两条数据，且有一次没有获取到奖励（11-19）。 实际签到接口上是有防并发控制的（Onebyone），3s内同一用户是不能再次发起调用的。一般接口耗时在500ms左右，3s内基本已经完成签到。所以再次调用接口时，已完成签到的校验就会生效。按照该理想过程，基本不会发生同一天，同一用户出现两条签到记录的情况。 根据19号的签到时间，分析11.19当天的签到情况，发现签到过程首次签到时，用户并没有完成签到，3s后又发起了一次签到。按照理论第二次签到时，今天是否已经签到的校验肯定是不会通过的（查库里的签到数据），因为第一次签到数据已经入库。但是第二次却成功了，也就是第一次签到的数据还没有完成落库。 分析了整个调用顺序为：防并发校验–&gt;基本参数校验–&gt;业务逻辑校验–&gt;确认是否进行过首次签到–&gt;签到数据落库（首签额外需要记录）–&gt;计算签到周期及查询任务平台对应的活动预发放奖品–&gt;调用对应的签到任务（首签单独调用下游礼包系统，发送相关奖品）–&gt;事后相关操作（抛kafka等） 根据调用日志时间，发现当天调用任务平台接口出现大规模超时的情况。第一次调用完成的时间远超过了防并发的时间3s，即第一次调用未完成，签到数据未落库，就已经超过了3s。但是用户侧接口已经超时，发起了第二次签到，且相关验证都已通过，且完成了签到和奖励的发放。而当第二次签到结束时，第一次签到数据落库，再调用下游任务平台去判断相关奖励的发放。而下游系统做了用户单天单次参与活动的限制，所以第二次用户发放奖品记录为空。（如果是同一个请求内，多次调用下游系统发放奖品，如rpc接口的超时重试，只会发放一次，但返回都是有奖品的，接口的幂等设计）。 影响 上游做了签到周期天数校验或者完全依赖签到天数的业务场景系统，会出现相关异常arrayindexoutofboundsexception。 签到系统而言，签到周期没被破坏，是根据日期来计算的，依然按照正确的签到结果进行了奖品的发放。 修复 后台添加签到数据修正的功能，重复数据可以进行删除 签到周期进行排重 下游rpc接口根据实际场景，设置超时时间，不能使用服务提供方设置的超时时间作为服务消费方的超时时间。当前系统的多个rpc超时时间不能超过防并发的3s。 多次请求时，通过mybatis持久化时，事务未提交，后面的请求，依然要保证可以从其缓存中读取到相关待提交的数据（待确认）","categories":[{"name":"问题记录","slug":"问题记录","permalink":"https://moon-zhou.github.io/categories/问题记录/"}],"tags":[]},{"title":"算法与数据结构-2019.11.16","slug":"算法与数据结构-2019.11.16","date":"2019-11-16T12:30:34.000Z","updated":"2019-11-21T12:44:07.867Z","comments":true,"path":"2019/11/16/算法与数据结构-2019.11.16/","link":"","permalink":"https://moon-zhou.github.io/2019/11/16/算法与数据结构-2019.11.16/","excerpt":"","text":"力扣刷题 链表 有序链表里删除重复的节点 删除链表里倒数第n个数","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://moon-zhou.github.io/categories/算法与数据结构/"}],"tags":[]},{"title":"单例模式","slug":"单例模式","date":"2019-11-16T12:14:34.000Z","updated":"2019-11-16T13:58:44.727Z","comments":true,"path":"2019/11/16/单例模式/","link":"","permalink":"https://moon-zhou.github.io/2019/11/16/单例模式/","excerpt":"如果页面样式有缺，点击传送门 背景开刷设计模式概念一个类仅有一个实例，并提供一个访问它的全局访问点。使用场景类不需要频繁地创建与销毁，从而节省系统资源。","text":"如果页面样式有缺，点击传送门 背景开刷设计模式概念一个类仅有一个实例，并提供一个访问它的全局访问点。使用场景类不需要频繁地创建与销毁，从而节省系统资源。 特点 构造方法私有 持有自己类型的属性 对外提供获取实例的静态方法 方法饿汉 类加载时进行初始化 无需加锁且线程安全 容易产生垃圾 懒汉 使用时才进行对象实例化 注意点（结合github示例demo） 注意反射安全问题 注意线程安全问题（双重检查锁、指令重排问题） 特殊实现方式： 静态内部类 枚举示例（核心）show you my code 示例地图1234567graph LRHungryModeSingleton--&gt;LazyLoadModeThreadUnsafeSingletonLazyLoadModeThreadUnsafeSingleton--&gt;LazyLoadModeThreadSafeSingletonLazyLoadModeThreadSafeSingleton--&gt;LazyLoadModeThreadReflectionSafeSingletonLazyLoadModeThreadReflectionSafeSingleton--&gt;LazyLoadModeDoubleSynCheckSingletonLazyLoadModeDoubleSynCheckSingleton--&gt;LazyLoadModeDoubleSynCheckRefactionSafeSingletonLazyLoadModeDoubleSynCheckRefactionSafeSingleton--&gt;LazyLoadModeDoubleCheckFinalSingleton","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://moon-zhou.github.io/categories/设计模式/"}],"tags":[]},{"title":"Chrome extention","slug":"Chrome extention","date":"2019-11-13T12:14:34.000Z","updated":"2019-11-13T12:18:33.805Z","comments":true,"path":"2019/11/13/Chrome extention/","link":"","permalink":"https://moon-zhou.github.io/2019/11/13/Chrome extention/","excerpt":"背景请假处理相关事宜，回来尚早，登录github查看下关注的项目，提示chrome版本过低，因此做了相关升级。 升级过程，删除了历史数据，因此chrom插件都需要重新安装。 记录下开发来说比较常用的extention plugin。 因为vpn速度太慢，因此记录离线安装方式","text":"背景请假处理相关事宜，回来尚早，登录github查看下关注的项目，提示chrome版本过低，因此做了相关升级。 升级过程，删除了历史数据，因此chrom插件都需要重新安装。 记录下开发来说比较常用的extention plugin。 因为vpn速度太慢，因此记录离线安装方式 插件 名称 功能 掘金 github/博客园以及掘金等技术社区的热门文章、项目推送 Octotree github项目目录内容左侧目录树导航 安装步骤 掘金 下载地址，下载crx文件 打开谷歌浏览器–扩展程序 将crx文件直接拖进去即可 打开一个新tab页，即可看见推送内容 Octotree 下载地址，下载对应浏览器zip文件（crx没有安装成功） 将zip文件解压 打开谷歌浏览器–扩展程序–加载已解压的扩展程序 选择解压的文件夹即可 打开一个github project，左侧会出现树形结构目录（类IDE结构） 注意点最新版的chrome浏览器crx插件格式有变化，如果老版本的插件不一定能安装。后续其他插件在同步更新。","categories":[{"name":"工具效能","slug":"工具效能","permalink":"https://moon-zhou.github.io/categories/工具效能/"}],"tags":[]},{"title":"CDN","slug":"CDN","date":"2019-11-08T09:14:34.000Z","updated":"2019-11-10T13:39:33.775Z","comments":true,"path":"2019/11/08/CDN/","link":"","permalink":"https://moon-zhou.github.io/2019/11/08/CDN/","excerpt":"背景最近系统下挂的静态资源服务器持续告警ping延迟，做相关迁移过程中，发现有部分域名访问的静态资源也在这两台机器上，但是域名未做CDN接入。 因此需要对相关域名做CDN接入。同时再补充下CDN相关知识学习。","text":"背景最近系统下挂的静态资源服务器持续告警ping延迟，做相关迁移过程中，发现有部分域名访问的静态资源也在这两台机器上，但是域名未做CDN接入。 因此需要对相关域名做CDN接入。同时再补充下CDN相关知识学习。 CDN概念Content Delivery Network即内容分发网络。 构建在现有网络基础之上的智能虚拟网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。 关键技术主要有内容存储和分发技术。主要节点 用户（浏览器、app） CDN节点（移动、联通、电信、教育网、铁通…） 内容发布服务器 过程 用户向浏览器提供需要访问的域名 览器调用域名解析库对域名进行解析，由于CDN对域名解析过程进行了调整，所以解析函数库一般得到的是该域名对应的CNAME记录，为了得到实际的IP地址，浏览器需要再次对获得的CNAME域名进行解析以得到实际的IP地址；在此过程中，使用的全局负载均衡DNS解析。如根据地理位置信息解析对应的IP地址，使得用户能就近访问 此次解析得到CDN缓存服务器的IP地址，浏览器在得到实际的ip地址之后，向缓存服务器发出访问请求 缓存服务器根据浏览器提供的要访问的域名，通过Cache内部专用DNS解析得到此域名的实际IP地址，再由缓存服务器向此实际IP地址提交访问请求 缓存服务器从实际IP地址得到内容以后，一方面在本地进行保存，以备以后使用，二方面把获取的数据放回给客户端，完成数据服务过程 CDN回源回源原理 源站内容有更新的时候，源站主动把内容推送到CDN节点。 常规的CDN都是回源的。即：当有用户访问某一个URL的时候，如果被解析到的那个CDN节点没有缓存响应的内容，或者是缓存已经到期，就会回源站去获取。如果没有人访问，那么CDN节点不会主动去源站拿的。 回源域名一般是cdn领域的专业术语，通常情况下，是直接用ip进行回源的，但是如果客户源站有多个ip，并且ip地址会经常变化，对于cdn厂商来说，为了避免经常更改配置（回源ip），会采用回源域名方式进行回源，这样即使源站的ip变化了，也不影响原有的配置。 CDN本来是给我们的网站加速的，但是有时会因为不合适的回源策略给服务器带来负担，只有选择正确的策略才能给自己的网站带来更高的访问效率。 回源率计算方法 回源请求数比： 统计数据来自所有边缘节点上的请求记录，其中，对于没有缓存或缓存过期（可缓存）的请求以及不可缓存的请求，均计入回源请求中，其他直接命中缓存的，则为命中请求。 回源流量比： 回源流量是回源请求文件大小产生的流量和请求本身产生的流量 回源流量比=回源流量/回源流量+用户请求访问的流量 CDN缓存策略 CDN边缘节点缓存策略因服务商不同而不同，但一般都会遵循http标准协议，通过http响应头中的Cache-control: max-age的字段来设置CDN边缘节点数据缓存时间。 当客户端向CDN节点请求数据时，CDN节点会判断缓存数据是否过期，若缓存数据并没有过期，则直接将缓存数据返回给客户端；否则，CDN节点就会向源站发出回源请求，从源站拉取最新数据，更新本地缓存，并将最新数据返回给客户端。 CDN服务商一般会提供基于文件后缀、目录多个维度来指定CDN缓存时间，为用户提供更精细化的缓存管理。 CDN缓存时间会对“回源率”产生直接的影响。若CDN缓存时间较短，CDN边缘节点上的数据会经常失效，导致频繁回源，增加了源站的负载，同时也增大的访问延时；若CDN缓存时间太长，会带来数据更新时间慢的问题。开发者需要增对特定的业务，来做特定的数据缓存时间管理。 CDN缓存刷新 CDN边缘节点对开发者是透明的，相比于浏览器Ctrl+F5的强制刷新来使浏览器本地缓存失效，开发者可以通过CDN服务商提供的“刷新缓存”接口来达到清理CDN边缘节点缓存的目的。这样开发者在更新数据后，可以使用“刷新缓存”功能来强制CDN节点上的数据缓存过期，保证客户端在访问时，拉取到最新的数据。 参考 hrome-extension://lecdifefmmfjnjjinhaennhdlmcaeeeb/main.html https://www.jianshu.com/p/ce98fbff39ac https://www.jianshu.com/p/e7751ecb6f21","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://moon-zhou.github.io/categories/分布式技术栈/"}],"tags":[]},{"title":"Spring之属性注入之一","slug":"Spring之属性注入之一","date":"2019-11-07T12:14:34.000Z","updated":"2019-11-13T12:24:02.172Z","comments":true,"path":"2019/11/07/Spring之属性注入之一/","link":"","permalink":"https://moon-zhou.github.io/2019/11/07/Spring之属性注入之一/","excerpt":"背景继续深扒passport代码属性注入 xml配置bean 属性使用p:name-ref=”name”配置 属性为基本类型的格式： p:属性名=属性值 1p:name=&quot;Lily&quot; 或者 p:port=&quot;$&#123;redis.port&#125;&quot; 属性为引用类型的格式：p:属性名-ref=属性值（属性值为spring上下文里的变量） 1p:name-ref=&quot;name&quot; 或者 p:pool-config-ref=&quot;poolConfig&quot; 依赖的类属性必须为xxx-ref之前的xxx，且必须有setXxx方法","text":"背景继续深扒passport代码属性注入 xml配置bean 属性使用p:name-ref=”name”配置 属性为基本类型的格式： p:属性名=属性值 1p:name=&quot;Lily&quot; 或者 p:port=&quot;$&#123;redis.port&#125;&quot; 属性为引用类型的格式：p:属性名-ref=属性值（属性值为spring上下文里的变量） 1p:name-ref=&quot;name&quot; 或者 p:pool-config-ref=&quot;poolConfig&quot; 依赖的类属性必须为xxx-ref之前的xxx，且必须有setXxx方法 完整示例1234567&lt;bean id=&quot;JedisConnectionFactory&quot; class=&quot;org.springframework.data.redis.connection.jedis.JedisConnectionFactory&quot; p:host-name=&quot;$&#123;redis.host&#125;&quot; p:port=&quot;$&#123;redis.port&#125;&quot; p:password=&quot;$&#123;redis.pass&#125;&quot; p:pool-config-ref=&quot;poolConfig&quot; /&gt;&lt;bean id=&quot;poolConfig&quot; class=&quot;xxx.xxx&quot;/&gt; 类似 12345678&lt;bean id=&quot;JedisConnectionFactory&quot; class=&quot;org.springframework.data.redis.connection.jedis.JedisConnectionFactory&quot;/&gt; &lt;property name=&quot;host-name&quot; value=&quot;$&#123;redis.host&#125;&quot; /&gt; &lt;property name=&quot;port&quot; value=&quot;$&#123;redis.port&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;redis.pass&#125;&quot; /&gt; &lt;property name=&quot;pool-config&quot; ref=&quot;$&#123;redis.poolConfig&#125;&quot; /&gt;&lt;/bean&gt;&lt;bean id=&quot;poolConfig&quot; class=&quot;xxx.xxx&quot;/&gt; 参考https://www.cnblogs.com/smileblogs/p/10173612.html","categories":[{"name":"代码考古","slug":"代码考古","permalink":"https://moon-zhou.github.io/categories/代码考古/"}],"tags":[]},{"title":"SpringMvc之SimpleUrlHandlerMapping","slug":"SpringMvc之SimpleUrlHandlerMapping","date":"2019-11-04T12:14:34.000Z","updated":"2019-11-05T14:19:11.405Z","comments":true,"path":"2019/11/04/SpringMvc之SimpleUrlHandlerMapping/","link":"","permalink":"https://moon-zhou.github.io/2019/11/04/SpringMvc之SimpleUrlHandlerMapping/","excerpt":"背景 因为最近签到系统的需求基本没有迭代，因此正式进入passport的学习和开发。 passport的基本架构为：客户端jar包（接入方使用），以及服务端war包。服务端对外提供http接口（公网），rpc接口（内网）。 负责的登录功能，wap和pc都是通过http接口进行的交互，因此先梳理http接口相关技术点。 按照现有经验，应该是使用注解式的方法开放出controller层的对外http接口，寻找良久，虽然找到入口代码，但是并未找到映射路径，最后发现使用的是SimpleUrlHandlerMapping。","text":"背景 因为最近签到系统的需求基本没有迭代，因此正式进入passport的学习和开发。 passport的基本架构为：客户端jar包（接入方使用），以及服务端war包。服务端对外提供http接口（公网），rpc接口（内网）。 负责的登录功能，wap和pc都是通过http接口进行的交互，因此先梳理http接口相关技术点。 按照现有经验，应该是使用注解式的方法开放出controller层的对外http接口，寻找良久，虽然找到入口代码，但是并未找到映射路径，最后发现使用的是SimpleUrlHandlerMapping。 使用 配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041方式一：&lt;beans ...&gt; &lt;bean class=&quot;org.springframework.web.servlet.handler.SimpleUrlHandlerMapping&quot;&gt; &lt;property name=&quot;mappings&quot;&gt; &lt;props&gt; &lt;prop key=&quot;/welcome.htm&quot;&gt;welcomeController&lt;/prop&gt; &lt;prop key=&quot;/*/welcome.htm&quot;&gt;welcomeController&lt;/prop&gt; &lt;prop key=&quot;/helloGuest.htm&quot;&gt;helloGuestController&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;welcomeController&quot; class=&quot;com.mkyong.common.controller.WelcomeController&quot; /&gt; &lt;bean id=&quot;helloGuestController&quot; class=&quot;com.mkyong.common.controller.HelloGuestController&quot; /&gt; &lt;/beans&gt;方式二：&lt;beans ...&gt; &lt;bean class=&quot;org.springframework.web.servlet.handler.SimpleUrlHandlerMapping&quot;&gt; &lt;property name=&quot;mappings&quot;&gt; &lt;value&gt; /welcome.htm=welcomeController /*/welcome.htm=welcomeController /helloGuest.htm=helloGuestController &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;welcomeController&quot; class=&quot;com.mkyong.common.controller.WelcomeController&quot; /&gt; &lt;bean id=&quot;helloGuestController&quot; class=&quot;com.mkyong.common.controller.HelloGuestController&quot; /&gt; &lt;/beans&gt; 访问时使用的是精确匹配 总结 进行精确路径的匹配 进行模式串匹配，按照AntPattern的规则找出其中最优的匹配（用于校验时某些情况存在bug） 进行根路径匹配 使用默认handler 参考 https://www.jianshu.com/p/a43413b0ced1","categories":[{"name":"代码考古","slug":"代码考古","permalink":"https://moon-zhou.github.io/categories/代码考古/"}],"tags":[]},{"title":"安全问题汇总-2019.11.04","slug":"安全问题汇总-2019.11.04","date":"2019-11-04T09:14:34.000Z","updated":"2019-11-05T14:17:41.140Z","comments":true,"path":"2019/11/04/安全问题汇总-2019.11.04/","link":"","permalink":"https://moon-zhou.github.io/2019/11/04/安全问题汇总-2019.11.04/","excerpt":"背景最近公司外部白帽子频繁提交跳转链接相关的漏洞。问题1：url跳转描述从我司域名直接跳转到外部域名，可能会被第三方非法网站利用。漏洞分析 原先也对请求的url参数做了校验，但是使用的是PathMatcher::AntPathMatcher，该方法按路径进行匹配存在bug，以下非法路径依然可以被匹配 12匹配规则：http*://*.FIRST_DOMAIN.com/** 访问路径：https://www.baidu.com?enterpriseportal.FIRST_DOMAIN.com/sfbmp/index.htm","text":"背景最近公司外部白帽子频繁提交跳转链接相关的漏洞。问题1：url跳转描述从我司域名直接跳转到外部域名，可能会被第三方非法网站利用。漏洞分析 原先也对请求的url参数做了校验，但是使用的是PathMatcher::AntPathMatcher，该方法按路径进行匹配存在bug，以下非法路径依然可以被匹配 12匹配规则：http*://*.FIRST_DOMAIN.com/** 访问路径：https://www.baidu.com?enterpriseportal.FIRST_DOMAIN.com/sfbmp/index.htm 修复 跳转链接做一级域名的白名单校验 白名单放在分布式配置中心，可实时动态修改 核心校验1234567891011121314151617181920212223242526272829303132333435363738public static boolean matchDomain(String urlString) &#123; if (StringUtils.isEmpty(urlString)) &#123; return true; &#125; String domain = getToplevelDomain(urlString); // 可以配置到分布式配置中心，实时修改 String permitUrlDomains = &quot;.snxiaojinshi.com,.cnsuning.com,.suning.com,.financesn.com,yifubao.com,.snjijin.com,.sncfc.com.cn,.snisc.cn&quot;; String[] domainArr = permitUrlDomains.split(&quot;,&quot;); for (String d : domainArr) &#123; if (domain.endsWith(d)) &#123; return true; &#125; &#125; return false;&#125;/** * 获取顶级域名 */private static String getToplevelDomain(String urlString) &#123; /* * 分布式配置中心配置： * (?i)^https?://(?:[\\\\w-]+\\\\.)*((?!com)\\\\w*\\\\.(?:(com\\\\.)?cn|com|tv|net)[.\\\\w]*)[\\\\/]* */ String pattern = &quot;(?i)^https?://(?:[\\\\\\\\w-]+\\\\\\\\.)*((?!com)\\\\\\\\w*\\\\\\\\.(?:(com\\\\\\\\.)?cn|com|tv|net)[.\\\\\\\\w]*)[\\\\\\\\/]*&quot;; Pattern p = Pattern.compile(pattern, Pattern.CASE_INSENSITIVE); Matcher matcher = p.matcher(urlString); String urls = &quot;&quot;; while (matcher.find()) &#123; return &quot;.&quot; + matcher.group(1); &#125; return urls;&#125; 问题2：url Xss描述跳转链接参数在url请求时，存在反射型XSS aHR0cHM6Ly9tcGF5LnN1bmluZy5jb20vZXB3bS9yZWdpc3QvZG9SZWdpc3RJbml0Lmh0bT9iYWNrVXJsPWh0dHBzJTNBJTJGJTJGcGxwbHBzLnN1bmluZy5jb20lMkZwbHBscHMlMkZlbnRyeSUyRmVudHJ5Lmh0bWwlMjctKHM9d2luZG93KS0odD1zLnRvcCktKHRbJTI3YWwlMjclMmIlMjdlcnQlMjddKSgxKS0lMjcmb25seVJlZ2lzdD0xIw==问题分析跳转链接里存在非法字符，通过字符串拼接的方法，可以组织成可执行的js脚本修复 因为入参是url，且不会持久化，仅缓存用于跳转，直接对入参做字符合法性校验 合法性规则配置在分布式配置中心，可动态修改 和第一个问题一样，也需要保持授信域名 核心校验123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * 获取请求的backUrl * 入参：request.getQueryString() */public static String getBackUrl(String requestQuery) &#123; String backUrl = &quot;&quot;; String p = requestQuery; if (p != null) &#123; if (p.indexOf(SessionKey.BACK_URL) != -1) &#123; if (!(p.substring(p.indexOf(SessionKey.BACK_URL) + (SessionKey.BACK_URL.length())).startsWith(&quot;=&quot;))) &#123; return backUrl; &#125; backUrl = p.substring(p.indexOf(SessionKey.BACK_URL) + (SessionKey.BACK_URL.length() + 1)); String prefix = &quot;http&quot;; if (!backUrl.startsWith(prefix)) &#123; int index = backUrl.indexOf(prefix); if (index &gt; 0) &#123; backUrl = backUrl.substring(index); &#125; &#125; &#125; if (backUrl.indexOf(&apos;?&apos;) == -1 &amp;&amp; backUrl.indexOf(&apos;&amp;&apos;) != -1) &#123;// 判断URL是否存在&amp;，但不存在?的情况 backUrl = backUrl.substring(0, backUrl.indexOf(&apos;&amp;&apos;)); &#125; &#125; return backUrl;&#125;public static boolean isIncludeIllegalCharacter(String urlString) &#123; Set&lt;String&gt; illegalDomains = getConfigillegalDomains(); for (String illegalCharacter : illegalDomains) &#123; urlString = urlString.replace(&quot;http://&quot;, &quot;&quot;); urlString = urlString.replace(&quot;https://&quot;, &quot;&quot;); if (urlString.contains(illegalCharacter)) &#123; return true; // 非法 &#125; &#125; return false;&#125;/** * 获取动态配置非法字符 */private static Set&lt;String&gt; getConfigillegalDomains() &#123; Set&lt;String&gt; illegalDomains = new LinkedHashSet&lt;String&gt;(); // 肺部是配置中心配置：@,#,/,\\,?,%40,%0a,%20%0a,%22,(,) String illegalDomainStr = SystemSCMConfig.get(&quot;illegalDomains&quot;); String[] trustDomain = illegalDomainStr.split(&quot;,&quot;); for (String temp : trustDomain) &#123; if (StringUtils.isNotBlank(temp)) &#123; illegalDomains.add(temp); &#125; &#125; return illegalDomains;&#125;","categories":[{"name":"问题记录","slug":"问题记录","permalink":"https://moon-zhou.github.io/categories/问题记录/"}],"tags":[]},{"title":"算法与数据结构-2019.10.27","slug":"算法与数据结构-2019.10.27","date":"2019-10-27T12:30:34.000Z","updated":"2019-10-27T12:31:37.161Z","comments":true,"path":"2019/10/27/算法与数据结构-2019.10.27/","link":"","permalink":"https://moon-zhou.github.io/2019/10/27/算法与数据结构-2019.10.27/","excerpt":"","text":"力扣刷题 链表 找出两个链表的交点 链表反转 其他 缓存过期算法常用实现-惰性删除策略 参考https://github.com/CyC2018/CS-Notes/blob/master/notes/Leetcode%20%E9%A2%98%E8%A7%A3%20-%20%E9%93%BE%E8%A1%A8.md","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"https://moon-zhou.github.io/categories/算法与数据结构/"}],"tags":[]},{"title":"WebMvcConfigurationSupport使用导致静态资源404","slug":"WebMvcConfigurationSupport使用导致静态资源404","date":"2019-10-20T07:40:34.000Z","updated":"2019-10-20T07:40:21.365Z","comments":true,"path":"2019/10/20/WebMvcConfigurationSupport使用导致静态资源404/","link":"","permalink":"https://moon-zhou.github.io/2019/10/20/WebMvcConfigurationSupport使用导致静态资源404/","excerpt":"背景 WebMvcConfigurerAdapter提示已过时，因此使用WebMvcConfigurationSupport进行替换 替换后发现正常数据接口请求都正常，但是页面跳转请求里面，静态资源无法加载","text":"背景 WebMvcConfigurerAdapter提示已过时，因此使用WebMvcConfigurationSupport进行替换 替换后发现正常数据接口请求都正常，但是页面跳转请求里面，静态资源无法加载 原因分析 springboot的web自动配置类 WebMvcAutoConfiguration 上有条件注解 @ConditionalOnMissingBean(WebMvcConfigurationSupport.class)，意思是在项目类路径中 缺少 WebMvcConfigurationSupport类型的bean时改自动配置类才会生效，所以继承 WebMvcConfigurationSupport 后需要自己再重写相应的方法。 123456789@Configuration@ConditionalOnWebApplication(type = Type.SERVLET)@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class &#125;)@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter(&#123; DispatcherServletAutoConfiguration.class, TaskExecutionAutoConfiguration.class, ValidationAutoConfiguration.class &#125;)public class WebMvcAutoConfiguration &#123;&#125; 解决方案 在继承WebMvcConfigurationSupport的类里重写 addResourceHandlers（）方法，加入静态文件路径即可 12345@Overridepublic void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler(&quot;/**&quot;) .addResourceLocations(&quot;classpath:/&quot;);&#125; Githubhttps://github.com/moon-zhou/SpringBoot_Backend_Modules/blob/master/backend-base-web/src/main/java/org/moonzhou/backend/base/web/config/WebMvcConfig.java","categories":[{"name":"SpringBoot2.X","slug":"SpringBoot2-X","permalink":"https://moon-zhou.github.io/categories/SpringBoot2-X/"},{"name":"问题记录","slug":"SpringBoot2-X/问题记录","permalink":"https://moon-zhou.github.io/categories/SpringBoot2-X/问题记录/"}],"tags":[]},{"title":"Java之接口默认方法","slug":"Java之接口默认方法","date":"2019-10-19T12:14:34.000Z","updated":"2019-10-19T08:06:45.412Z","comments":true,"path":"2019/10/19/Java之接口默认方法/","link":"","permalink":"https://moon-zhou.github.io/2019/10/19/Java之接口默认方法/","excerpt":"背景函数式编程里涉及到接口仅有一个抽象的方法，不包含默认方法。因此需要扩展下这块内容。","text":"背景函数式编程里涉及到接口仅有一个抽象的方法，不包含默认方法。因此需要扩展下这块内容。 定义 接口:一种引用的数据类型，接口只是描述应该具备的方法，没有具体的实现，不能实例化。注意点如下： 除非实现接口的类是抽象类，否则该类要定义接口中的所有方法。 接口无法被实例化 每一个方法都是隐式公共、抽象的（方法名被 public abstract隐式修饰） 变量会被隐式的指定为 public static final 变量 接口中的方法是不能在接口中实现的，只能由实现接口的类来实现接口中的方 类在实现接口的方法时，不能抛出强制性异常，只能在接口中，或者继承接口的抽象类中抛出该强制性异常 默认方法：允许接口方法定义默认实现，子类方法不必须实现此方法而就可以拥有该方法及实现。 12345678910111213141516171819202122232425262728// java.util.function@FunctionalInterfacepublic interface IntConsumer &#123; /** * Performs this operation on the given argument. * * @param value the input argument */ void accept(int value); /** * Returns a composed &#123;@code IntConsumer&#125; that performs, in sequence, this * operation followed by the &#123;@code after&#125; operation. If performing either * operation throws an exception, it is relayed to the caller of the * composed operation. If performing this operation throws an exception, * the &#123;@code after&#125; operation will not be performed. * * @param after the operation to perform after this operation * @return a composed &#123;@code IntConsumer&#125; that performs in sequence this * operation followed by the &#123;@code after&#125; operation * @throws NullPointerException if &#123;@code after&#125; is null */ default IntConsumer andThen(IntConsumer after) &#123; Objects.requireNonNull(after); return (int t) -&gt; &#123; accept(t); after.accept(t); &#125;; &#125;&#125; 示例https://github.com/moon-zhou/Java8Practice/tree/master/src/main/java/com/moonzhou/interfacedemo","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://moon-zhou.github.io/categories/JAVA/"}],"tags":[]},{"title":"Github回滚提交历史","slug":"Github回滚提交历史","date":"2019-10-19T09:23:34.000Z","updated":"2019-10-19T14:20:09.119Z","comments":true,"path":"2019/10/19/Github回滚提交历史/","link":"","permalink":"https://moon-zhou.github.io/2019/10/19/Github回滚提交历史/","excerpt":"","text":"背景 公司使用git上传代码时，用户名和email使用的是工号和公司邮箱 周末使用公司电脑编写充电项目时，使用git提交代码到github上，未修改用户名和邮箱信息 公司会根据工号和邮箱，爬github信息，防止内部代码上传 因此错误上传代码后，需要及时回滚掉提交记录 解决方案回滚到错误提交前的记录，重新提交错误的文件 github找到需要回滚到某一次的hashcode，之后的提交文件需要备份 使用git reset –hard hashCode回使本地仓库回滚到这次的提交 git push origin HEAD –force，将这次的提交强制推到远程仓库，同步提交记录 将备份的文件或者修改后的文件重新提交 删除整个远程仓库，重新创建，提交","categories":[{"name":"Git","slug":"Git","permalink":"https://moon-zhou.github.io/categories/Git/"}],"tags":[]},{"title":"Git学习-小白实操","slug":"Git commit & comment","date":"2019-10-02T09:23:34.000Z","updated":"2019-10-06T11:30:56.999Z","comments":true,"path":"2019/10/02/Git commit & comment/","link":"","permalink":"https://moon-zhou.github.io/2019/10/02/Git commit & comment/","excerpt":"背景无论是最近的新项目还是持续迭代的老系统，提交的comment啥样的都有，各有千秋，但都无法准确的反应出当前的提交内容。 甚至连作者选中其中一条在不看内容的情况下，都无法准确描述这次提交的内容。 有责任心一点会用文字详细描述本次提交内容，但是没有固定的格式语法。 更有甚者只是描述下代码相关的功能，比如“xxxxx功能提交”，所以一个版本下来，所有的提交只有这一个描述。 见过最极端的就是直接写了个“代码提交”。 还有的一个功能写完一个类就commit一次，造成提交历史里净是他的提交记录，而且同时修改同一个类时，又总是造成与别人的冲突。","text":"背景无论是最近的新项目还是持续迭代的老系统，提交的comment啥样的都有，各有千秋，但都无法准确的反应出当前的提交内容。 甚至连作者选中其中一条在不看内容的情况下，都无法准确描述这次提交的内容。 有责任心一点会用文字详细描述本次提交内容，但是没有固定的格式语法。 更有甚者只是描述下代码相关的功能，比如“xxxxx功能提交”，所以一个版本下来，所有的提交只有这一个描述。 见过最极端的就是直接写了个“代码提交”。 还有的一个功能写完一个类就commit一次，造成提交历史里净是他的提交记录，而且同时修改同一个类时，又总是造成与别人的冲突。 规范 包括三个部分：header，body 和 footer。其中，header 是必需的，body 和 footer 可以省略。 12345&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;&lt;BLANK LINE&gt;&lt;body&gt;&lt;BLANK LINE&gt;&lt;footer&gt; 不管是哪一个部分，任何一行都不得超过72个字符（或100个字符）。这是为了避免自动换行影响美观。 Header 包括三个字段：type（必需）、scope（可选）和subject（必需） type：用于说明 commit 的类别，只允许使用下面7个标识。如果type为feat和fix，则该 commit 将肯定出现在 Change log 之中。其他情况（docs、chore、style、refactor、test）由你决定，要不要放入 Change log，建议是不要。 feat：新功能（feature） fix：修补bug docs：文档（documentation） style： 格式（不影响代码运行的变动） refactor：重构（即不是新增功能，也不是修改bug的代码变动） test：增加测试 chore：构建过程或辅助工具的变动 scope：scope用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。 subject：commit 目的的简短描述，不超过50个字符。 以动词开头，使用第一人称现在时，比如change，而不是changed或changes 第一个字母小写 结尾不加句号（.）Body对本次 commit 的详细描述，可以分成多行。 注意点 使用第一人称现在时，比如使用change而不是changed或changes。 永远别忘了第2行是空行 应该说明代码变动的动机，以及与以前行为的对比。FooterFooter 部分只用于以下两种情况 不兼容变动 如果当前代码与上一个版本不兼容，则 Footer 部分以BREAKING CHANGE开头，后面是对变动的描述、以及变动理由和迁移方法。 1234567891011121314151617BREAKING CHANGE: isolate scope bindings definition has changed.To migrate the code follow the example below:Before:scope: &#123; myAttr: &apos;attribute&apos;,&#125;After:scope: &#123; myAttr: &apos;@&apos;,&#125;The removed `inject` wasn&apos;t generaly useful for directives so there should be no code using it. 关闭 Issue 如果当前 commit 针对某个issue，那么可以在 Footer 部分关闭这个 issue 。 1Closes #234 Revert还有一种特殊情况，如果当前 commit 用于撤销以前的 commit。 必须以revert:开头，后面跟着被撤销 Commit 的 Header。 Body部分的格式是固定的，必须写成This reverts commit hashcode.，其中的hash是被撤销 commit 的 SHA 标识符。 如果当前 commit 与被撤销的 commit，在同一个发布（release）里面，那么它们都不会出现在 Change log 里面。如果两者在不同的发布，那么当前 commit，会出现在 Change log 的Reverts小标题下面。123revert: feat(pencil): add &apos;graphiteWidth&apos; optionThis reverts commit 667ecc1654a317a13331b17617d973392f415f02. 优点 可读性好，清晰，不必深入看代码即可了解当前commit的作用 为Code Review做准备 方便跟踪工程历史（问题引入确认） 让其他的开发者在运行 git blame 的时候想跪谢 提高项目的整体质量，提高个人工程素质 可以过滤某些commit（比如文档改动），便于快速查找信息 1git log --grep feature 可以直接从commit生成Change log 参考 http://www.ruanyifeng.com/blog/2016/01/commit_message_change_log.html","categories":[{"name":"Git","slug":"Git","permalink":"https://moon-zhou.github.io/categories/Git/"},{"name":"工程质量","slug":"Git/工程质量","permalink":"https://moon-zhou.github.io/categories/Git/工程质量/"}],"tags":[]},{"title":"日常问题汇总-2019.09.24","slug":"日常问题汇总-2019.09.25","date":"2019-09-25T12:14:34.000Z","updated":"2019-10-06T11:30:56.999Z","comments":true,"path":"2019/09/25/日常问题汇总-2019.09.25/","link":"","permalink":"https://moon-zhou.github.io/2019/09/25/日常问题汇总-2019.09.25/","excerpt":"背景 有用户反馈签到提醒没有收到。 异常治理时发现，有一个一类异常SQLException（扣个人分），引起关注，需要进行深入分析和治理掉。 1232019-09-25 10:05:05,766 INFO [stdout] (pool-4-thread-1) ; uncategorized SQLException; SQL state [null]; error code [0]; Transaction cannot proceed STATUS_ROLLEDBACK; nested exception is java.sql.SQLException: Transaction cannot proceed STATUS_ROLLEDBACK2019-09-25 10:05:05,766 INFO [stdout] (pool-4-thread-1) ### Error querying database. Cause: java.sql.SQLException: Transaction cannot proceed STATUS_ROLLEDBACK","text":"背景 有用户反馈签到提醒没有收到。 异常治理时发现，有一个一类异常SQLException（扣个人分），引起关注，需要进行深入分析和治理掉。 1232019-09-25 10:05:05,766 INFO [stdout] (pool-4-thread-1) ; uncategorized SQLException; SQL state [null]; error code [0]; Transaction cannot proceed STATUS_ROLLEDBACK; nested exception is java.sql.SQLException: Transaction cannot proceed STATUS_ROLLEDBACK2019-09-25 10:05:05,766 INFO [stdout] (pool-4-thread-1) ### Error querying database. Cause: java.sql.SQLException: Transaction cannot proceed STATUS_ROLLEDBACK 第一个问题分析 推送设计 查询现有需要推送的用户总量：36765 当前用户id为29863 当前用户的id小于总数，如果全量数据进行推送的话，不可能会遗漏当前用户。 确认该用户的推送情况，该用户从未被推送（推送了会刷推送时间，推送时间未null，即用户开通推送提醒之后就未收到过消息推送） 确认这几天的总体推送情况，从推送数目来看，都只是推动到26000条左右的。而且都只推送了5分钟。如果正常推送的话，数据正常推送会一直推送到36765，但现在只推送了5分钟就停止推送了。 123start id: 25500. end id: 25799. sleep time is: 3.start id: 25800. end id: 26099. sleep time is: 3.start id: 25800. end id: 26099. sleep time is: 3. 搜索输出日志的前后日志，发现有个error级别的日志记录，即上面的SQLException 。 第二个问题分析 该异常表示数据库事务进行了回滚 详细分析相关业务，发现该段时间内并未进行sql的更新或入库操作，按理来说是不会有数据库回滚的。 再分析这个时间段的相关日志发现，这个时间段只有一个推送JOB在执行，但是推送JOB只是查询数据库，然后调用服务端业务，也并没有数据的更新或者入库。 再次核对该JOB代码，发现方法上加了@Transactional注解。 根据现象进行合理猜测 结合以上的分析，基本可以确认，这俩问题的原因一致：sql执行只有5分钟，超过5分钟抛出异常，但是查询方法，无回滚状态，无法进行回滚，抛了相关的异常。导致的业务上异常为，推送如果没执行完，后面的用户将不再进行推送。 证据 @Transactional注解本身并未显示使用超时设置，那timeout就是默认值-1，使用数据库本身的值。 123456789101112131415161718192021222324252627@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface Transactional &#123; @AliasFor(&quot;transactionManager&quot;) String value() default &quot;&quot;; @AliasFor(&quot;value&quot;) String transactionManager() default &quot;&quot;; Propagation propagation() default Propagation.REQUIRED; Isolation isolation() default Isolation.DEFAULT; int timeout() default -1; boolean readOnly() default false; Class&lt;? extends Throwable&gt;[] rollbackFor() default &#123;&#125;; String[] rollbackForClassName() default &#123;&#125;; Class&lt;? extends Throwable&gt;[] noRollbackFor() default &#123;&#125;; String[] noRollbackForClassName() default &#123;&#125;;&#125; 因为是使用Mycat做分库分表的方案，所以确认mycat有无相关超时配置。找到sqlExecuteTimeout：SQL执行超时的时间，Mycat会检查连接上最后一次执行SQL的时间，若超过这个时间则会直接关闭这连接。默认时间为300秒。 12&lt;!-- sql执行超时5分钟 --&gt;&lt;!-- &lt;property name=&quot;sqlExecuteTimeout&quot;&gt;300&lt;/property&gt; --&gt; 短期修改策略 现有推送的策略为每秒300个用户，每次推送间隔3s。结合现在服务端接口执行时间，推送的用户总数，修改为每秒400个用户，每次推送间隔2s。这样就可以在5分钟之内完成所有用户的推送。 服务端接口是线程池并发的方法，如果每秒用户推送数目过多的话，会出现线程拒绝的问题。详情见日出问题汇总-一 长期修改策略 后台推送方法去掉@Transactional 服务端现在是有三台机器，后台推送可以开启多线程调用服务端RPC接口，但需要确认好接口的负载均衡策略。避免多个请求都落到同一台机器，造成服务端推送任务线程池满，发生任务拒绝的情况RejectedExecutionException。 修改Mycat配置（该配置存疑，因为同一条sql在频繁执行），持续关注是否有相关SQL异常产生","categories":[{"name":"问题记录","slug":"问题记录","permalink":"https://moon-zhou.github.io/categories/问题记录/"}],"tags":[]},{"title":"日常问题汇总-2019.09.24","slug":"日常问题汇总-2019.09.24","date":"2019-09-24T12:14:34.000Z","updated":"2019-09-30T13:38:32.652Z","comments":true,"path":"2019/09/24/日常问题汇总-2019.09.24/","link":"","permalink":"https://moon-zhou.github.io/2019/09/24/日常问题汇总-2019.09.24/","excerpt":"功能描述负责的前置系统（H5）对外提供绑卡功能，流程结束，回跳原业务系统页面。问题现在流程结束无法进行回跳问题报文1https://mpay.suning.com/epwm/card/signCard.htm?_x_req_block_=0slH4zSTbIC3IOxKkJFRhYrTY8HYk3O1QYtfWAMTxulycqqnwzIqO0jnSHh0xIYvT4HZd0alzW6UTfJa4zhclWB7mpNuFYsRA0mm8mxVa29)CTbbiyAQr7YCLx9OW5vQdi)WNlTmxWN)H)0SanTggKOCbv8KR0Zv88B)gTIVcHuLPvJa8eDczMY)gH3SnEWkMGjurkwAfr9NeXqbyle)EgsEUExoZjJGxzMzTTlFeWtAX7LHaG2EV5qJ71UQksXAG6yhfcxtxjyLsZNiSJFNzT6eERlIOjj3R1SeefgY7TI)inre6E4wOys(ldDx9zOw2mLqPZl0k18LnbIXmmQO9R5GIsxEvmTWTGI(N2yhKgU7fDJZADodsRHOm3CAnyUnrCipRXq)ZjWdJ75lgPERE72H2iIW9z76sF(c11OcKxkHCKLF5kUirKqOc0C9xp4J4BVuK(suYrgO0CFf9lepsQ2OXIS42jD4FeruBChQ8blhBOfYNJj5SSpmg00IH)(sAQB(RYAe44BsGeeWwcuq2V(PcsmdXTqcGIJWvs9WVp1Ukrws9dSrqrLxyvQqOqBh6(3hfAzXA)soPnBmLrgJqEKjTg2ykAfmvJmbOCkerg1vvye2s7uvkUi(JJLQnpvQyDybArEZIP)x6uhInky4r1cHt810cyqHnrEuDmOIs3feW6(888Zekc8(2kfpQp2wZ3VTB2W4RJxx449YscApFcvpxvKgiKcTOLewcjFj2DLcgVPGFTp9tygtnLyNw7EaBj)Iqcdl9nT)hXbQKF)ZjwZ(TStzuAErcKIqD8v6dJ6BoM)7IMQlYn46afmpNO9OgLLCnMyGvmB)Ihur(4fdz5STdU75rpaCRLym9JcveM6bn(1TJMMfVqB3IU2rpm7rWhpFHwc5m(g)85pjlvwruQVGvRi5Ap9VX9B4Q64AAn2QuvkmGmhr6D62j)8Y1vVvvkEEG790O5zAr42u6Tq79gX8GrvxGGfmUOIvXE5EiIrlFUaG6gRBMctAqE)TElj9V4mNF0EVy7mmue)8Ehm38MbLuH4sXsSpNmiRa8cPLKA2926owEWekI)CdMkWZC(m5ElYfoHtLqBNLL)JbBgZwSZUVCtvtp3zls37RLrVnnwIOeORKOW6NvV2Lrp0ax0FqYlgNmysn0RET7YnKhoWxp84RVfcDlpiroiJtt2QDCqEA6(YJZAL2o6GviwJvRpJb9xmpJgUhQzSFOBQs(mbrJe04F9AS7lUhbpFLEcelUY0MOtEDO7PQHD7xnFgE3c72W5H3VpxmQZwQTuY9AhvaHdMKn)449TmpMCA32LQ1TZzb(gjYLNti9W4gslFM5WeOLPEGtj0aPY(P6HxHzK7Q5oT2bwHML5zR5s4uLIKySg)b9QK7hXz9txzg1EOABDdAjQryi(EmegUF46i01FEWOzG5ymCfyS8vC7eDFUe3kXcK3BIpbo5YdID15xFtt9SxR9OjY6R2Z5kB)V(8t3mZQ**&amp;_x_resp_flag_=0","text":"功能描述负责的前置系统（H5）对外提供绑卡功能，流程结束，回跳原业务系统页面。问题现在流程结束无法进行回跳问题报文1https://mpay.suning.com/epwm/card/signCard.htm?_x_req_block_=0slH4zSTbIC3IOxKkJFRhYrTY8HYk3O1QYtfWAMTxulycqqnwzIqO0jnSHh0xIYvT4HZd0alzW6UTfJa4zhclWB7mpNuFYsRA0mm8mxVa29)CTbbiyAQr7YCLx9OW5vQdi)WNlTmxWN)H)0SanTggKOCbv8KR0Zv88B)gTIVcHuLPvJa8eDczMY)gH3SnEWkMGjurkwAfr9NeXqbyle)EgsEUExoZjJGxzMzTTlFeWtAX7LHaG2EV5qJ71UQksXAG6yhfcxtxjyLsZNiSJFNzT6eERlIOjj3R1SeefgY7TI)inre6E4wOys(ldDx9zOw2mLqPZl0k18LnbIXmmQO9R5GIsxEvmTWTGI(N2yhKgU7fDJZADodsRHOm3CAnyUnrCipRXq)ZjWdJ75lgPERE72H2iIW9z76sF(c11OcKxkHCKLF5kUirKqOc0C9xp4J4BVuK(suYrgO0CFf9lepsQ2OXIS42jD4FeruBChQ8blhBOfYNJj5SSpmg00IH)(sAQB(RYAe44BsGeeWwcuq2V(PcsmdXTqcGIJWvs9WVp1Ukrws9dSrqrLxyvQqOqBh6(3hfAzXA)soPnBmLrgJqEKjTg2ykAfmvJmbOCkerg1vvye2s7uvkUi(JJLQnpvQyDybArEZIP)x6uhInky4r1cHt810cyqHnrEuDmOIs3feW6(888Zekc8(2kfpQp2wZ3VTB2W4RJxx449YscApFcvpxvKgiKcTOLewcjFj2DLcgVPGFTp9tygtnLyNw7EaBj)Iqcdl9nT)hXbQKF)ZjwZ(TStzuAErcKIqD8v6dJ6BoM)7IMQlYn46afmpNO9OgLLCnMyGvmB)Ihur(4fdz5STdU75rpaCRLym9JcveM6bn(1TJMMfVqB3IU2rpm7rWhpFHwc5m(g)85pjlvwruQVGvRi5Ap9VX9B4Q64AAn2QuvkmGmhr6D62j)8Y1vVvvkEEG790O5zAr42u6Tq79gX8GrvxGGfmUOIvXE5EiIrlFUaG6gRBMctAqE)TElj9V4mNF0EVy7mmue)8Ehm38MbLuH4sXsSpNmiRa8cPLKA2926owEWekI)CdMkWZC(m5ElYfoHtLqBNLL)JbBgZwSZUVCtvtp3zls37RLrVnnwIOeORKOW6NvV2Lrp0ax0FqYlgNmysn0RET7YnKhoWxp84RVfcDlpiroiJtt2QDCqEA6(YJZAL2o6GviwJvRpJb9xmpJgUhQzSFOBQs(mbrJe04F9AS7lUhbpFLEcelUY0MOtEDO7PQHD7xnFgE3c72W5H3VpxmQZwQTuY9AhvaHdMKn)449TmpMCA32LQ1TZzb(gjYLNti9W4gslFM5WeOLPEGtj0aPY(P6HxHzK7Q5oT2bwHML5zR5s4uLIKySg)b9QK7hXz9txzg1EOABDdAjQryi(EmegUF46i01FEWOzG5ymCfyS8vC7eDFUe3kXcK3BIpbo5YdID15xFtt9SxR9OjY6R2Z5kB)V(8t3mZQ**&amp;_x_resp_flag_=0 分析 前置的服务系统，确认操作用户 根据日志系统，查询用户操作行为，找到入口时请求 分析请求的当次所有业务日志，发现统一的日志拦截，能够正常打印回跳地址。但是业务里获取回跳地址却发现获取值为空。 根据不同的现象分析对应的详细代码逻辑，发现两处的获取参数方式不同 统一拦截日志 业务获取回跳 request.getParameterMap() request.getQueryString() 之前统一的对外访问链接，都接入了安全加密组件（前端提交之前统一加密，后端filter做统一解密，AES加解密），如果获取正常，则必然是过了解密的filter。而获取不到则说明获取时仍是密文。查看工具源码，发现解密组件重写了getParameter，getParameterNames，getParameterMap，并未对getQueryString做重写（有场景不能重写该方法），核心代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class DecryptionRequestWrapper extends HttpServletRequestWrapper &#123; private final boolean isDecryptStream; private final SecurityContext securityContext; private DecryptionInputStreamWrapper decryptionInputStream; private Map&lt;String, String[]&gt; decryptParameters; public DecryptionRequestWrapper(HttpServletRequest request, boolean isDecryptStream, SecurityContext securityContext) &#123; super(request); this.isDecryptStream = isDecryptStream; this.securityContext = securityContext; &#125; public ServletInputStream getInputStream() throws IOException &#123; if (this.decryptionInputStream != null) &#123; return this.decryptionInputStream; &#125; else if (this.isDecryptStream) &#123; this.decryptionInputStream = new DecryptionInputStreamWrapper(super.getInputStream(), this.securityContext); return this.decryptionInputStream; &#125; else &#123; return super.getInputStream(); &#125; &#125; public String getParameter(String name) &#123; String[] values = this.getParameterValues(name); return values != null &amp;&amp; values.length &gt; 0 ? values[0] : null; &#125; public Map&lt;String, String[]&gt; getParameterMap() &#123; this.tryDecrypt(); if (this.decryptParameters.isEmpty()) &#123; return this.getRequest().getParameterMap(); &#125; else &#123; Map&lt;String, String[]&gt; result = new HashMap(this.getRequest().getParameterMap()); result.remove(&quot;_x_req_block_&quot;); result.putAll(this.decryptParameters); return result; &#125; &#125; public Enumeration&lt;String&gt; getParameterNames() &#123; return Collections.enumeration(this.getParameterMap().keySet()); &#125; public String[] getParameterValues(String name) &#123; this.tryDecrypt(); String[] result = (String[])this.decryptParameters.get(name); if (result == null) &#123; result = this.getRequest().getParameterValues(name); &#125; return result; &#125; private void tryDecrypt() &#123; if (this.decryptParameters == null) &#123; this.decryptParameters = new HashMap(); String[] encryptValues = this.getRequest().getParameterValues(&quot;_x_req_block_&quot;); if (encryptValues != null) &#123; String[] arr$ = encryptValues; int len$ = encryptValues.length; for(int i$ = 0; i$ &lt; len$; ++i$) &#123; String encryptValue = arr$[i$]; this.doDecrypt(encryptValue); &#125; &#125; &#125; &#125; private void doDecrypt(String encryptQueryString) &#123; if (StringUtils.isNotEmpty(encryptQueryString)) &#123; String originQueryString = this.securityContext.decodeQuery(encryptQueryString); CodecUtils.parseQueryString(originQueryString, this.decryptParameters); &#125; &#125;&#125; 明确原因，request请求里，无法正确获取链接里的参数是因为request.getQueryString()里没有被解密组件重写，无法获取里面的参数 解决方案 明确加密的参数内容，发现我们回跳的部分是无需加密的，因此这部分数据可以明文传输，其他部分作为密码接着放在跳转链接后面。即backUrl部分明文即可： 1https://mpay.suning.com/epwm/card/signCard.htm?backUrl=http://eppg.suning.com/epps-eppg/wapContract/show.htm?_x_req_block_=0slH4zSTbIC3IOxKkJFRhYrTY8HYk3O1QYtfWAMTxulycqqnwzIqO0jnSHh0xIYvT4HZd0alzW6UTfJa4zhclWB7mpNuFYsRA0mm8mxVa29)CTbbiyAQr7YCLx9OW5vQdi)WNlTmxWN)H)0SanTggKOCbv8KR0Zv88B)gTIVcHuLPvJa8eDczMY)gH3SnEWkMGjurkwAfr9NeXqbyle)EgsEUExoZjJGxzMzTTlFeWtAX7LHaG2EV5qJ71UQksXAG6yhfcxtxjyLsZNiSJFNzT6eERlIOjj3R1SeefgY7TI)inre6E4wOys(ldDx9zOw2mLqPZl0k18LnbIXmmQO9R5GIsxEvmTWTGI(N2yhKgU7fDJZADodsRHOm3CAnyUnrCipRXq)ZjWdJ75lgPERE72H2iIW9z76sF(c11OcKxkHCKLF5kUirKqOc0C9xp4J4BVuK(suYrgO0CFf9lepsQ2OXIS42jD4FeruBChQ8blhBOfYNJj5SSpmg00IH)(sAQB(RYAe44BsGeeWwcuq2V(PcsmdXTqcGIJWvs9WVp1Ukrws9dSrqrLxyvQqOqBh6(3hfAzXA)soPnBmLrgJqEKjTg2ykAfmvJmbOCkerg1vvye2s7uvkUi(JJLQnpvQyDybArEZIP)x6uhInky4r1cHt810cyqHnrEuDmOIs3feW6(888Zekc8(2kfpQp2wZ3VTB2W4RJxx449YscApFcvpxvKgiKcTOLewcjFj2DLcgVPGFTp9tygtnLyNw7EaBj)Iqcdl9nT)hXbQKF)ZjwZ(TStzuAErcKIqD8v6dJ6BoM)7IMQlYn46afmpNO9OgLLCnMyGvmB)Ihur(4fdz5STdU75rpaCRLym9JcveM6bn(1TJMMfVqB3IU2rpm7rWhpFHwc5m(g)85pjlvwruQVGvRi5Ap9VX9B4Q64AAn2QuvkmGmhr6D62j)8Y1vVvvkEEG790O5zAr42u6Tq79gX8GrvxGGfmUOIvXE5EiIrlFUaG6gRBMctAqE)TElj9V4mNF0EVy7mmue)8Ehm38MbLuH4sXsSpNmiRa8cPLKA2926owEWekI)CdMkWZC(m5ElYfoHtLqBNLL)JbBgZwSZUVCtvtp3zls37RLrVnnwIOeORKOW6NvV2Lrp0ax0FqYlgNmysn0RET7YnKhoWxp84RVfcDlpiroiJtt2QDCqEA6(YJZAL2o6GviwJvRpJb9xmpJgUhQzSFOBQs(mbrJe04F9AS7lUhbpFLEcelUY0MOtEDO7PQHD7xnFgE3c72W5H3VpxmQZwQTuY9AhvaHdMKn)449TmpMCA32LQ1TZzb(gjYLNti9W4gslFM5WeOLPEGtj0aPY(P6HxHzK7Q5oT2bwHML5zR5s4uLIKySg)b9QK7hXz9txzg1EOABDdAjQryi(EmegUF46i01FEWOzG5ymCfyS8vC7eDFUe3kXcK3BIpbo5YdID15xFtt9SxR9OjY6R2Z5kB)V(8t3mZQ**&amp;_x_resp_flag_=0 思考关于公共组件，目前很多都是侵入式接入，比如这一次的统一安全解密组件，就需要代码里配置FILTER，且filter的顺序还要格外小心。 与此类似的还有其他组件，web-session，ids-client，以及spring的ContextLoaderListener。都是这种方式。 这类组件开发时，尤其要小心其中获取参数的方法，如果要重写，一定要保证重写的完全。 扩展web-session核心源码分析。此处不便透露，有兴趣可以私下交流。","categories":[{"name":"问题记录","slug":"问题记录","permalink":"https://moon-zhou.github.io/categories/问题记录/"}],"tags":[]},{"title":"HashMap源码1","slug":"HashMap源码1","date":"2019-09-22T09:23:34.000Z","updated":"2019-09-22T08:01:35.470Z","comments":true,"path":"2019/09/22/HashMap源码1/","link":"","permalink":"https://moon-zhou.github.io/2019/09/22/HashMap源码1/","excerpt":"背景 来自年龄的焦虑，多学一点，深入一点 由浅入深，本次先进行基础的分析 基本知识点 键值映射的数据结构，每一个键值对也叫做Entry/Node 无序 允许插入 null 的键和值 非线程安全","text":"背景 来自年龄的焦虑，多学一点，深入一点 由浅入深，本次先进行基础的分析 基本知识点 键值映射的数据结构，每一个键值对也叫做Entry/Node 无序 允许插入 null 的键和值 非线程安全 基本结构 初始大小16 1234/** * The default initial capacity - MUST be a power of two. */static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 手动初始化或者自动扩展时，长度必须是2的幂，详情 123456789101112/** * Returns a power of two size for the given target capacity. */static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 无hash碰撞时，按数组存储 hash碰撞后，碰撞的Entry/Node通过链表的方式进行存储 1.7里冲突节点使用“头插法”（类比栈，==后插入的Entry被查找的可能性更大==） 1.8里当链表长度大于 8 时==有可能==转为红黑树存储，且为“尾插法”（类比队列）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 桶的树化阈值：链表长度大于 8 时，有可能会转化成树/** * The bin count threshold for using a tree rather than list for a * bin. Bins are converted to trees when adding an element to a * bin with at least this many nodes. The value must be greater * than 2 and should be at least 8 to mesh with assumptions in * tree removal about conversion back to plain bins upon * shrinkage. */static final int TREEIFY_THRESHOLD = 8;// 桶的链表还原阈值：当在扩容（resize()）时（此时HashMap的数据存储位置会重新计算），在重新计算存储位置后，当原有的红黑树内数量 &lt; 6时，则将 红黑树退化为链表/** * The bin count threshold for untreeifying a (split) bin during a * resize operation. Should be less than TREEIFY_THRESHOLD, and at * most 6 to mesh with shrinkage detection under removal. */static final int UNTREEIFY_THRESHOLD = 6;// 最小树形化容量阈值：即 当哈希表中的容量 &gt; 该值时，才允许树形化链表（即将链表 转换成红黑树）// 也就是说在转变成树之前，还会有一次判断，只有键值对数量大于 64 才会发生转换。这是为了避免在哈希表建立初期，多个键值对恰好被放入了同一个链表中而导致不必要的转化。/** * The smallest table capacity for which bins may be treeified. * (Otherwise the table is resized if too many nodes in a bin.) * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts * between resizing and treeification thresholds. */static final int MIN_TREEIFY_CAPACITY = 64;/** * Replaces all linked nodes in bin at index for given hash unless * table is too small, in which case resizes instead. */final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; // 在转变成树之前，还会有一次判断，只有键值对数量大于 64 才会发生转换。 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125; 扩容：resize() 条件：HashMap.Size &gt; Capacity * LoadFactor 扩大到原来容量的两倍，并对键重新散列 1234567891011/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */final Node&lt;K,V&gt;[] resize() &#123;&#125; 哈希函数 常用方法：除留余数法（为了均匀地散列键的散列值，通常都会把数组的大小取素数（HashTable 的初始大小就是 11），因为素数的因子少，余数相等的概率小，冲突的几率就小。） HashMap 的容量始终是 2 的次幂，这是一个合数，之所以这样设计，是为了将==取模运算转为位运算==，提高性能。这个等式h % length = h &amp; (length-1)成立的原因如下： 12342^1 = 10 2^1 -1 = 01 2^2 = 100 2^2 -1 = 011 2^3 = 1000 2^3 -1 = 01112^n = 1(n个零) 2^n -1 = 0(n个1) 转为位运算后，length-1 就相当于一个低位掩码，在按位与时，它会把原散列值的高位置0，这就导致散列值只在掩码的小范围内变化，显然增大了冲突几率。为了减少冲突，HashMap 在设计散列算法时，使用高低位异或，变相的让键的高位也参与了运算 12345678910static final int hash(Object key) &#123; // JDK8 int h; // h = key.hashCode() 1. 取hashCode值 // h ^ (h &gt;&gt;&gt; 16) 2. 高16位与低16位异或，变相保留高位的比特位 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;// JDK7 的源码，JDK8 没有这个方法，但原理一样static int indexFor(int h, int length) &#123; return h &amp; (length-1); // 3. 取模运算&#125; 非线程安全 线程间的竞争条件主要是发生冲突或扩容时，链表的断链和续链操作。 参考 https://juejin.im/post/5d7ec6d4f265da03b76b50ff https://juejin.im/post/5a215783f265da431d3c7bba https://www.cnblogs.com/chinajava/p/5808416.html","categories":[{"name":"源码","slug":"源码","permalink":"https://moon-zhou.github.io/categories/源码/"}],"tags":[]},{"title":"HashMap初始化容量设置思考","slug":"HashMap初始化容量设置思考","date":"2019-09-21T09:23:34.000Z","updated":"2019-09-22T08:01:47.283Z","comments":true,"path":"2019/09/21/HashMap初始化容量设置思考/","link":"","permalink":"https://moon-zhou.github.io/2019/09/21/HashMap初始化容量设置思考/","excerpt":"结论当我们使用HashMap(int initialCapacity)来初始化容量的时候，jdk会默认帮我们计算一个相对合理的值当做初始容量。但是这个值并没有参考loadFactor的值。 也就是说，如果我们设置的默认值是7，经过Jdk处理之后，会被设置成8，但是，这个HashMap在元素个数达到 8*0.75 = 6的时候就会进行一次扩容，这明显是我们不希望见到的。 如果我们通过expectedSize / 0.75F + 1.0F计算，7/0.75 + 1 = 10 ,10经过Jdk处理之后，会被设置成16，这就大大的减少了扩容的几率。 当HashMap内部维护的哈希表的容量达到75%时（默认情况下），会触发rehash，而rehash的过程是比较耗费时间的。所以初始化容量要设置成expectedSize/0.75 + 1的话，可以有效的减少冲突也可以减小误差。【+1为取上整】 所以，我可以认为，当我们明确知道HashMap中元素的个数的时候，把默认容量设置成expectedSize / 0.75F + 1.0F 是一个在性能上相对好的选择，但是，同时也会牺牲些内存。","text":"结论当我们使用HashMap(int initialCapacity)来初始化容量的时候，jdk会默认帮我们计算一个相对合理的值当做初始容量。但是这个值并没有参考loadFactor的值。 也就是说，如果我们设置的默认值是7，经过Jdk处理之后，会被设置成8，但是，这个HashMap在元素个数达到 8*0.75 = 6的时候就会进行一次扩容，这明显是我们不希望见到的。 如果我们通过expectedSize / 0.75F + 1.0F计算，7/0.75 + 1 = 10 ,10经过Jdk处理之后，会被设置成16，这就大大的减少了扩容的几率。 当HashMap内部维护的哈希表的容量达到75%时（默认情况下），会触发rehash，而rehash的过程是比较耗费时间的。所以初始化容量要设置成expectedSize/0.75 + 1的话，可以有效的减少冲突也可以减小误差。【+1为取上整】 所以，我可以认为，当我们明确知道HashMap中元素的个数的时候，把默认容量设置成expectedSize / 0.75F + 1.0F 是一个在性能上相对好的选择，但是，同时也会牺牲些内存。 初始化核心算法 根据用户传入的容量值（代码中的cap），通过计算，得到第一个比他大的2的幂并返回。 核心算法代码： 1234567int n = cap - 1;n |= n &gt;&gt;&gt; 1;n |= n &gt;&gt;&gt; 2;n |= n &gt;&gt;&gt; 4;n |= n &gt;&gt;&gt; 8;n |= n &gt;&gt;&gt; 16;return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; 其实是对一个二进制数依次向右移位，然后与原值取或。目的对于一个数字的二进制，从第一个不为0的位开始，把后面的所有位都设置成1。 1100 1100 1100 &gt;&gt;&gt;1 = 0110 0110 01101100 1100 1100 | 0110 0110 0110 = 1110 1110 11101110 1110 1110 &gt;&gt;&gt;2 = 0011 1011 10111110 1110 1110 | 0011 1011 1011 = 1111 1111 11111111 1111 1111 &gt;&gt;&gt;4 = 1111 1111 11111111 1111 1111 | 1111 1111 1111 = 1111 1111 1111 做一下极限值的判断，然后把Step 1得到的数值+1。 参考 https://juejin.im/post/5cb3e3d4f265da039d327633","categories":[{"name":"源码","slug":"源码","permalink":"https://moon-zhou.github.io/categories/源码/"}],"tags":[]},{"title":"日常问题汇总-二","slug":"日常问题汇总-二","date":"2019-09-16T09:23:34.000Z","updated":"2019-09-22T08:01:29.820Z","comments":true,"path":"2019/09/16/日常问题汇总-二/","link":"","permalink":"https://moon-zhou.github.io/2019/09/16/日常问题汇总-二/","excerpt":"背景 某系统需要针对访问参数做安全性验证 底层抽象公共校验方法时，使用正则验证实现 正则加载过程逻辑发生了错误","text":"背景 某系统需要针对访问参数做安全性验证 底层抽象公共校验方法时，使用正则验证实现 正则加载过程逻辑发生了错误 设计思想 校验规则工具类、静态验证方法 规则定义存储在类的静态变量 常规验证规则在代码里写死配置在类变量里，动态规则配置在分布式配置中心里（一个） 因为规则是类的静态变量，所以每次调用校验方法时，获取分布式配置里的规则，替换掉最后一个 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public class XssShieldUtil &#123; /** 日志 */ private static final Logger LOGGER = LoggerFactory.getLogger(XssShieldUtil.class); // 规则 private static List&lt;Pattern&gt; patterns = null; /** XSS字符过滤正则 */ private static final String PATTERN_XSS_CHAR = &quot;(\\\\s|\\\\[|\\\\]|\\\\(|\\\\))*&quot;; /** * 功能描述: XSS特殊字符检查&lt;br&gt; * 〈详细功能描述〉 * * @param value 参数 * @return boolean */ public static boolean includeXss(String value) &#123; if(StringUtils.isBlank(value)) &#123; return false; &#125; return !StringUtils.equals(value, stripXss(value)); &#125; /** * 功能描述: XSS特殊字符过滤&lt;br&gt; * 〈详细功能描述〉 * * @param value 参数 * @return String */ public static String stripXss(String value) &#123; if(StringUtils.isNotBlank(value)) &#123; Matcher matcher = null; for(Pattern pattern : getPatterns()) &#123; matcher = pattern.matcher(value); // 匹配 if(matcher.find()) &#123; // 删除相关字符串 value = matcher.replaceAll(&quot;&quot;); &#125; &#125; value = value.replaceAll(&quot;&lt;&quot;, &quot;&amp;lt;&quot;).replaceAll(&quot;&gt;&quot;, &quot;&amp;gt;&quot;); LOGGER.info(&quot;stripXss after filter value=&#123;&#125;&quot;, value); &#125; return value; &#125; private static List&lt;Pattern&gt; getPatterns() &#123; if (patterns == null) &#123; List&lt;Pattern&gt; list = new ArrayList&lt;Pattern&gt;(); String regex = null; Integer flag = null; int arrLength = 0; // bug1:类级的方法，里面包含了类级的变量，访问时没有做并发控制，存在并发问题。即list有用户在遍历时，依然 for(Object[] arr : getXssPatternList()) &#123; arrLength = arr.length; // bug2: 不需要循环，循环之后，arrLength为2，list为不为7，为14，即相同的固定值塞了两个一模一样的 for(int i = 0; i &lt; arrLength; i++) &#123; regex = (String)arr[0]; flag = (Integer)arr[1]; list.add(Pattern.compile(regex, flag)); &#125; &#125; patterns = list; &#125; // 第八条规则动态从分布式配置中心里获取加载，替换原来的 // 初衷是好的，但是这里造成了bug3：从一开始就不为8，那么造成list一直在增加，最终会导致OOM if(8 == patterns.size())&#123; patterns.remove(patterns.size() - 1); &#125; String pattern = ScmProperties.getInstance().getValue(IdsConstants.PATTERN_XSS_CHAR); LOGGER.info(&quot;call getPatterns patternXssChar=&#123;&#125;&quot;, pattern); pattern = StringUtils.isEmpty(pattern) ? PATTERN_XSS_CHAR : pattern; patterns.add(Pattern.compile(pattern, Pattern.CASE_INSENSITIVE)); return patterns; &#125; // 7条固定规则 private static List&lt;Object[]&gt; getXssPatternList() &#123; List&lt;Object[]&gt; ret = new ArrayList&lt;Object[]&gt;(); ret.add(new Object[]&#123;&quot;regex rule1&quot;, Pattern.CASE_INSENSITIVE&#125;); ret.add(new Object[]&#123;&quot;regex rule2&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL&#125;); ret.add(new Object[]&#123;&quot;regex rule3&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL&#125;); ret.add(new Object[]&#123;&quot;regex rule4&quot;, Pattern.CASE_INSENSITIVE&#125;); ret.add(new Object[]&#123;&quot;regex rule5&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL&#125;); ret.add(new Object[]&#123;&quot;regex rule6&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL&#125;); ret.add(new Object[]&#123;&quot;regex rule7&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL&#125;); return ret; &#125; /** * 工具类禁止实例化 */ private XssShieldUtil()&#123;&#125;&#125; 问题汇总 bug1，类变量存在并发问题，有线程在遍历规则list时，有的线程在修改规则list bug2，循环的逻辑本身存在问题 bug3，依赖数目进行控制list大小，当条件不成立时，则大小根本无法控制，最终OOM 修复核心思路 解决并发 解决动态加载规则 核心修改getPatterns() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public class XssShieldUtil &#123; /** 日志 */ private static final Logger LOGGER = LoggerFactory.getLogger(XssShieldUtil.class); private static List&lt;Pattern&gt; patterns = null; /** XSS字符过滤正则 */ private static final String PATTERN_XSS_CHAR = &quot;(\\\\s|\\\\[|\\\\]|\\\\(|\\\\))*&quot;; // 规则在类加载的时候给类变量进行初始化 static &#123; patterns.add(Pattern.compile(&quot;regex rule1&quot;, Pattern.CASE_INSENSITIVE)); patterns.add(Pattern.compile(&quot;regex rule2&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL)); patterns.add(Pattern.compile(&quot;regex rule3&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL)); patterns.add(Pattern.compile(&quot;regex rule4&quot;, Pattern.CASE_INSENSITIVE)); patterns.add(Pattern.compile(&quot;regex rule5&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL)); patterns.add(Pattern.compile(&quot;regex rule6&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL)); patterns.add(Pattern.compile(&quot;regex rule7&quot;, Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL)); &#125; /** * 功能描述: XSS特殊字符检查&lt;br&gt; * 〈详细功能描述〉 * * @param value 参数 * @return boolean */ public static boolean includeXss(String value) &#123; if(StringUtils.isBlank(value)) &#123; return false; &#125; return !StringUtils.equals(value, stripXss(value)); &#125; /** * 功能描述: XSS特殊字符过滤&lt;br&gt; * 〈详细功能描述〉 * * @param value 参数 * @return String */ public static String stripXss(String value) &#123; if(StringUtils.isNotBlank(value)) &#123; Matcher matcher = null; for(Pattern pattern : getPatterns()) &#123; matcher = pattern.matcher(value); // 匹配 if(matcher.find()) &#123; // 删除相关字符串 value = matcher.replaceAll(&quot;&quot;); &#125; &#125; value = value.replaceAll(&quot;&lt;&quot;, &quot;&amp;lt;&quot;).replaceAll(&quot;&gt;&quot;, &quot;&amp;gt;&quot;); LOGGER.info(&quot;stripXss after filter value=&#123;&#125;&quot;, value); &#125; return value; &#125; private static List&lt;Pattern&gt; getPatterns() &#123; // 创建局部变量返回，避免并发 List&lt;Pattern&gt; newList = new ArrayList&lt;Pattern&gt;(); // 固定规则 newList.addAll(patterns); LOGGER.debug(&quot;newList 1 size=&#123;&#125;&quot;, newList.size()); String pattern = ScmProperties.getInstance().getValue(IdsConstants.PATTERN_XSS_CHAR); LOGGER.info(&quot;call getPatterns patternXssChar=&#123;&#125;&quot;, pattern); pattern = StringUtils.isEmpty(pattern) ? PATTERN_XSS_CHAR : pattern; // 动态规则 newList.add(Pattern.compile(pattern, Pattern.CASE_INSENSITIVE)); return newList; &#125; /** * 工具类禁止实例化 */ private XssShieldUtil()&#123;&#125;&#125;","categories":[{"name":"问题记录","slug":"问题记录","permalink":"https://moon-zhou.github.io/categories/问题记录/"}],"tags":[]},{"title":"PowerMock基本使用","slug":"PowerMock基本使用","date":"2019-09-14T13:54:39.000Z","updated":"2019-09-14T13:59:15.314Z","comments":true,"path":"2019/09/14/PowerMock基本使用/","link":"","permalink":"https://moon-zhou.github.io/2019/09/14/PowerMock基本使用/","excerpt":"如果页面样式有缺，点击传送门 背景 公司使用的持续部署平台，集成了SonarQube做代码质量检查，其中有单元测试覆盖率的要求。而全链路的测试覆盖率难度较大，如依赖下游系统接口返回结果等。通过MOCK各层数据，化繁为简，大大降低了覆盖代码的运行场景的难度。 团队里人员的更迭，每一个新加入的小伙伴，因为经验和本身学习能力的差异，对从未接触的东西从学习到上手效率不同，且部门没有一个成熟的技术操作文档。 Mockito不能mock静态、final、私有方法等，而PowerMock是在Mockito原有的基础上做了扩展，通过修改类字节码并使用自定义ClassLoader加载运行的方式来实现mock静态方法、final方法、private方法、系统类的功能。（PowerMock直接依赖于Mockito）","text":"如果页面样式有缺，点击传送门 背景 公司使用的持续部署平台，集成了SonarQube做代码质量检查，其中有单元测试覆盖率的要求。而全链路的测试覆盖率难度较大，如依赖下游系统接口返回结果等。通过MOCK各层数据，化繁为简，大大降低了覆盖代码的运行场景的难度。 团队里人员的更迭，每一个新加入的小伙伴，因为经验和本身学习能力的差异，对从未接触的东西从学习到上手效率不同，且部门没有一个成熟的技术操作文档。 Mockito不能mock静态、final、私有方法等，而PowerMock是在Mockito原有的基础上做了扩展，通过修改类字节码并使用自定义ClassLoader加载运行的方式来实现mock静态方法、final方法、private方法、系统类的功能。（PowerMock直接依赖于Mockito） 预备知识 了解基本的单元测试，知道Junit 基本术语 mock：构造虚拟数据，模拟真实方法调用 断言 mock测试流程 创建Mock对象 1List mockedList = mock(List.class); 使用mock对象 12using mock object mockedList.add(“one”); mockedList.clear(); //verification 验证mock对象 123verify(mockedList).add(&quot;one&quot;); verify(mockedList).clear();Assert... 使用 引入依赖 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.powermock&lt;/groupId&gt; &lt;artifactId&gt;powermock-module-junit4&lt;/artifactId&gt; &lt;version&gt;2.0.0-RC.3&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.powermock&lt;/groupId&gt; &lt;artifactId&gt;powermock-api-mockito2&lt;/artifactId&gt; &lt;version&gt;2.0.0-RC.3&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; JUnit常用注解 @RunWith：运行器 @RunWith(JUnit4.class)就是指用JUnit4来运行 @RunWith(SpringJUnit4ClassRunner.class),让测试运行于Spring测试环境 @RunWith(Suite.class)的话就是一套测试集合 @RunWith(PowerMockRunner.class)，使用PowerMockRunner运行 @Test Mockito里常用注解 @Mock对象：对象生成时不会执行任何构造器方法，方法调用时，不执行方法中的任何内容，返回原始默认值。 @Spy对象：对象生成时执行构造器方法，方法调用时，执行方法中的任何内容。 @InjectMocks对象： 对象生成时会执行构造器方法，如果有多个构造器，则会选择参数最多的构造方法，方法调用时，执行方法中的任何内容。 @InjectMocks注解标注的属性，可以自动注入标记@Mock、@Spy等注解的属性值 @InjectMocks标注的属性不能使用接口，因为@InjectMocks不能传入参数指明实现类 e.g.: 12345// 1、模拟HttpServletRequest对象，不需要依赖web容器，模拟获得请求参数HttpServletRequest request = mock(HttpServletRequest.class); when(request.getParameter(&quot;foo&quot;)).thenReturn(&quot;boo&quot;);// 注意:mock()是Mockito的静态方法，可以用@mock注解替换private @mock HttpServletRequest request Mockito里常用语法 数据打桩：构造虚拟数据，模拟方法返回，注意此方法可以返回多个值 123456when…thenReturn…doReturn…when…（用于spy对象）// 返回多个值，第一次调用返回第一个，后面依次调用对应依次的返回when(mock.someMethod()).thenReturn(value1).thenReturn(value2); when(mock.someMethod()).thenReturn(value1, value2); Answer接口模拟根据参数返回不同结果 123456789101112131415when(userAppMapper.getAppSecretByAppKey(anyString())).thenAnswer( (InvocationOnMock invocationOnMock) -&gt; &#123; String arg = (String) invocationOnMock.getArguments()[0]; if (null == arg || arg.equals(null)) &#123; return null; &#125; else if (arg.equals(&quot;q1w2e3r4t5y6u7i8o9p0&quot;)) &#123; UserApp app = new UserApp(); app.setAppKey(&quot;q1w2e3r4t5y6u7i8o9p0&quot;); app.setAppSecret(&quot;q1w2e3r4t5y6u7i8o9p0&quot;); return app; &#125; else &#123; return null; &#125; &#125;); 方法异常：构造抛异常 12when…thenThrow…doThow…when…（对void 方法进行方法预期设定） 方法是否执行 12doCallRealMethod…when…doNothing…when…（对void 方法进行方法预期设定） 验证行为：Mock对象的执行情况 执行次数 123456verify(mock).method()verify(mock, times(1)).method()verify(mock, atLeastOnce()).method()verify(mock, atLeast(1)).method()verify(mock, atMost(1)).method()verify(mock, never()).method() 超时验证：timeout 方法调用顺序：InOrder verifyNoMoreInteractions verifyZeroInteractions ArgumentCaptor Argument Matcher（参数匹配器）： any(User.class)，匹配任意User对象；anyString()匹配任意字符串；anyInt()匹配任意int型 PowerMock里常用注解 @RunWith(PowerMockRunner.class)：必须在Runwith里申明使用PowerMockRunner，以下注解才能生效 @PrepareForTest：Mock静态、final、私有方法。 1@PrepareForTest(&#123; StringUtils.class,FirstSignInfoPullTask.class&#125;) @SuppressStaticInitializationFor(“org.moonzhou.test.XXXX”)：阻止静态代码块运行 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576@Componentpublic class RedisOperatorImpl implements RedisOperator &#123; protected static ShardedJedisClientImpl shardedClient; static &#123; shardedClient = new ShardedJedisClientImpl(&quot;redis.conf&quot;); &#125; @Override public String set(final String key, final String value) &#123; return shardedClient.execute(new ShardedJedisAction&lt;String&gt;() &#123; public String doAction(ShardedJedis shardedJedis) &#123; return shardedJedis.set(key, value); &#125; &#125;); &#125;&#125;// 测试类@RunWith(PowerMockRunner.class)@PrepareForTest(&#123; StringUtils.class&#125;)@SuppressStaticInitializationFor(&quot;com.suning.epp.member.fmsms.admin.common.RedisOperatorImpl&quot;)public class MockFirstSignInfoPullTaskTest &#123; @InjectMocks private FirstSignInfoPullTask firstSignInfoPullTask; @Mock private FmsmsIntegration fmsmsIntegration; @Mock private ApplicationProperties applicationProperties; @Mock private RedisOperatorImpl redisService; @Mock private FileUploadIntegrationImpl ossFileUploadIntegration; @Before public void init() &#123; MockitoAnnotations.initMocks(MockFirstSignInfoPullTaskTest.class); &#125; @Test public void test() &#123; PowerMockito.mockStatic(RedisOperatorImpl.class); PowerMockito.mockStatic(StringUtils.class); List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(&quot;xxxxx&quot;); list.add(&quot;yyyyy&quot;); PowerMockito.when(applicationProperties.getTotalCount()).thenReturn(&quot;2&quot;); PowerMockito.when(applicationProperties.getStopRunning()).thenReturn(&quot;1&quot;); PowerMockito.when(redisService.get(&quot;firstSignFileCount&quot;)).thenReturn(&quot;0&quot;); PowerMockito.when(applicationProperties.getOssFileBucket()).thenReturn(&quot;memberattr_private&quot;); FileOSSResponse response = new FileOSSResponse(); JSONObject jsonObject = new JSONObject(); jsonObject.put(&quot;arrayLists&quot;,list); response.setFile(jsonObject.toJSONString()); PowerMockito.when(ossFileUploadIntegration.downFileStream(Mockito.anyObject())).thenReturn(response); PowerMockito.when(StringUtils.transformUserInfosFromBase64Str(Mockito.anyString())).thenReturn(list); Map&lt;String, Object&gt; resMap = new HashMap&lt;String, Object&gt;(); resMap.put(&quot;responseCode&quot;,&quot;00000&quot;); PowerMockito.when(fmsmsIntegration.firstSignInfoPush(Mockito.anyMap())).thenReturn(resMap); firstSignInfoPullTask.firstSignInfoPullTask(); &#125;&#125; PowerMock里常用语法：Mock静态、final、私有方法时，需要加注解@PrepareForTest mock方法内部new出来对象 1PowerMockito.whenNew(XXX.class).withArguments(&quot;AAA&quot;).thenReturn(New XXX()); Mock普通对象的final方法： 12@PrepareForTestPowerMockito.mock(XXX.class) 12345678910111213141516171819202122//测试目标代码：public class Source &#123; public boolean callFinalMethod(SourceDepend refer) &#123; return refer.isAlive(); &#125;&#125;public class SourceDepend &#123; public final boolean isAlive() &#123; return false; &#125;&#125; //测试用例代码：@Test@PrepareForTest(SourceDepend.class)public void testCallFinalMethod()&#123; SourceDepend depencency = PowerMockito.mock(SourceDepend.class); Source underTest = new Source(); PowerMockito.when(depencency.isAlive()).thenReturn(true); Assert.assertTrue(underTest.callFinalMethod(depencency));&#125; Mock普通类的静态方法 12@PrepareForTestPowerMockito.mockStatic(XXX.class); 123456789101112131415161718//测试目标代码：public boolean callStaticMethod() &#123; return SourceDepend.isExist();&#125;public static boolean isExist()&#123; return false;&#125; //测试用例代码：@Test@PrepareForTest(SourceDepend.class)public void testCallStaticMethod() &#123; Source underTest = new Source(); PowerMockito.mockStatic(SourceDepend.class); PowerMockito.when(SourceDepend.isExist()).thenReturn(true); Assert.assertTrue(underTest.callStaticMethod());&#125; Mock 私有方法 123456@PrepareForTestXXX xxx = PowerMockito.mock(XXX.class);PowerMockito.when(xxx, &quot;privateMethod&quot;).thenReturn(aaa);// another way(no testing)// PowerMockito.verifyPrivate(new XXX()).invoke(&quot;privateMethod&quot;, 1, &quot;json&quot;, request); 12345678910111213141516171819//测试目标代码：public boolean callPrivateMethod() &#123; return isExist();&#125; private boolean isExist() &#123; return false;&#125; //测试用例代码： @Test@PrepareForTest(Source.class)public void testCallPrivateMethod() throws Exception&#123; Source underTest = PowerMockito.mock(Source.class); PowerMockito.when(underTest.callPrivateMethod()).thenCallRealMethod(); PowerMockito.when(underTest, &quot;isExist&quot;).thenReturn(true); Assert.assertTrue(underTest.callPrivateMethod());&#125; 总结 以上为实际开发过程中涉及到的mock方法写单元测试，覆盖代码逻辑的基本使用方法 尽量通过mock，覆盖每一个逻辑分支 方法返回一定要使用断言 参考 https://www.cnblogs.com/hunterCecil/p/5721468.html https://www.jianshu.com/p/69f3d6785ad8","categories":[{"name":"工程质量","slug":"工程质量","permalink":"https://moon-zhou.github.io/categories/工程质量/"}],"tags":[]},{"title":"Hexo添加标记和分类","slug":"Hexo添加标记和分类","date":"2019-09-08T13:49:34.000Z","updated":"2019-09-08T14:20:58.182Z","comments":true,"path":"2019/09/08/Hexo添加标记和分类/","link":"","permalink":"https://moon-zhou.github.io/2019/09/08/Hexo添加标记和分类/","excerpt":"背景 云笔记目录下的文章都放在根目录下，数量已经达到不太好维护的程度，统一做了目录的划分 个人博客里的内容也需要进行对应的分类","text":"背景 云笔记目录下的文章都放在根目录下，数量已经达到不太好维护的程度，统一做了目录的划分 个人博客里的内容也需要进行对应的分类 选择主题 登录hexo官网主题库 之前使用的是Anodyne，从设计风格上，本次选择了Yilia-plus 离线下载或者clone到hexo目录下的themes文件夹下 修改项目目录下_config.yml的主题(hexo\\_config.yml,注意yml配置文件，冒号后有空格) 1theme: yilia-plus 主题基本配置 进入主题文件夹，打开主题下的_config.yml(hexo\\themes\\yilia-plus\\_config.yml) 根据主题下的README，按步骤自定义配置，本次核心修改category配置 1234menu: 主页: / 文章: /archives 分类: /categories 添加category配置 创建“分类”选项(hexo项目根目录) 1hexo new page categories 第一步执行完，会在项目目录下\\source\\categories文件夹下生产index.md文档，对该配置文档进行编辑(必须编辑在front matter里，即双—之间，尤其设置type) 123456---title: 分类date: 2017-12-02 21:01:24type: &quot;categories&quot;comments: false--- 确认项目目录下_config.yml里的category目录配置 1category_dir: categories 修改每一个项目目录下source_posts里的每一个md文档（博客文章），在front matter里添加分类categories 123456---title: Git学习-小白不能忍之二date: 2019-06-23 17:23:34categories: - Git--- 重新生成静态网站博文，并验证 123hexo cleanhexo ghexo s 验证时发现，发布文件夹hexo\\public\\categories里已经有相关配置了，但是category页面是个空白。（Anodyne主题就不会有该问题，所以每一主题都已自己的一套配置项，每次切换都需要根据README进行一次对应的配置修改） 需要重新编辑\\source\\categories下index.md，添加layout配置 1234567---title: 分类date: 2017-12-02 21:01:24type: &quot;categories&quot;layout: &quot;categories&quot;comments: false--- 自定义layout 主题\\themes\\yilia-plus\\layout目录下新建categories.ejs，自带的categorie.ejs无法正常使用（报错） 1234567891011121314151617181920&lt;article class=&quot;article article-type-post show&quot;&gt; &lt;header class=&quot;article-header&quot; style=&quot;border-bottom: 1px solid #ccc&quot;&gt; &lt;h1 class=&quot;article-title&quot; itemprop=&quot;name&quot;&gt; &lt;%= page.title %&gt; &lt;/h1&gt; &lt;/header&gt; &lt;% if (site.categories.length)&#123; %&gt; &lt;div class=&quot;category-all-page&quot;&gt; &lt;h2&gt;共计&amp;nbsp;&lt;%= site.categories.length %&gt;&amp;nbsp;个分类&lt;/h2&gt; &lt;%- list_categories(site.categories, &#123; show_count: true, class: &apos;category-list-item&apos;, style: &apos;list&apos;, depth: 2, separator: &apos;&apos; &#125;) %&gt; &lt;/div&gt; &lt;% &#125; %&gt;&lt;/article&gt; 主题themes\\yilia-plus\\source-src\\css目录下创建categories.scss样式文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950.category-all-page &#123; margin: 30px 40px 30px 40px; position: relative; min-height: 70vh; h2&#123; margin: 20px 0; &#125; .category-all-title &#123; text-align: center; &#125; .category-all &#123; margin-top: 20px; &#125; .category-list &#123; margin: 0; padding: 0; list-style: none; &#125; .category-list-item-list-item&#123; margin: 10px 15px; &#125; .category-list-item-list-count&#123; color: grey; &amp;:before &#123; display: inline; content: &quot; (&quot; &#125; &amp;:after &#123; display: inline; content: &quot;) &quot; &#125; &#125; .category-list-item &#123; margin: 10px 10px; &#125; .category-list-count &#123; color: grey; &amp;:before &#123; display: inline; content: &quot; (&quot; &#125; &amp;:after &#123; display: inline; content: &quot;) &quot; &#125; &#125; .category-list-child &#123; padding-left: 10px; &#125;&#125; 在主题themes\\yilia-plus\\source-src\\css目录下main.scss文件里，引入该scss文件（在同一目录） 1@import &quot;./categories&quot;; js文件会实时生效，但是scss文件需要进行重新编译 进入主题目录themes\\yilia-plus执行npm install 生成目标文件npm run dist 如果安装很慢，请进行镜像设置；如果安装出错，请uninstall之后重试 配置完成后，重新生成网站内容，验证正常 123hexo cleanhexo ghexo s tags配置类似 总结 该主题需要自定义layout及样式 不同的主题，配置差异很大，需要根据README逐个配置 source下目录结构 123456├─categories│ └──index.md├─tags│ └──index.md└─_posts └──***.md public下目录结构 123456├─archives│ └─***├─categories│ └─***└─tags └─***","categories":[{"name":"HEXO","slug":"HEXO","permalink":"https://moon-zhou.github.io/categories/HEXO/"}],"tags":[]},{"title":"日常问题汇总-一","slug":"日常问题汇总-一","date":"2019-09-07T12:14:34.000Z","updated":"2019-09-08T14:11:46.122Z","comments":true,"path":"2019/09/07/日常问题汇总-一/","link":"","permalink":"https://moon-zhou.github.io/2019/09/07/日常问题汇总-一/","excerpt":"如果页面样式有缺，点击传送门 背景 日常如何保证系统能够健康的运行，必不可少的就是实时的系统监控及告警。日常的服务接口成功率和耗时监控，还有一个就是系统异常数/种类，异常的影响级别等维度的监控。为此公司每月必须对系统产生的异常进行分析、治理。","text":"如果页面样式有缺，点击传送门 背景 日常如何保证系统能够健康的运行，必不可少的就是实时的系统监控及告警。日常的服务接口成功率和耗时监控，还有一个就是系统异常数/种类，异常的影响级别等维度的监控。为此公司每月必须对系统产生的异常进行分析、治理。 异常一 java.util.concurrent.RejectedExecutionException: Task com.suning.epps.fmsms.application.service.manager.config.PushSignRemindConfServiceImpl$1@6d18166d rejected from java.util.concurrent.ThreadPoolExecutor@4749b88d[Running, pool size = 16, active threads = 16, queued tasks = 100, completed tasks = 0] 异常解释 线程池超过其提交任务执行的吞吐量，大量任务过来时，没有足够的线程来完成，导致部分任务被拒绝执行，返回异常给主线程。 发生场景 分布式任务job跑批：定时为特定用户进行消息推送 架构 后台系统选择符合的数据，调用服务系统提供的推送rpc接口 服务系统根据传来的用户，直接调用推送系统进行推送 架构原因：后台作为分布式job入口，只负责获取原始数据，具体的业务推送的运算逻辑，统一在服务端里进行处理。后台机器目前只有一台（备一台，无异常时不参与对外提供服务），服务端有三台（备三台），这样才能整体提高该系统机器的一个使用效率。 服务端接口： 定义了参数为用户id的列表，列表数为1000，即每一次调用向1000个用户提供提送 推送的结果无强事务性，为了提高接口的处理能力，使用了多线程对提交的用户进行异步推送 分布式job跑批开始时，后台系统将获取到的数据丢给rpc接口（服务端）时，瞬时的tps可能会很高，因此第二步使用的多线程不能由业务逻辑去创建和管理，该场景使用统一的线程池进行线程的管理。 异常分析 数据量过大，job在调用服务端时，循环获取现有的数据后，直接调用服务端接口，导致tps很高 服务端里的线程池设置的最大线程数为16，同时阻塞队里使用 的是ArrayBlockingQueue，队列大小设置为100，未显示设置拒绝策略（默认AbortPolicy）。 12345final BlockingQueue&lt;Runnable&gt; queue = new ArrayBlockingQueue&lt;Runnable&gt;( 100);ExecutorService executor = new ThreadPoolExecutor(4, 16, 60L, TimeUnit.SECONDS, queue); 结合异常，显而易见，高tps下，线程池最大16个任务在执行，同时阻塞队列里有100个待执行任务，集群里的3台机器也无法完全处理完，使用拒绝策略，抛出异常给主线程，主线程只是记录了异常，并未做其他补偿操作，所以导致部分任务被丢弃。 治理方案 服务端：扩大了核心线程数和最大线程数，阻塞队列的大小。计算公式为： Nthreads = Ncpu * Ucpu * (1 + W / C) Ncpu为CPU数目，Ucpu为目标CPU的使用率（0~1），W/C为等待时间与计算时间的比率 后台： job跑批时，后端系统循环调用服务端接口时，设置每一次rpc接口调用里用户列表数据的大小可配置（分布式配置中心配置后实时生效） for循环批次组织用户数据调用rpc接口时，每调用一次，计算线程sleep 5秒，降低服务接口的tps job跑批方法里，加入跑批停止的开关（分布式配置中心配置后实时生效），防止异常过多时，降级掉该job 服务接口里，针对job跑批要有幂等的处理，跑完的数据实时记录跑批结果，如果job降级后再启动，防止重复推送的情况。 治理注意点 使用LinkedBlockingQueue，必须设置其队列大小，否则默认为Integer.MAX_VALUE，并发量突增时，可能会因为链队列的不停扩大，导致OOM，不仅当前的服务不可用，也使得这台机器的其他服务也因此跪了，如果tps高持续时间较长，down一台机器，压力就需要被其他机器分担，很容易导致整个集群挂了。所以ArrayBlockingQueue不需要修改，超过容量时，也仅仅是本服务丢掉了部分数据未进行推送。 123public LinkedBlockingQueue() &#123; this(Integer.MAX_VALUE);&#125; 关于LinkedBlockingQueue和ArrayBlockingQueue 数据结构：ArrayBlockingQueue采用的是数组作为数据存储容器，LinkedBlockingQueue采用的则是以Node节点作为连接对象的链表。 ArrayBlockingQueue实现的队列中的锁是没有分离的，即添加操作和移除操作采用的同一个ReenterLock锁，而LinkedBlockingQueue实现的队列中的锁是分离的，其添加采用的是putLock，移除采用的则是takeLock，这样能大大提高队列的吞吐量，也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。 1234567891011121314/** Current number of elements */private final AtomicInteger count = new AtomicInteger();/** Lock held by take, poll, etc */private final ReentrantLock takeLock = new ReentrantLock(); /** Wait queue for waiting takes */private final Condition notEmpty = takeLock.newCondition(); /** Lock held by put, offer, etc */private final ReentrantLock putLock = new ReentrantLock(); /** Wait queue for waiting puts */private final Condition notFull = putLock.newCondition(); 其他 最近正在体系化多线程的相关技术，线程池也在里面，后续会逐步整理出来。 异常二 2019-08-26 09:09:26,604|RequestTaskExecutor-thread-66531|8818a82b50c14e0386121e3eb697ef03|INFO|FacadeLogInterceptor|exit methodName:SignFacadeImpl.execute,argument:{“responseCode”:”9999”,”responseMsg”:”\\n### Error updating database. Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: mycat_error:1213,data_node:10.100.234.114,sub_tbl:CHECK_IN_DETAIL_0032,Deadlock found when trying to get lock; try restarting transaction\\n### The error may involve defaultParameterMap\\n### The error occurred while setting parameters\\n### SQL: update check_in_detail set full_sign = ‘1’, last_update_time = now() where channel_page_code = ? and user_no = ? AND datediff(sign_time,now()) = 0\\n### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: mycat_error:1213,data_node:10.100.234.114,sub_tbl:CHECK_IN_DETAIL_0032,Deadlock found when trying to get lock; try restarting transaction\\n; SQL []; mycat_error:1213,data_node:10.100.234.114,sub_tbl:CHECK_IN_DETAIL_0032,Deadlock found when trying to get lock; try restarting transaction; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: mycat_error:1213,data_node:10.100.234.114,sub_tbl:CHECK_IN_DETAIL_0032,Deadlock found when trying to get lock; try restarting transaction”} 异常解释 clientA更新某一行数据时，事务还未提交，又有一个clientB来操作同一行数据，此时clientB就会进入等待状态，直到出现Deadlock。 发生场景及分析 用户操作完补签后，如果用户已经达到了某个指标，会设置一个标志位（阶段一满签） 客户端一个用户发起了多个相同的请求时，一个请求未结束再发起一个一样的请求 正常业务场景下，一个用户只会发起一个场景，出现该场景为用户快速点击了按钮，前端未做防并发控制，导致服务端同时接收到多个请求更新同一条数据 服务端接口未做防并发请求 治理方案 客户端按钮添加防并发处理，按钮点击完未正常放回前不可点击，设置可点击超时时间。 服务端接口做好防并发方式（分布式锁方案即可） redis缓存用户id+方法，过期时间大于一次方法执行的最大时间 setNx + expire（保证两个方法的原子性） 其他 分布式锁相关还在整理中。 其他问题 Mycat 问题 Mycat的默认情况下，如果代码里面开启的事务，Mycat如介入事务管理。如果代码里面出现数据库异常，Mycat就会认为事务需要rollback，但是如果此时我们catch掉该异常希望继续提交其他数据库事务操作（比如部分非重要操作，为了不影响主流程执行），Mycat会拒绝commit请求，此刻事务就处于未提交也未回滚的状态，会对其他数据库操作造成持续异常。 解决方案：关闭Mycat介入事务 1&lt;property name=&quot;txInterruptByMycat&quot;&gt;false&lt;/property&gt;","categories":[{"name":"问题记录","slug":"问题记录","permalink":"https://moon-zhou.github.io/categories/问题记录/"}],"tags":[]},{"title":"【朝花再拾】AOP-01","slug":"【朝花再拾】AOP-01","date":"2019-08-25T04:07:34.000Z","updated":"2019-09-08T07:52:39.237Z","comments":true,"path":"2019/08/25/【朝花再拾】AOP-01/","link":"","permalink":"https://moon-zhou.github.io/2019/08/25/【朝花再拾】AOP-01/","excerpt":"如果无法正确查看流程图， 点击传送门 背景最近在重新整理spring知识结构，从Springboot入手，在自定日志打印时，使用aop进行的处理。(详情见上一篇日志) 同时最近项目组招聘小伙伴时，问到过spring aop的相关问题。 因此觉得有必要由浅入深，把以前学习的落到文档上，方便自己的回顾，也便于传播。","text":"如果无法正确查看流程图， 点击传送门 背景最近在重新整理spring知识结构，从Springboot入手，在自定日志打印时，使用aop进行的处理。(详情见上一篇日志) 同时最近项目组招聘小伙伴时，问到过spring aop的相关问题。 因此觉得有必要由浅入深，把以前学习的落到文档上，方便自己的回顾，也便于传播。 AOP编程思考 通常使用java进行面向对象编程时，代码的执行都是按照时间序列纵向展开的（运行）：以方法调用作为基本执行单位展开的，将方法调用作为一个连接点，由连接点串起来的程序执行流程就是整个程序的执行过程。（每个方法运行时都会创建一个栈帧） aop与传统编程思维不同，它将每一个方法调用，即连接点作为编程的入口，针对方法进行编程。从执行的逻辑上来看，相当于在之前纵向的按照时间轴执行的程序横向切入。相当于将之前的程序横向切割成若干的面，即Aspect.每个面被称为切面。 AOP本质上是针对方法调用的编程思路。 AOP的产生方法的鉴权，打印方法的运行时间，传统的数据库操作方法（获取链接-&gt;执行sql-&gt;获取结果-&gt;提交事务-&gt;获取结果），这些场景里，需要针对方法做一些共性的操作，因此与aop编程思想十分契合。利用aop抽取方法的共性操作，方法本身无需关注，只需要关注自身的业务逻辑。 AOP的实现方式 静态代理：aspect 动态代理：JDK/cglib/Javassist/ASM 图解： 12345graph LR调用方--&gt;代理对象代理对象--&gt; 调用方代理对象--&gt;目标执行方法目标执行方法--&gt;代理对象 静态代理 含义 代理类通过实现与目标对象相同的接口，并在类中维护一个代理对象。通过构造器塞入目标对象，赋值给代理对象，进而执行代理对象实现的接口方法，并实现前拦截，后拦截等所需的业务功能。 优点：可以做到不对目标对象进行修改的前提下，对目标对象进行功能的扩展和拦截。(代理类的扩展本身就是业务逻辑的扩展，无需解耦或者某种程度说已经解耦) 缺点：因为代理对象，需要实现与目标对象一样的接口，会导致代理类十分繁多，不易维护，同时一旦接口增加方法，则目标对象和代理类都需要维护。 show github: 实现 测试 动态代理 因为静态代理可能会产生代理类的“爆炸”，是不是有什么方案可以不要写太多的代理类，因而引出动态代理： 框架不会去修改字节码，而是在内存中临时为方法生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。 JDK方式 在jdk1.3以后，jdk跟我们提供了一个API java.lang.reflect.InvocationHandler的类， 这个类可以让我们在JVM调用某个类的方法时动态的为些方法做些什么事。 版本1 思想：将目标执行的对象传入代理对象中，通过反射机制来执行目标对象的方法 实现 测试 版本2 思想：版本1里，代理时需要做的业务，在代理对象里完成的。因此需要将代理时的业务与代理本身进行解耦 实现 测试 缺点：在实际开发中，可能需要对没有实现接口的类（普通类）增强，用JDK动态代理的方式就没法实现。 cglib 介绍 cglib是一个开源库 在运行期扩展Java类与实现Java接口(Hibernate用它来实现ersistent Object 持久化对象的字节码的动态生成、Spring AOP框架) CGLIB包的底层是通过使用一个小而快的字节码处理框架ASM，来转换字节码并生成新的类。 使用步骤 通过cglib动态代理获取代理对象Enhancer过程（类比Proxy） 设置业务逻辑处理类 设置回调对象，即执行intercept方法（拦截） 创建代理对象，与业务类相同，直接运行代理类的业务逻辑处理方法 V1版本核心：详情/测试 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * sub：cglib生成的代理对象 * method：被代理对象方法 * args：方法入参 * methodProxy: 代理方法 */@Overridepublic Object intercept(Object sub, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; // 可优化，见V2 System.out.println(&quot;cglib proxy before method...&quot;); Object result = methodProxy.invokeSuper(sub, args); // 可优化，见V2 System.out.println(&quot;cglib proxy after method...&quot;); return result;&#125;@Testpublic void testRun() &#123; // 代理类class文件存入本地磁盘方便我们反编译查看源码 Properties sourceCodePath = new Properties(); sourceCodePath.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, &quot;E:\\\\TestCode\\\\cglib\\\\v1&quot;); System.setProperties(sourceCodePath); // 通过cglib动态代理获取代理对象过程(类比JDK动态代理里的Proxy，但Enhancer更强大，既可以代理接口，也可以代理普通类，但不能拦截final方法) Enhancer enhancer = new Enhancer(); // 设置enhancer对象的父类，即业务类(需要被代理的类) enhancer.setSuperclass(CommonBiz.class); // 设置enhancer的回调对象 enhancer.setCallback(new CglibProxyV1()); // 创建代理对象 CommonBiz commonBizProxy = (CommonBiz) enhancer.create(); // 通过代理对象调用目标方法 commonBizProxy.execute();&#125; 与jdk动态代理的第一个版本类似，代理的处理业务逻辑需要与代理本身解耦，因此引出第二个版本 业务处理和代理处理逻辑都动态传入 intercept拦截处理业务逻辑，处理之前/之后的部分通过反射，先处理代理业务 核心代码：详情/测试 12345678910111213141516171819/** * sub：cglib生成的代理对象 * method：被代理对象方法 * args：方法入参 * methodProxy: 代理方法 */@Overridepublic Object intercept(Object sub, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; before(method); Object result; try &#123; result = methodProxy.invokeSuper(sub, args); &#125; finally &#123; after(method); &#125; return result;&#125; 参考 https://blog.csdn.net/weianluo/article/details/81607134 https://www.cnblogs.com/qf123/p/8671479.html https://blog.csdn.net/yhl_jxy/article/details/80633194","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://moon-zhou.github.io/categories/JAVA/"}],"tags":[]},{"title":"SB日志打印","slug":"SB日志打印","date":"2019-08-22T15:23:34.000Z","updated":"2019-09-08T07:52:01.935Z","comments":true,"path":"2019/08/22/SB日志打印/","link":"","permalink":"https://moon-zhou.github.io/2019/08/22/SB日志打印/","excerpt":"背景1. 为方便问题定位，每一次请求最好可以通过唯一的标识来串起每一个单独打印的日志 2. 正常的业务需求在sb框架里进行各业务逻辑层的拆分，传统的mvc分层，以及义务自定义的一些分层处理。因此公共的各层出入参需要打印且脱敏。","text":"背景1. 为方便问题定位，每一次请求最好可以通过唯一的标识来串起每一个单独打印的日志 2. 正常的业务需求在sb框架里进行各业务逻辑层的拆分，传统的mvc分层，以及义务自定义的一些分层处理。因此公共的各层出入参需要打印且脱敏。 请求日志连接方案 针对每一个controller请求，请求进入之前，设置唯一随机值，请求结束，删除该随机值。 使用logback提供的MDC扩展，设置每一次请求的invokeNo（“线程号”） 每一次通过logger.info输出日志的时候，都带上这个随机值。 show your myHub sb里实现拦截器HandlerInterceptor，设置线程号 https://github.com/moon-zhou/SpringBoot_Backend_Modules/blob/master/backend-base-web/src/main/java/org/moonzhou/backend/base/web/interceptor/CommonInterceptor.java sb注册上拦截器 https://github.com/moon-zhou/SpringBoot_Backend_Modules/blob/master/backend-base-web/src/main/java/org/moonzhou/backend/base/web/config/WebMvcConfig.java 配置logback，日志输出格式里添加上线程号的参数 https://github.com/moon-zhou/SpringBoot_Backend_Modules/blob/master/backend-base-war/src/main/resources/logback-spring.xml 1[%X&#123;invokeNo&#125;] 分层日志打印方案 统一的各层拦截，标准日志输出 利用aop，针对各层特定的路径配置环绕通知 1234567891011121314/** * 切入点描述 这个是controller包的切入点 */@Pointcut(&quot;execution(public * org.moonzhou.backend.base.web.controller..*.*(..))&quot;)public void controllerLog() &#123;&#125;//签名，可以理解成这个切入点的一个名称/** * 环绕增强，相当于MethodInterceptor * 环绕controller */@Around(&quot;controllerLog()&quot;)public Object aroundController(ProceedingJoinPoint joinPoint) throws Throwable &#123;&#125; logback里配置分层日志的loggerName 12345&lt;logger name=&quot;ControllerLogger&quot; level=&quot;$&#123;monitor.log.level&#125;&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;CONTROLLER_APPENDER&quot; /&gt;&lt;/logger&gt;private static final Logger SERVICE_LOGGER = LoggerFactory.getLogger(&quot;ControllerLogger&quot;); 脱敏输出出入参 详情见LogAspect.java和logback-spring.xml：https://github.com/moon-zhou/SpringBoot_Backend_Modules 日志异步化 保持原有的append生成文件及backup规则 再配置异步化append，依赖原有的append 使用异步化的append 异步日志打印时，日志格式里的class和method以及line是无法正常打印的1234567891011121314151617181920212223242526272829303132333435&lt;!-- 时间滚动输出 level为 ERROR 日志 --&gt;&lt;appender name=&quot;ERROR_FILE_APPENDER&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 正在记录的日志文件的路径及文件名 --&gt; &lt;file&gt;$&#123;log.path&#125;/log_error.log&lt;/file&gt; &lt;!--日志文件输出格式--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] [%class] [%method] [%line] [%X&#123;invokeNo&#125;] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- 日志记录器的滚动策略，按日期，按大小记录 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;log.path&#125;/error/log-error-%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt;constants &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;!--日志文件保留天数--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 此日志文件只记录ERROR级别的 --&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt;&lt;/appender&gt;&lt;!-- error日志异步化 --&gt;&lt;appender name=&quot;ERROR_ASYNC_FILE_APPENDER&quot; class=&quot;ch.qos.logback.classic.AsyncAppender&quot;&gt; &lt;!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --&gt; &lt;discardingThreshold&gt;0&lt;/discardingThreshold&gt; &lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为256 --&gt; &lt;queueSize&gt;10240&lt;/queueSize&gt; &lt;!-- 添加附加的appender,最多只能添加一个 --&gt; &lt;appender-ref ref=&quot;ERROR_FILE_APPENDER&quot; /&gt;&lt;/appender&gt; 自定义注解，针对某些方法，灵活的添加日志 自定义日志注解 编写aop拦截类，将自定义注解作为切点条件，拦截规则里，针对切点做实际的日志输出处理 使用method log annotation，放到具体的类上进行测试。 详情见MethodLog及AnnotationLogAspect：https://github.com/moon-zhou/SpringBoot_Backend_Modules 问题：如果方法上已经被aop增强调用了，则该方法下再去调用的方法，加上自定义日志注解是不会生效（类似问题） 1234567891011121314151617181920212223242526/** * 测试注解日志请求 * controller上直接使用MethodLog是始终都会生效的 * http://localhost:8881/backend-base/hello/testAnnotationLog.do * @return */@MethodLog(operationType = &quot;testType&quot;, operationName = &quot;testUser&quot;, description = &quot;测试注解日志&quot;)@RequestMapping(&quot;/testAnnotationLog&quot; + SystemConstants.REQUEST_SUFFIX)@ResponseBodypublic BaseDto testAnnotationLog() &#123; // 这个使用的是spring上下文里的对象去调用initReturn方法，所以initReturn方法上的methodLog注解会被AnnotationLogAspect的规则拦截 return BeanUtil.getBean(this.getClass()).initReturn(); // 此处调用方法，已经被拦截处理过，即被动态代理拦截了，再直接调用别的方法，是通过代理对象调用的，方法是不会被增强的，即initReturn方法上注解不会生效 // return initReturn();&#125; /** * 测试注解日志打印 * @return */@MethodLog(operationType = &quot;init&quot;, operationName = &quot;testUser&quot;, description = &quot;初始化controller返回值&quot;)public BaseDto initReturn() &#123; return new BaseDto();&#125;","categories":[{"name":"SpringBoot2.X","slug":"SpringBoot2-X","permalink":"https://moon-zhou.github.io/categories/SpringBoot2-X/"}],"tags":[]},{"title":"【反思录】19年7月的一点思考","slug":"【反思录】19年7月的一点思考","date":"2019-08-13T08:56:34.000Z","updated":"2019-09-08T07:52:34.657Z","comments":true,"path":"2019/08/13/【反思录】19年7月的一点思考/","link":"","permalink":"https://moon-zhou.github.io/2019/08/13/【反思录】19年7月的一点思考/","excerpt":"从六月底开始，接到原始需求，要开发一个关于签到的项目。 项目从零开始，主要从会员中台偏向门户的开发组和多活项目组各抽调2人，组成4人开发小组，加上领导作为架构的角色加入，总共4.5人的开发小组成立。","text":"从六月底开始，接到原始需求，要开发一个关于签到的项目。 项目从零开始，主要从会员中台偏向门户的开发组和多活项目组各抽调2人，组成4人开发小组，加上领导作为架构的角色加入，总共4.5人的开发小组成立。 前期架构拆解需求功能，非核心功能，已有系统已经具备的能力，通通拆解出去，明确好各个系统的职责。经过大小数次的讨论，最终明确签到系统核心做签到处理，签到奖励通过任务平台系统进行规则触发，调用礼包/券等系统进行发放等（详情见《签到类需求的设计与思考》)）。这个过程完全体现除了架构的各方面能力，现有系统的业务理解，系统的边界电仪，沟通能力，业务抽象和拆解的能力。按领导的话说就是无非是待的时间长一点，见得多一点。举重若轻。 在系统边界定义的“漫长”过程中，大家一方面分析需求，讨论细节，完善开发设计方案。这也是一个挺痛苦的过程。之所以有这个感受，来源于之前的开发方式。作为会员中台的开发，开发的东西在业务层面来看还是相对来说比较靠底层的服务。所以以往的需求，拆解到我们这里的时候，基本已经成型了，基本上该明确的地方都已经明确了。因此还诞生了一个现象，开发的设计文档里，经常出现产品需求里的段落文字描述，有点量还不少（撇去开发设计文档偷懒的因素）。所以这一次接到的更靠近用户侧的需求时，没有了以往的那种舒适感。 除了业务的划分，系统的级别评估，规划也在架构的带领下进行着评估。 以上基本完成了前期的准备工作。 终于到了动手的时候，前端、服务端、后端搭建系统环境，编码，自测，联调，转测。本以为会平稳的按部就班的时候，总有些意外不期而至。 第一个问题出现在我负责的会员门户相关系统里，wap端有部分功能在易购app里被使用了，这部分需要进行安全改造。梳理涉及敏感信息的功能，表单/ajax提交时，参数都需要进行加密传输，711刚刚结束业务版本，714就得上线。为此我分出接近2天时间投入，周六配合测试全场景覆盖，定位和分析问题，因为wap也属于半前后端分离，且前端人力不够，周六只有我一人配合，整个过程也是非常繁忙，好在加密方案的实施没有什么问题，仅仅是场景的遗漏。周日小伙伴继续接力修改漏洞及上线发布。上线发布的过程也出现了一个bug，解版进行解决。这个改造也算是有惊无险的解决了。 没过两天，第二个问题又来了。fastjson低版本安全漏洞，需要进行升级，门户类系统优先，718之前完成。刚刚着手改完升级的jar包，给测试写完测试建议，又有摄像头使用权限提示的改造，所以统一压缩到一个版本，718发布。 期间的业务需求也随之往后，静默视频，一键绑卡等等等等。当然安全改造涉及金服所有系统，签到的下游系统开发所属系统也在改造之列，整体签到计划（联调、转测）往后移两天。这也为后面节奏的失控，埋下了一个小隐患。 除了涉及安全的紧急版本之外，另一个就是系统多活改造的项目了。没有签到项目的时候，也没有排正规的开发计划，都是我带着做。新项目来了，只能领到协调小伙伴来进行改造了，测试环境搭建和代码改造分别找了两个小伙伴在之前进度的基础上继续进行。因为人力的问题，这个过程有一个小伙伴离开，另一个小伙伴需要进行系统的交接，所以，两个小伙伴基本完成工作之后，又没有人投入。这时候领导只能将外部支援小伙伴协调回来，继续完成后续的测试环境的多活演练。这个期间，我也是基本上投入20%。 到七月中下旬的时候，也就是718之后，业务版本需求的堆积，协调回来做多活的小伙伴被分配到业务版本需求里，后续的演练和生产多活环境的搭建，都交由另外专门负责的小伙伴完成。其实从前面也可以看出，演练还是我们在配合，分析各种问题等等等，后续的生产上线估计还得接着投入。期间人力的多次变动，虽然划分明确了各自的任务，但实施的时候，真的能够像如理想中一样吗？肯定不是，别人不熟悉你的系统，你得说明系统的架构，代码结构，业务。尤其是前后人力变更太大，原先预估的投入最多10%，现在投入至少有25%。这必然影响新系统的开发。 新系统里担任技术经理和开发的角色，大致的职责就是控制好开发的进度，协调好各方问题的解决。然而，期间核心开发预估百分百投入，却因为客观原因需要频繁请假，基本上投入了60%，这也就造成了开发过程的最大风险。怎么办小伙伴内部消化，分别看他实现的功能，配合前端联调，下游rpc接口联调等等。内部消化了了怎么办，还是有交付风险，那就周末加班了。 因为系统的定位是签到系统，中心这个领域只有这一个系统，原先的签到只是固化在app里的一个功能，没有实现拆分。因此当会员中心签到需要改版时，相关后端服务接口自然而然就落在了我们系统了。且这部分开发人力没有在最初的工作计划里体现，且提出时，基本已经到了转测的时间。怎么办，协调人力，加班消化。 伴随着增加的工作计划，二期需求的如约而至，正常签到完之后，还需要有补签的功能，因为涉及到补签卡系统，需求发布时间不一致问题，整体的联调测试比一期往后延一个礼拜。因为前期本身工作的繁杂，原系统的问题，多活，新系统开发，小伙伴请假功能的配合联调，会员中心签到需求等等，导致二期补签工作联调延后，部分功能遗漏，需求变更没有及时关注等等。 刚刚加完班，把补签，新需求都开发自测完成。还有部分的分布式job实现，待下周继续。 总结如下： 人力永远都是一个问题。 缺乏备份小伙伴，bus factor风险很高。 在第二点的基础上，会造成临时组成的开发小组，小伙伴永远不可能理想型的完全投入，没有备份的前提下，需要花费相当的时间配合定位各种测试和生产，门户类系统尤为突出，直面用户，流量入口，也是问题入口。所以实际投入新系统开发时间不够只能自己消化。 临时组件团队开发的风险识别意识尤其要强，本身就存在磨合问题，小伙伴自身的问题要及时暴露。 带头人还是需要强势一点。 多任务交叉的时候，及时拆解，划分好相关责任人。 精益项目里也说过，开发担任项目经理角色没有测试，或者产品更合适，因为后两者更关注整体进度与质量（有专门项目经理的除外）。新系统是标准型项目，项目经理在这个过程中协调解决问题，消减了很大一部分的风险。专业的人做专业的事。 人力-计划-工作量-质量，需要维持好一个平衡。最后如果总需要各方来内部消化的话，肯定是有问题的。 当计划推着你不停往前赶的时候，难免会出现技术债，其实我们已经出现了。","categories":[{"name":"总结反思录","slug":"总结反思录","permalink":"https://moon-zhou.github.io/categories/总结反思录/"}],"tags":[]},{"title":"【奇技淫巧】SB里数据层的拓展及小技巧","slug":"【奇技淫巧】SB里数据层的拓展及小技巧","date":"2019-08-13T08:56:34.000Z","updated":"2019-09-08T07:52:32.317Z","comments":true,"path":"2019/08/13/【奇技淫巧】SB里数据层的拓展及小技巧/","link":"","permalink":"https://moon-zhou.github.io/2019/08/13/【奇技淫巧】SB里数据层的拓展及小技巧/","excerpt":"背景 JavaWeb里，基础的不复杂的业务系统，ORM框架通常都是直接使用。本文介绍数据层的扩展和小技巧。","text":"背景 JavaWeb里，基础的不复杂的业务系统，ORM框架通常都是直接使用。本文介绍数据层的扩展和小技巧。 mybatis generator 父pom里添加构建plugin管理，pluginManagement-plugins-plugin，添加mybatis-generator-maven-plugin（注意添加依赖的jar包，否则会报错），配置好generatorConfig.xml路径 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;build&gt; &lt;finalName&gt;XXX-$&#123;maven.build.timestamp&#125;&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources/config/$&#123;envName&#125;/&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;$&#123;java.version&#125;&lt;/source&gt; &lt;target&gt;$&#123;java.version&#125;&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.suning.epp.member.fmsms.admin.FmsmsAdminWebApplication&lt;/mainClass&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;configuration&gt; &lt;configurationFile&gt;$&#123;project.basedir&#125;/src/main/resources/mybatis/generatorConfig.xml&lt;/configurationFile&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;Generate MyBatis Artifacts&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.46&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt;&lt;/build&gt; dao子模块里使用该plugin 12345678910111213141516171819202122232425 &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;*/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 配置generatorConfig.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt;&lt;!-- 配置生成器 --&gt;&lt;generatorConfiguration&gt; &lt;!-- 一个数据库一个context --&gt; &lt;!--defaultModelType=&quot;flat&quot; 大数据字段，不分表 --&gt; &lt;context id=&quot;MysqlTables&quot; targetRuntime=&quot;MyBatis3Simple&quot; defaultModelType=&quot;flat&quot;&gt; &lt;!-- 自动识别数据库关键字，默认false，如果设置为true，根据SqlReservedWords中定义的关键字列表； 一般保留默认值，遇到数据库关键字（Java关键字），使用columnOverride覆盖 --&gt; &lt;property name=&quot;autoDelimitKeywords&quot; value=&quot;true&quot;/&gt; &lt;!-- 生成的Java文件的编码 --&gt; &lt;property name=&quot;javaFileEncoding&quot; value=&quot;utf-8&quot;/&gt; &lt;!-- beginningDelimiter和endingDelimiter：指明数据库的用于标记数据库对象名的符号，比如ORACLE就是双引号，MYSQL默认是`反引号； --&gt; &lt;!-- &lt;property name=&quot;beginningDelimiter&quot; value=&quot;`&quot; /&gt; &lt;property name=&quot;endingDelimiter&quot; value=&quot;`&quot; /&gt; --&gt; &lt;!-- 格式化java代码 --&gt; &lt;property name=&quot;javaFormatter&quot; value=&quot;org.mybatis.generator.api.dom.DefaultJavaFormatter&quot;/&gt; &lt;!-- 格式化XML代码 --&gt; &lt;property name=&quot;xmlFormatter&quot; value=&quot;org.mybatis.generator.api.dom.DefaultXmlFormatter&quot;/&gt; &lt;plugin type=&quot;org.mybatis.generator.plugins.SerializablePlugin&quot;/&gt; &lt;plugin type=&quot;org.mybatis.generator.plugins.ToStringPlugin&quot;/&gt; &lt;!-- 注释 --&gt; &lt;commentGenerator&gt; &lt;property name=&quot;suppressAllComments&quot; value=&quot;true&quot;/&gt;&lt;!-- 是否取消注释 --&gt; &lt;property name=&quot;suppressDate&quot; value=&quot;true&quot;/&gt; &lt;!-- 是否生成注释代时间戳--&gt; &lt;/commentGenerator&gt; &lt;!--数据库链接地址账号密码--&gt; &lt;jdbcConnection driverClass=&quot;com.mysql.jdbc.Driver&quot; connectionURL=&quot;jdbc:mysql://10.243.59.148:3306/fmsmssit?serverTimezone=UTC&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf-8&quot; userId=&quot;fabu&quot; password=&quot;cp1Y1Aa0E4Oo&quot;&gt; &lt;/jdbcConnection&gt; &lt;javaTypeResolver&gt; &lt;property name=&quot;forceBigDecimals&quot; value=&quot;false&quot;/&gt; &lt;/javaTypeResolver&gt; &lt;!--生成Model类存放位置--&gt; &lt;javaModelGenerator targetPackage=&quot;com.suning.epp.member.fmsms.admin.dmo&quot; targetProject=&quot;src/main/java&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;trimStrings&quot; value=&quot;true&quot;/&gt; &lt;/javaModelGenerator&gt; &lt;!--生成映射文件存放位置--&gt; &lt;sqlMapGenerator targetPackage=&quot;mybatis.mapper&quot; targetProject=&quot;src/main/resources&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt; &lt;/sqlMapGenerator&gt; &lt;!--生成Dao类存放位置--&gt; &lt;!-- 客户端代码，生成易于使用的针对Model对象和XML配置文件 的代码 type=&quot;ANNOTATEDMAPPER&quot;,生成Java Model 和基于注解的Mapper对象 type=&quot;MIXEDMAPPER&quot;,生成基于注解的Java Model 和相应的Mapper对象 type=&quot;XMLMAPPER&quot;,生成SQLMap XML文件和独立的Mapper接口 --&gt; &lt;javaClientGenerator type=&quot;XMLMAPPER&quot; targetPackage=&quot;com.suning.epp.member.fmsms.admin.dao&quot; targetProject=&quot;src/main/java&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt; &lt;/javaClientGenerator&gt; &lt;!--生成对应表及类名--&gt; &lt;table tableName=&quot;pit_manage&quot; domainObjectName=&quot;PitManage&quot; enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;true&quot; enableDeleteByExample=&quot;true&quot; enableSelectByExample=&quot;true&quot; selectByExampleQueryId=&quot;true&quot;&gt;&lt;/table&gt; &lt;table tableName=&quot;operation_record&quot; domainObjectName=&quot;OperationRecord&quot; enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;true&quot; enableDeleteByExample=&quot;true&quot; enableSelectByExample=&quot;true&quot; selectByExampleQueryId=&quot;true&quot;&gt;&lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; IDEA里打开Maven Project视图，打开dao模块下的Plugins，即可看见mybatis-generator，双击执行mybatis-generator:generate 不同版本的SB，子模块引入plugin时，可能有的还需要配置resources，根据执行时候的实际情况，报错信息解决即可。 配置执行sql打印 在application.yml中添加下面配置，可以显示执行的sql语句 123logging: level: com.xxx.xxx.dao : debug 配置logback 1&lt;logger name=&quot;com.apache.ibatis&quot; level=&quot;debug&quot;/&gt; mybatis-plus 引入依赖(父pom进行管理，dao使用时引入) 123456 &lt;!-- https://mvnrepository.com/artifact/com.baomidou/mybatis-plus-boot-starter --&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-plus-boot-starter.version&#125;&lt;/version&gt;&lt;/dependency&gt; 修改yml配置 123456789#mybatis配置mybatis: mapper-locations: classpath*:mybatis/mapper/*Mapper.xml type-aliases-package: org.moonzhou.backend.base.dmo#mybatis-plus配置，仅一行不同mybatis-plus: mapper-locations: classpath*:mybatis/mapper/*Mapper.xml type-aliases-package: org.moonzhou.backend.base.dmo mybatis generator无法使用，只能使用mybatis-plus提供的generator 引入jar包 12345 &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-plus-generator.version&#125;&lt;/version&gt;&lt;/dependency&gt; 代码修改相关配置 详细参考：https://github.com/moon-zhou/SpringBoot_Backend_Modules/blob/master/backend-base-dao/src/test/java/org/moonzhou/backend/base/dmo/MybatisPlusGeneratorTest.java mybatis-plus分页（此处demo为手写sql的方式） mapper里，分页查询接口使用IPage page作为分页的条件 初始化时设置current和size 底层sql只需要关注原有的查询参数即可 selectUserByPageVo方法：https://github.com/moon-zhou/SpringBoot_Backend_Modules/blob/master/backend-base-dao/src/main/java/org/moonzhou/backend/base/dao/mapper/UserMapper.java 多数据源的配置【TODO】 通过druid进行多数据源配置 通过sharding-jdbc进行多数据源的配置 通过360的Atlas实现Mysql的读写分离 代码示例 mybatis-generator示例github地址：https://github.com/moon-zhou/SpringBoot_Backend_Modules.git 参考 https://mp.baomidou.com/guide/page.html","categories":[{"name":"SpringBoot2.X","slug":"SpringBoot2-X","permalink":"https://moon-zhou.github.io/categories/SpringBoot2-X/"}],"tags":[]},{"title":"Maven中jar依赖冲突解决","slug":"Maven中jar依赖冲突解决","date":"2019-08-13T08:43:34.000Z","updated":"2019-09-08T07:52:08.613Z","comments":true,"path":"2019/08/13/Maven中jar依赖冲突解决/","link":"","permalink":"https://moon-zhou.github.io/2019/08/13/Maven中jar依赖冲突解决/","excerpt":"背景最近开了一个新系统开发，其中需要有个定时推送的业务，调用推送系统给手机推送相关消息。再接入推送系统的时候始终无法成功。","text":"背景最近开了一个新系统开发，其中需要有个定时推送的业务，调用推送系统给手机推送相关消息。再接入推送系统的时候始终无法成功。 分析与解决 推送系统以消息队列的方式对外提供服务（公司内部基于spring的jms开发的消息队列中间件），接入队列的过程中，提示始终无法创建队列的连接。 反馈相关错误给中间件系统，反馈是查下相关jar的版本。 排查过程中，发现依赖的消息队列的jar包有两个，一个时低版本，一个是高版本，初步怀疑是jar包冲突。 确认jar包冲突 下载maven构建的工程，确认最终打包里的依赖jar包版本，发现版本是较低的那个 从现有接入成功的项目工程里，发现是依赖的高版本jar包，99%确认 进行低版本排包 使用的idea（eclipse类似，dependency hierarchy视图） 多模块工程里，确认明确引入jar包的module 在该module下，打开依赖jar包视图：Ctrl+Alt+Shift+U或者打开View–&gt;Tool Windows–&gt;Maven Projects–&gt;Show Dependency，或者pom.xml右键Diagram–&gt;show dependency Ctrl+F查找jar包，确认该module下jar版本是否正常 确认该module下jar包是正常的，100%确认有其他jar包也依赖了spring的jms，逐个排查每一个module。重复第三第四步。 最后找到在相关module的依赖视图里找到了该jar的上游依赖 在上游依赖的jar包里spring的jms排掉即可 123456&lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;&lt;/groupId&gt; &lt;artifactId&gt;&lt;/artifactId&gt; &lt;/exclusion&gt;&lt;/exclusions&gt; 验证 重新maven构建整个项目，在最后的war里确认最终的jar包版本，正常 重新发布，验证相关功能正常 意外 社区版是没有show dependency，使用mvn dependency:tree，查看各jar的依赖关系。","categories":[{"name":"Maven","slug":"Maven","permalink":"https://moon-zhou.github.io/categories/Maven/"},{"name":"问题记录","slug":"Maven/问题记录","permalink":"https://moon-zhou.github.io/categories/Maven/问题记录/"}],"tags":[]},{"title":"sb2.0统一错误页面","slug":"sb2.0统一错误页面","date":"2019-08-13T08:43:34.000Z","updated":"2019-09-08T07:52:06.597Z","comments":true,"path":"2019/08/13/sb2.0统一错误页面/","link":"","permalink":"https://moon-zhou.github.io/2019/08/13/sb2.0统一错误页面/","excerpt":"背景调试mybatis-plus分页时，500错误，直接显示了原有的报错页。","text":"背景调试mybatis-plus分页时，500错误，直接显示了原有的报错页。 实操步骤 重写错误跳转 12345678910111213141516171819@Configurationpublic class ErrorConfigurar &#123; /** * SpringBoot2.0以上版本WebServerFactoryCustomizer代替之前版本的EmbeddedWebServerFactoryCustomizerAutoConfiguration * * @return */ //@Bean必须加上 @Bean public WebServerFactoryCustomizer&lt;ConfigurableWebServerFactory&gt; webServerFactoryCustomizer() &#123; //第二种写法：java8 lambda写法 return (factory -&gt; &#123; ErrorPage errorPage404 = new ErrorPage(HttpStatus.NOT_FOUND, &quot;/error.do&quot;); ErrorPage errorPage500 = new ErrorPage(HttpStatus.INTERNAL_SERVER_ERROR, &quot;/error.do&quot;); factory.addErrorPages(errorPage404, errorPage500); &#125;); &#125;&#125; 自定义错误跳转（普通controller，用于给第一步跳转） https://github.com/moon-zhou/SpringBoot_Backend_Modules/blob/master/backend-base-web/src/main/java/org/moonzhou/backend/base/web/controller/MyErrorController.java 编写第二步里的相关页面 https://github.com/moon-zhou/SpringBoot_Backend_Modules/tree/master/backend-base-war/src/main/webapp/templates/error","categories":[{"name":"SpringBoot2.X","slug":"SpringBoot2-X","permalink":"https://moon-zhou.github.io/categories/SpringBoot2-X/"}],"tags":[]},{"title":"sb里正确使用logback的姿势","slug":"sb里正确使用logback的姿势","date":"2019-08-13T06:06:34.000Z","updated":"2019-09-08T07:52:04.398Z","comments":true,"path":"2019/08/13/sb里正确使用logback的姿势/","link":"","permalink":"https://moon-zhou.github.io/2019/08/13/sb里正确使用logback的姿势/","excerpt":"背景springboot里查看测试代码逻辑时，需要打印日志信息进行分析。","text":"背景springboot里查看测试代码逻辑时，需要打印日志信息进行分析。 实操步骤 因为Springboot已经引入了常用日志框架，logback，log4j，slf4j。所以无需再引入依赖，直接上手配置即可。（pom文件里，点击spring-boot-starter，进入starter的相关依赖xml，找到spring-boot-starter-logging，点击进入即可看到相关依赖） Spring Boot uses Commons Logging for all internal logging but leaves the underlying log implementation open. Default configurations are provided for Java Util Logging, Log4J2, and Logback. In each case, loggers are pre-configured to use console output with optional file output also available. By default, if you use the “Starters”, Logback is used for logging. Appropriate Logback routing is also included to ensure that dependent libraries that use Java Util Logging, Commons Logging, Log4J, or SLF4J all work correctly. from 官方api:https://docs.spring.io/spring-boot/docs/2.1.7.RELEASE/reference/html/boot-features-logging.html#boot-features-logging-format 可以直接使用spring里的配置，也可以自定义使用。 使用spring里的配置 12345logging: level: org.moonzhou.backend.base.dao: debug org.moonzhou.backend.base.web.controller: warm file: logs/spring-boot-logging.log 自定义 application.yml添加如下配置 1logging.config=classpath:logback-spring.xml classpath下添加相关配置 https://github.com/moon-zhou/SpringBoot_Backend_Modules/blob/master/backend-base-war/src/main/resources/logback-spring.xml logback配置xml里配置注意各个输出日志的文件级别 以上的配置里是固定的输出文件，更加灵活的特殊文件输出可使用logger进行配置，比如特殊的监控日志需要额外的打印到专有的监控文件，以便接入其他统计系统里【TODO-各层业务层监控日志及自定义日志】 测试 https://github.com/moon-zhou/SpringBoot_Backend_Modules/blob/master/backend-base-web/src/main/java/org/moonzhou/backend/base/web/controller/HelloController.java","categories":[{"name":"SpringBoot2.X","slug":"SpringBoot2-X","permalink":"https://moon-zhou.github.io/categories/SpringBoot2-X/"}],"tags":[]},{"title":"签到类需求的设计与思考","slug":"签到类需求的设计与思考","date":"2019-08-12T15:23:34.000Z","updated":"2019-09-08T07:51:43.829Z","comments":true,"path":"2019/08/12/签到类需求的设计与思考/","link":"","permalink":"https://moon-zhou.github.io/2019/08/12/签到类需求的设计与思考/","excerpt":"背景6月底，所在会员研发中心接到原始需求，需要针对特定的频道开发签到功能。 基本要求： 1. 各频道签到页面可以动态配置 2. 各频道签到规则可不一致 3. 签到有每日奖品及累计奖品发放 4. 周期内可以通过补签卡进行补签 5. 补签和签到效果一致，发放对应奖品","text":"背景6月底，所在会员研发中心接到原始需求，需要针对特定的频道开发签到功能。 基本要求： 1. 各频道签到页面可以动态配置 2. 各频道签到规则可不一致 3. 签到有每日奖品及累计奖品发放 4. 周期内可以通过补签卡进行补签 5. 补签和签到效果一致，发放对应奖品 前期需求的讨论 动态配置页面的实现 了解现有的内容配置系统，看是否满足要求 确认现有内容管理不能完全满足，内容系统制管理内容 需要一个布局系统，整合内容管理的展示 签到奖励是通过谁来发送（功能落到哪个系统） 签到数据在签到系统 rpc调用任务平台发送签到奖励和补签奖励 补签卡的发放和使用 完成相关任务，不是直接调用券系统进行发放，而是通过任务平台–》礼包系统–》券系统 补签用卡 直接调用券系统 架构设计 后台配置管理系统 布局管理（和内容管理系统有关） 独立的文案配置（本质上也可以放到内容管理系统，但产品认为配置的任务文案，方便统一查看） 签到信息的查询和导出 补偿数据的查询 分布式job的实现：用户配置推送信息的job（上一篇全表扫描），补偿数据的job 服务系统的设计 开放签到等相关接口的rpc服务 rpc接口不局限于用户操作业务相关的，还包含job服务相关接口 通过网关进行包装 rpc只能是系统内网之间的通信服务，外部小程序或者H5只能通过http进行访问，需要金融网关对其进行一层包装，将rpc接口转换为http接口。 后端系统功能 整体采用springboot，包含两个代码库：springboot、vue vue代码库的最终打包文件放到springboot里 搭建过程可参考之前springboot+vue环境搭建 正常业务：频道管理，页面布局管理，以及补偿数据查询 job入口：用户推送消息job，签到失败补偿job（配置的到分布式任务平台，周期性调用） 服务端系统功能 签到类接口 查询签到信息接口（签到周期，每个用户展示的周期根据其实际签到进行计算，展示的不一定一样） 签到接口 不前接口 页面数据展示类接口 页面布局内容查询接口 轮播数据即可欧 用户配置类接口 查询定时提醒配置 修改定时提醒配置 job类服务接口 用户推送接口（后端系统调用该接口，再调用下游推送系统） 核心重大决策 签到接口 本签到系统数据落库成功，签到成功， 下游任务平台接口调用失败/超时的情况下，调用时的参数落补偿表，后台进行手动/job补偿。 任务平台的接口是幂等的，相同的参数调用不会频繁发送签到奖励。 任务平台调用风控时，如果认为是有风险的，即使补偿也无法成功，该情况只能等用户反馈后，由下游礼包等奖励系统，直接手动补偿。 补签接口 连续补签时，任务平台没有批量接口 业务上有系统，即签到系统，多线程批量调用，默认每一次单独补签为成功，调用超时/失败，补偿表进行处理 补签时是不会出现风控拦截的，因为补签卡发放时已经过了一到风控，能发送补签卡可定不会被拦截补签 用户消息推送 定时全表扫描（上一篇一次全表扫描XXXX） 筛选符合条件的数据 调用服务端接口进行推送（服务端调下游） 签到规则 会员中心 周期7天内，从未签过，打开时当天即为第一天 连续签7天即为满签 一旦有一天未签，重新从第一天开始签到 理财 周期7天内，从未签过，打开时当天即为第一天 七天之内均可签到，如有遗漏，在第七天结束之前均可以进行补签 前天周后，开始新的一轮，如果新一轮一直不签到，则每次打开，当天即为第一天 后期优化 job–》补偿次数可以优化为动态配置，否则达到补偿次数的数据一直占据着数据库的最前面，无法补偿。 补偿数据如果一直无法补偿，可以考虑再创建一个无法补偿的表存储，避免补偿表做过多的无用数据扫描 签到规则的提取，现在是if-else写死，后期可以抽取规则，根据条件注入，调用不同的规则实现 分析各层日志，接入紫金大盘进行接口调用量，成功率的统计分析 网关上接口的调用量和返回监控，是否需要配置上流控及返回文案 rsf接口关注tp99，耗时成功率等情况 思考 业务上的需求和最终实现上可能是矛盾的，需要进行互相的妥协。比如连续补签并发调用下游系统的相关决策。 保证数据的最终一致性","categories":[{"name":"架构设计","slug":"架构设计","permalink":"https://moon-zhou.github.io/categories/架构设计/"}],"tags":[]},{"title":"一次全表扫描关于分布式id的总结","slug":"一次全表扫描关于分布式id的总结","date":"2019-08-04T12:43:34.000Z","updated":"2019-09-08T07:52:44.016Z","comments":true,"path":"2019/08/04/一次全表扫描关于分布式id的总结/","link":"","permalink":"https://moon-zhou.github.io/2019/08/04/一次全表扫描关于分布式id的总结/","excerpt":"背景最近需要对某一个做了分表的数据，进行全表扫描做数据筛选后进行消息推送。设计思路 全表扫描时的筛选条件是什么 如何保证全表批量扫描时，每一批的数据量大致相同 确保可以全表扫描，没有数据的遗漏","text":"背景最近需要对某一个做了分表的数据，进行全表扫描做数据筛选后进行消息推送。设计思路 全表扫描时的筛选条件是什么 如何保证全表批量扫描时，每一批的数据量大致相同 确保可以全表扫描，没有数据的遗漏 实现 我们使用了Mycat来进行分库分表 分表字段为用户id 使用Mycat的sequence，来生成表的主键id，从而保证了所有表id的整体递增 固定每一次的数据量1000，按条件筛选后，批次处理数据量偏差不大，不会存在数据过大OOM的风险 知道总体的数据，从1~最后的数据，可以确保全表扫描 缺点 强依赖Mycat，Mycat依赖数据库的sequence配置表（实现方式） 数据落库时，id都需要通过Mycat获取sequence的当前值，作为数据的id，如果并发过高，对数据库的压力会比较大 配置表所在的Mysql宕机后，如果数据未及时同步，存在id重复的情况 总结以上的方案我们可以使用，是因为业务场景为扫描的用户配置信息，用户在设置操作时，不会存在高并发的情况，所以完全没有问题。（没有业务场景的方案设计，都是耍流氓）抽象/发散在高并发，分布式系统里，如何生成全局唯一、趋势递增的id相关场景 秒杀的业务场景下如何生成全局唯一、趋势递增的订单编号 基本要求 保证订单编号的生成逻辑要快、稳定，减少时延 保证生成的订单编号全局唯一、不重复、趋势递增、有时序性 实现方案 时间戳 [+ 机器码] + N位随机数流水号 缺点： 并发量高的场景，易出现重复id 数据库生成 规则：利用数据库（Mysql）的自增id，每一个表的初始值不一样，步长为分库/分表的数量（e.g. DB1-ID-(1,4,7…),DB2-ID-(2,5,8…),DB3-ID-(3,6,9…)） 缺点： 强依赖数据库，主从切换时的不一致可能会导致重复发号 性能及高可用瓶颈在数据库 redis 规则：利用 INCR 和 INCRBY这样的自增原子命令（Redis自身的单线程的特点所以能保证生成的 ID 肯定是唯一有序的） 缺点： 单机存在性能瓶颈 集群的方式又会涉及到和数据库集群同样的问题，所以也需要设置分段和步长来实现。 优点： 性能比较高 生成的数据是有序的 其他注意点：为了避免长期自增后数字过大可以通过与当前时间戳组合起来使用，另外为了保证并发和业务多线程的问题可以采用 Redis + Lua的方式进行编码，保证安全。 雪花算法（snowflake-64bit） 规则：第一位固定0 + 41bit时间戳 + 10bit机器码 + 12bit序列号，10bit机器码还可以进行拆分为5bit数据中心标识 + 5bit机器标识 第1位占用1bit，其值始终是0，可看做是符号位不使用。 第2位开始的41位是时间戳，41-bit位可表示2^41个数，每个数代表毫秒，那么雪花算法可用的时间年限是(1L&lt;&lt;41)/(1000L360024*365)=69 年的时间。 中间的10-bit位可表示机器数，即2^10 = 1024台机器，但是一般情况下我们不会部署这么台机器。如果我们对IDC（互联网数据中心）有需求，还可以将 10-bit 分 5-bit 给 IDC，分5-bit给工作机器。这样就可以表示32个IDC，每个IDC下可以有32台机器，具体的划分可以根据自身需求定义。 最后12-bit位是自增序列，可表示2^12 = 4096个数。 优点： ID是趋势递增 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高 生成ID的性能高（算法简单） 可以根据自身业务特性分配bit位，非常灵活 缺点： 强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。直至时间被追回。 实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180package com.jajian.demo.distribute;/** * Twitter_Snowflake&lt;br&gt; * SnowFlake的结构如下(每部分用-分开):&lt;br&gt; * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 &lt;br&gt; * 1位标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0&lt;br&gt; * 41位时间截(毫秒级)，注意，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截) * 得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。41位的时间截，可以使用69年，年T = (1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69&lt;br&gt; * 10位的数据机器位，可以部署在1024个节点，包括5位datacenterId和5位workerId&lt;br&gt; * 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号&lt;br&gt; * 加起来刚好64位，为一个Long型。&lt;br&gt; * SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高，经测试，SnowFlake每秒能够产生26万ID左右。 */public class SnowflakeDistributeId &#123; // ==============================Fields=========================================== /** * 开始时间截 (2015-01-01) */ private final long twepoch = 1420041600000L; /** * 机器id所占的位数 */ private final long workerIdBits = 5L; /** * 数据标识id所占的位数 */ private final long datacenterIdBits = 5L; /** * 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数) */ private final long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits); /** * 支持的最大数据标识id，结果是31 */ private final long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits); /** * 序列在id中占的位数 */ private final long sequenceBits = 12L; /** * 机器ID向左移12位 */ private final long workerIdShift = sequenceBits; /** * 数据标识id向左移17位(12+5) */ private final long datacenterIdShift = sequenceBits + workerIdBits; /** * 时间截向左移22位(5+5+12) */ private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; /** * 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */ private final long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits); /** * 工作机器ID(0~31) */ private long workerId; /** * 数据中心ID(0~31) */ private long datacenterId; /** * 毫秒内序列(0~4095) */ private long sequence = 0L; /** * 上次生成ID的时间截 */ private long lastTimestamp = -1L; //==============================Constructors===================================== /** * 构造函数 * * @param workerId 工作ID (0~31) * @param datacenterId 数据中心ID (0~31) */ public SnowflakeDistributeId(long workerId, long datacenterId) &#123; if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;worker Id can&apos;t be greater than %d or less than 0&quot;, maxWorkerId)); &#125; if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;datacenter Id can&apos;t be greater than %d or less than 0&quot;, maxDatacenterId)); &#125; this.workerId = workerId; this.datacenterId = datacenterId; &#125; // ==============================Methods========================================== /** * 获得下一个ID (该方法是线程安全的) * * @return SnowflakeId */ public synchronized long nextId() &#123; long timestamp = timeGen(); //如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常 if (timestamp &lt; lastTimestamp) &#123; throw new RuntimeException( String.format(&quot;Clock moved backwards. Refusing to generate id for %d milliseconds&quot;, lastTimestamp - timestamp)); &#125; //如果是同一时间生成的，则进行毫秒内序列 if (lastTimestamp == timestamp) &#123; sequence = (sequence + 1) &amp; sequenceMask; //毫秒内序列溢出 if (sequence == 0) &#123; //阻塞到下一个毫秒,获得新的时间戳 timestamp = tilNextMillis(lastTimestamp); &#125; &#125; //时间戳改变，毫秒内序列重置 else &#123; sequence = 0L; &#125; //上次生成ID的时间截 lastTimestamp = timestamp; //移位并通过或运算拼到一起组成64位的ID return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) // | (datacenterId &lt;&lt; datacenterIdShift) // | (workerId &lt;&lt; workerIdShift) // | sequence; &#125; /** * 阻塞到下一个毫秒，直到获得新的时间戳 * * @param lastTimestamp 上次生成ID的时间截 * @return 当前时间戳 */ protected long tilNextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = timeGen(); &#125; return timestamp; &#125; /** * 返回以毫秒为单位的当前时间 * * @return 当前时间(毫秒) */ protected long timeGen() &#123; return System.currentTimeMillis(); &#125;&#125;// 测试代码public static void main(String[] args) &#123; SnowflakeDistributeId idWorker = new SnowflakeDistributeId(0, 0); for (int i = 0; i &lt; 1000; i++) &#123; long id = idWorker.nextId();// System.out.println(Long.toBinaryString(id)); System.out.println(id); &#125;&#125; 其他方案【TODO】 美团-idleaf 百度-UidGenerator 参考 https://juejin.im/post/5d36c112e51d455cd73ba169 https://juejin.im/post/5d22972f6fb9a07edd2a34cc","categories":[{"name":"分布式","slug":"分布式","permalink":"https://moon-zhou.github.io/categories/分布式/"},{"name":"方案设计","slug":"分布式/方案设计","permalink":"https://moon-zhou.github.io/categories/分布式/方案设计/"}],"tags":[]},{"title":"【Monkey Run】jquery 插件","slug":"【Monkey Run】jquery 插件","date":"2019-07-26T11:58:34.000Z","updated":"2019-09-08T07:52:41.639Z","comments":true,"path":"2019/07/26/【Monkey Run】jquery 插件/","link":"","permalink":"https://moon-zhou.github.io/2019/07/26/【Monkey Run】jquery 插件/","excerpt":"说明历史的技术栈，总结于四年前，从电脑的某个小角落发现。 jquery 扩展插件jQuery插件的开发包括两种： 类级别的插件开发，即给jQuery添加新的全局函数，相当于给jQuery类本身添加方法。jQuery的全局函数就是属于jQuery命名空间的函数。 对象级别的插件开发，即给jQuery对象添加方法。","text":"说明历史的技术栈，总结于四年前，从电脑的某个小角落发现。 jquery 扩展插件jQuery插件的开发包括两种： 类级别的插件开发，即给jQuery添加新的全局函数，相当于给jQuery类本身添加方法。jQuery的全局函数就是属于jQuery命名空间的函数。 对象级别的插件开发，即给jQuery对象添加方法。 一、类级别的插件开发类级别的插件开发最直接的理解就是给jQuery类添加类方法，可以理解为添加静态方法。典型的例子就是$.AJAX()这个函数，将函数定义于jQuery的命名空间中。 1.1 定义一个全局函数jQuery.foo = function() { console.log(&apos;添加一个新的全局函数&apos;); }1.2使用extend定义全局函数jQuery.extend({ foo1:function() { console.log(&apos;extend 定义全局函数1&apos;); }, bar1:function() { console.log(&apos;extend 定义全局函数2&apos;); } });1.3 使用命名空间定义函数jQuery.plugin = { foo2:function() { console.log(&apos;使用namespace定义函数&apos;); } }调用方式$(function(){ $.foo(); // jQuery.foo(); $.foo1(); $.bar1(); $.plugin.foo2(); }); 二、对象级别的插件开发2.1 形式1(function($){ $.fn.extend({ foo3:function() { console.log(&apos;对象级别插件extend方式1&apos;); }, bar3:function() { console.log(&apos;对象级别插件extend方式2&apos;); } }) })(jQuery);2.2 形式2(function($){ $.fn.foo4 = function() { console.log(&apos;对象级别插件fn方式&apos;); } })(jQuery);上面定义了一个jQuery函数,形参是$，函数定义完成之后,把jQuery这个实参传递进去.立即调用执行。这样的好处是,我们在写jQuery插件时,也可以使用$这个别名,而不会与prototype引起冲突. 2.3 设置默认参数并对外暴露，保持私有方法/** * 私有方法 */ var privateFun = function(){ } function privateFun = function(){ } $.fn.simpleSwitch = function() { if (methods[method]) { return methods[method].apply(this, Array.prototype.slice.call(arguments, 1)); } else if (typeof method === &apos;object&apos; || !method) { return methods.init.apply(this, arguments); } else { $.error(&apos;Method &apos; + method + &apos; does not exist on jQuery.tooltip&apos;); } } /** * 默认的参数 */ $.fn.simpleSwitch.SIMPLESWITCH_DEFAULTS = { attr1: &quot;attr1&quot;, attr2: &quot;attr1&quot; }; 三、典型模板及解读// 传入了一个把公共变量“jQuery”传入了一个即时执行的函数里面，在函数局部（容器）中我们可以通过“$”来引用它 ;(function($) { // 局部作用域中使用$来引用jQuery // 在我们插件容器内，创造一个公共变量来构建一个私有方法 var privateFunction = function() { // 代码在这里运行 } // 通过字面量创造一个对象，存储我们需要的共有方法 var methods = { // 在字面量对象中定义每个单独的方法 init: function(options) { // 返回“this”（函数each（）的返回值也是this），以便进行链式调用。 return this.each(function() { var $this = $(this); var settings = $this.data(&apos;pluginName&apos;); if(typeof(settings) == &apos;undefined&apos;) { settings = $.extend({}, SIMPLESWITCH_DEFAULTS, options); $this.data(&apos;pluginName&apos;, settings); } else { settings = $.extend({}, settings, options); } // 代码在这里运行 // 例如： privateFunction(); }); }, destroy: function(options) { return $(this).each(function() { var $this = $(this); $this.removeData(&apos;pluginName&apos;); }); }, val: function(options) { var someValue = this.eq(0).html(); return someValue; }, onClick: function(){ }, offClick: function(){ }, click: function(){ } }; // 向jQuery中被保护的“fn”命名空间中添加你的插件代码，用“pluginName”作为插件的函数名称 $.fn.simpleSwitch = function() { // 检验方法是否存在 if (methods[method]) { /** * 在JS里Array是一个类 slice是此类里的一个方法 ，那么使用此方法应该Array.prototype.slice去截取参数 * 直白的方式为arrayObj.slice(start, [end])即[1,2,3].slice(1) * 等同于Array.prototype.slice.call([1,2,3], 1) */ return methods[method].apply(this, Array.prototype.slice.call(arguments, 1)); } else if (typeof method === &apos;object&apos; || !method) { // 如果方法不存在，检验对象是否为一个对象（JSON对象）或者method方法没有被传入 // 如果我们传入的是一个对象参数，或者根本没有参数，init方法会被调用 return methods.init.apply(this, arguments); } else { // 如果方法不存在或者参数没传入，则报出错误。需要调用的方法没有被正确调用 $.error(&apos;Method &apos; + method + &apos; does not exist on jQuery.tooltip&apos;); } /** * 关于call和apply都是调用方法，仅在参数arguments为数组时会有区别，如果调用的方法里的参数顺序与arguments一致，则使用apply，否则使用call */ } /** * 开关默认的参数 */ $.fn.simpleSwitch.SIMPLESWITCH_DEFAULTS = { }; })(jQuery); &lt;script type=&quot;text/javascript&quot;&gt; /*定义一个人类*/ function Person(name,age) { this.name=name; this.age=age; } /*定义一个学生类*/ function Student(name,age,grade) { Person.apply(this,arguments); Person.call(this,name,age); this.grade=grade; } //创建一个学生类 var student=new Student(&quot;zhangsan&quot;,21,&quot;一年级&quot;); //测试 alert(&quot;name:&quot;+student.name+&quot;\\n&quot;+&quot;age:&quot;+student.age+&quot;\\n&quot;+&quot;grade:&quot;+student.grade); //大家可以看到测试结果name:zhangsan age:21 grade:一年级 //学生类里面我没有给name和age属性赋值啊,为什么又存在这两个属性的值呢,这个就是apply的神奇之处. &lt;/script&gt; 四、总结和最佳做法 始终包裹在一个封闭的插件（即时执行的闭包里） 除非插件返回特定值（val），否则总是返回this关键字来维持chainability（jquery的链式编程） 传递一个可拓展的默认对象参数而不是大量的参数给插件（对插件进行抽象） 不要在一个插件中多次命名不同方法（不要出现下面的方式） (function($) { $.fn.tooltip = function(options) { // this }; $.fn.tooltipShow = function() { // is }; $.fn.tooltipHide = function() { // bad }; $.fn.tooltipUpdate = function(content) { // !!! }; })(jQuery); 始终命名空间的方法，事件和数据 参考：http://www.cnblogs.com/silverLee/archive/2009/12/22/1629925.htmlhttp://www.tuicool.com/articles/E3mEfeIhttp://www.cnblogs.com/Wayou/p/jquery_plugin_tutorial.htmlhttp://www.cnblogs.com/ellisonDon/archive/2012/08/12/2634503.htmlhttp://www.admin10000.com/document/9259.htmlhttp://blog.jobbole.com/30550/http://www.cnblogs.com/fromearth/archive/2009/07/08/1519054.htmlhttp://www.ibm.com/developerworks/cn/web/wa-jqplugin/#download","categories":[{"name":"前端","slug":"前端","permalink":"https://moon-zhou.github.io/categories/前端/"}],"tags":[]},{"title":"缓存那些事","slug":"缓存那些事","date":"2019-07-14T12:29:34.000Z","updated":"2019-09-08T07:51:49.237Z","comments":true,"path":"2019/07/14/缓存那些事/","link":"","permalink":"https://moon-zhou.github.io/2019/07/14/缓存那些事/","excerpt":"缓存那些事 缓存穿透 请求去查询一条压根儿数据库中根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。 带来的风险：黑客会对你的系统进行攻击，拿一个不存在的id 去查询数据，会产生大量的请求到数据库去查询。可能会导致你的数据库由于压力过大而宕掉。 解决办法： 缓存空值：这些key对应的值设置为null或者空对象丢到缓存里面(过期时间) BloomFilter：查询缓存之前先过下布隆过滤器，有再去走CACHE–DB（False is always false, True is maybe true.） 总结： key异常多、请求重复率比较低的数据，我们就没有必要进行缓存，使用BloomFilter。 空数据的key有限的，重复率比较高的，使用缓存空值。","text":"缓存那些事 缓存穿透 请求去查询一条压根儿数据库中根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。 带来的风险：黑客会对你的系统进行攻击，拿一个不存在的id 去查询数据，会产生大量的请求到数据库去查询。可能会导致你的数据库由于压力过大而宕掉。 解决办法： 缓存空值：这些key对应的值设置为null或者空对象丢到缓存里面(过期时间) BloomFilter：查询缓存之前先过下布隆过滤器，有再去走CACHE–DB（False is always false, True is maybe true.） 总结： key异常多、请求重复率比较低的数据，我们就没有必要进行缓存，使用BloomFilter。 空数据的key有限的，重复率比较高的，使用缓存空值。 缓存击穿 在平常高并发的系统中，大量的请求同时查询一个 key 时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去。 解决方案： 一般这种场景缓存的是公共资源，所以可以查库的操作可以加上互斥锁（分布式锁）。（查库的大操作里，再进行一次查缓存，防止大量请求没有获取到缓存时，都竞争这把锁排队，而第一个竞争到锁的线程查询完库之后又进行塞缓存，后续进程再查库之前时判断已查库就不需要进行真正的查库操作）（或者使用tryLock，失败重新进入，就不需要进行查库时也进行一次查缓存）（==同时需要注意不同key查询之间要互不影响==）。 热点数据不过期 缓存雪崩 当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上面。 解决方案 事前：使用集群缓存，保证缓存服务的高可用；参考第五点（过期时间不同） 事中：本地缓存 + 限流降级（ehcache + Hystrix） 事后：开启缓存持久化，尽快恢复集群（一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。） 总结 热点数据失效 在设置缓存的时候，一般会给缓存设置一个失效时间，过了这个时间，缓存就失效了。对于一些热点的数据来说，当缓存失效以后会存在大量的请求过来，然后打到数据库去，从而可能导致数据库崩溃的情况。 解决方案： 设置不同的失效时间：在一个基础的时间上加上或者减去一个范围内的随机值（避免这些热点的数据集中失效）","categories":[{"name":"分布式","slug":"分布式","permalink":"https://moon-zhou.github.io/categories/分布式/"}],"tags":[]},{"title":"【小白踩坑】SpringBoot + VUE搭建过程发布问题整理","slug":"【小白踩坑】SpringBoot + VUE搭建过程发布问题整理","date":"2019-07-06T15:15:34.000Z","updated":"2019-09-08T07:52:29.926Z","comments":true,"path":"2019/07/06/【小白踩坑】SpringBoot + VUE搭建过程发布问题整理/","link":"","permalink":"https://moon-zhou.github.io/2019/07/06/【小白踩坑】SpringBoot + VUE搭建过程发布问题整理/","excerpt":"前言 从本场地环境搭建，启动，到发布服务器，时刻都可能存在着各种问题。雁过留痕，以此记录。","text":"前言 从本场地环境搭建，启动，到发布服务器，时刻都可能存在着各种问题。雁过留痕，以此记录。 后台搭建问题 本地环境搭建启动问题总结链接记录：请戳我 因为图床域名被收回，超链接为文本笔记，非md文档。 发布到服务器上，出现了两个问题（前提是本地可以正常启动，web容器使用的是jboss） 服务器压根无法启动 因为本地可以启动，服务器上的web容器却无法启动，猜测是web容器相关配置，查找资料，需添加如下配置： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 服务器正常启动，但controller却无法访问，ajax请求及页面跳转都无法正常返回，显示404。 因为请求都无法返回，猜测是controller都未被注册到spring上下文里面，查找相关资料，找到如下解决方案：继承SpringBootServletInitializer，重写configure方法 123456789101112131415@SpringBootApplication@MapperScan(&quot;com.suning.epp.member.fmsms.admin.dao&quot;)@ImportResource(locations = &#123;&quot;classpath*:config/sfops-ws-client.xml&quot;&#125;)public class FmsmsAdminWebApplication extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; return application.sources(FmsmsAdminWebApplication.class); &#125; public static void main(String[] args) &#123; SpringApplication.run(FmsmsAdminWebApplication.class, args); &#125;&#125; ajax请求正常，跳转ftl页面出现404 确认是否引入了freemarker依赖 1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt;&lt;/dependency&gt; 确认templates目录是否编译到classes下，如果是resources目录下回自动编译，如果是自定义目录下，需要手动设置该目录为resources 确认配置文件，尤其是template-loader-path 页面跳转也正常，但是资源文件（js/css）404 确认static-locations配置 前端页面搭建问题 因为把原先创建的vue工程复制到别的文件夹，导致无法再次build（npm 项目，在安装依赖node_modules的时候，会记录当前的文件路径。当路径更改，就无法正常启动。） 删除原有的node_modules 使用npm install install过程可能出现npm ERR! code: ‘EPERM’ (权限问题 errro permit)：npm cache clean –force 多次执行npm install，依然报错，且执行npm run dev，报‘webpack-dev-server’不是内部或外部命令错误，但是小伙伴新搭建的却没有这类问题，猜测可能和npm有关，更新至最新版：npm install -g npm 再次执行npm install，正常，出现 run npm audit fix to fix them, or npm audit for details可忽略 npm run dev测试正常 配置完prefix之后npm无法使用，参考【傻瓜式学Vue-01搭建环境、初始化项目】第三步，建议目录不要配置到node的安装目录【TODO】 删除C:\\Users{账户}\\下的.npmrc文件 跳转到ftl页面，但是js/css始终404，查看相关位置的文件都正常 源文件里点击js/css可以进入相关页面 浏览器F12，发现相关脚本文件的地址都正常，上下文根都正常（eg.http://localhost:8881/XXXX/assets/css/hello/app.9df0c078c59382db011d74ed17465dad.css） 此时猜测问题应该在配置上，网上查找相关配置，修改完访问正常。 123Spring: resources: static-locations: classpath:/","categories":[{"name":"SpringBoot2.X","slug":"SpringBoot2-X","permalink":"https://moon-zhou.github.io/categories/SpringBoot2-X/"},{"name":"Vue","slug":"SpringBoot2-X/Vue","permalink":"https://moon-zhou.github.io/categories/SpringBoot2-X/Vue/"},{"name":"问题记录","slug":"SpringBoot2-X/Vue/问题记录","permalink":"https://moon-zhou.github.io/categories/SpringBoot2-X/Vue/问题记录/"}],"tags":[]},{"title":"【朝花再拾】Maven知识点","slug":"【朝花再拾】Maven知识点","date":"2019-07-06T15:15:34.000Z","updated":"2019-09-08T07:52:36.878Z","comments":true,"path":"2019/07/06/【朝花再拾】Maven知识点/","link":"","permalink":"https://moon-zhou.github.io/2019/07/06/【朝花再拾】Maven知识点/","excerpt":"背景 最近搭建SB系统时，是基于maven的project，常年没有搭建，有些知识点已经遗忘，在这个过程中，把相关东西一点点拾起来。","text":"背景 最近搭建SB系统时，是基于maven的project，常年没有搭建，有些知识点已经遗忘，在这个过程中，把相关东西一点点拾起来。 知识点 基本知识点：modules、parent、groupId、artifactId、version DepencyManagement与单纯的Dependencies DepencyManagement 由于是基于多模块进行的搭建，因此不同模块之间对第三方依赖的使用就需要进行规范，防止不同的模块对同一第三方依赖使用的版本不同，造成测试和发布的结果不一致问题。 父pom通过DepencyManagement-dependencies-dependency（groupId-artifactId-version）控制依赖以及版本 子module里pom通过dependencies-dependency（groupId-artifactId）直接使用，而不需要指定具体的版本号，直接依赖父pom的版本配置 父pom里还可以对version进行统一的配置提取管理，将依赖的version抽取到properties，定义变量，这样第三方依赖也被放到一起，更易于依赖版本的管理 单纯的Dependencies 相对于dependencyManagement，所有生命在dependencies里的依赖都会自动引入，并默认被所有的子项目继承 区别 dependencies即使在子模块中不写该依赖项，那么子模块仍然会从父项目中继承该依赖项（全部继承） dependencyManagement里只是声明依赖，并不实现引入，因此子模块需要显示的声明需要用的依赖。如果不在子模块中声明依赖，是不会从父项目中继承下来的；只有在子模块中写了该依赖项，并且没有指定具体版本，才会从父项目中继承该项，并且version和scope都读取自父pom;另外如果子模块中指定了版本号，那么会使用子模块中指定的jar版本。（==当然一般不建议子模块里指定version==） 总结 dependencies中的jar直接加到项目中，管理的是依赖关系（如果有父pom,子pom,则子pom中只能被动接受父类的版本）； dependencyManagement主要管理版本，对于子类继承同一个父类是很有用的，集中管理依赖版本不添加依赖关系，对于其中定义的版本，子pom不一定要继承父pom所定义的版本。 scope dependency里引入scope，主要管理依赖的部署。配置值及使用如下: 概念 compile：缺省值，适用于所有阶段，会随着项目一起发布。 provided：类似compile，期望JDK、容器或使用者会提供这个依赖。如servlet.jar。 runtime：只在运行时使用，如JDBC驱动，适用运行和测试阶段。 test：只在测试时使用，用于编译和运行测试代码。不会随项目发布。 system：类似provided，需要显式提供包含依赖的jar，Maven不会在Repository中查找它。 详解 compile （编译范围） compile是默认的范围；如果没有提供一个范围，那该依赖的范围就是编译范围。编译范围依赖在所有的classpath 中可用，同时它们也会被打包。 provided （已提供范围） provided 依赖只有在当JDK 或者一个容器已提供该依赖之后才使用。例如， 如果你开发了一个web 应用，你可能在编译 classpath 中需要可用的Servlet API 来编译一个servlet，但是你不会想要在打包好的WAR 中包含这个Servlet API；这个Servlet API JAR 由你的应用服务器或者servlet 容器提供。已提供范围的依赖在编译classpath （不是运行时）可用。它们不是传递性的，也不会被打包。 runtime （运行时范围） runtime 依赖在运行和测试系统的时候需要，但在编译的时候不需要。比如，你可能在编译的时候只需要JDBC API JAR，而只有在运行的时候才需要JDBC test （测试范围） test范围依赖在一般的编译和运行时都不需要，它们只有在测试编译和测试运行阶段可用。 system （系统范围） system范围依赖与provided 类似，但是你必须显式的提供一个对于本地系统中JAR 文件的路径。这么做是为了允许基于本地对象编译，而这些对象是系统类库的一部分。这样的构件应该是一直可用的，Maven 也不会在仓库中去寻找它。如果你将一个依赖范围设置成系统范围，你必须同时提供一个 systemPath 元素。注意该范围是不推荐使用的（你应该一直尽量去从公共或定制的 Maven 仓库中引用依赖）。 packaging 默认是jar类型 pom：父类型都为pom类型 jar：内部调用或者是作服务使用 war：需要部署的项目 profiles：配合打包时，针对不同的环境取不同的配置。 每个profile都有唯一的id，也包含properties属性。id定义不同环境，properties设置变量。结合打包时build使用。 示例： 1234567891011121314151617181920212223242526&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;sit&lt;/id&gt; &lt;properties&gt; &lt;envName&gt;sit&lt;/envName&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;pre&lt;/id&gt; &lt;properties&gt; &lt;envName&gt;pre&lt;/envName&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;uat&lt;/id&gt; &lt;properties&gt; &lt;envName&gt;uat&lt;/envName&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;prd&lt;/id&gt; &lt;properties&gt; &lt;envName&gt;prd&lt;/envName&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 扩展：springboot也为我们提供了针对不同环境的打包方式，此处暂不进行示例演示。 build 分类 project Build：project 的直接子元素（子模块pom里） profile Build：profile的直接子元素（直观上就是父pom里，与profile配合使用） 相关配置 resources-resource-filtering： true/false，表示为这个resource，filter是否激活 pluginManagement:pluginManagement的配置和plugins的配置是一样的，只是用于继承，使得可以在孩子pom中使用。类比DepencyManagement 其他配置暂时不做详解。 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 &lt;build&gt; &lt;finalName&gt;backend-base-$&#123;maven.build.timestamp&#125;&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources/config/$&#123;envName&#125;/&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;$&#123;java.version&#125;&lt;/source&gt; &lt;target&gt;$&#123;java.version&#125;&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;org.moonzhou.backend.base.BackendBaseWebApplication&lt;/mainClass&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt;&lt;/build&gt;&lt;!--子模块--&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 常用命令 mvn compile 编译,将Java 源程序编译成 class 字节码文件。 mvn test 测试，并生成测试报告 mvn clean 将以前编译得到的旧的 class 字节码文件删除 mvn pakage 打包,动态 web工程打 war包，Java工程打 jar 包 mvn install 将项目生成 jar 包放在仓库中，以便别的模块调用","categories":[{"name":"Maven","slug":"Maven","permalink":"https://moon-zhou.github.io/categories/Maven/"}],"tags":[]},{"title":"SpringBoot + VUE系统搭建","slug":"SpringBoot + VUE系统搭建","date":"2019-06-30T11:43:34.000Z","updated":"2019-09-08T07:51:59.501Z","comments":true,"path":"2019/06/30/SpringBoot + VUE系统搭建/","link":"","permalink":"https://moon-zhou.github.io/2019/06/30/SpringBoot + VUE系统搭建/","excerpt":"学前准备 有java web开发经验，熟悉MVC开发 了解前端页面编写 了解前后端数据交互","text":"学前准备 有java web开发经验，熟悉MVC开发 了解前端页面编写 了解前后端数据交互 背景 新项目开始，搭建后台系统，采用伪前后端分离（前端代码剥离，但最终依然需要加入到后端系统，通过后端容器进行发布） 目标拆分 后端系统搭建-SpringBoot 新建SpringBoot项目 配置多模块 各模块设计可参考github demo各模块README说明 各模块引入相关jar包 明确各模块依赖 配置打包环境 启动 功能测试 编写Controller，测试Controller层（ajax-json接口） 编写Service，测试Controller-Service 编写dao层，引入ORM框架（mybatis），测试Controller-Service-service 测试约定的application.yml配置 测试自定义yml配置 接入Freemarker，测试Controller页面跳转 前端系统搭建-VUE 环境搭建及初始化==参考傻瓜式学VUE系列== 固定数据测试 使用Element-UI，通过固定数据加载，初始化列表组件 打包，集成至后端系统，通过Controller进行测试 动态数据测试 调用后端固定接口，按返回数据初始化列表组件 打包，集成至后端系统，通过Controller加载页面，通过前端调用后端接口的数据来初始化组件 小白踩坑 初始创建为非maven项目，后续多模块无法依赖是，idea里右键选择Add Framework Support，选择maven即可。 入口main函数上加上@EnableAutoConfiguration，这样各个依赖的module里的注解才能正常被spring识别，加入spring上下文中进行管理。 注意各个包的定义，最终打包的文件，入口函数要在最外面，否则即使加了自动配置注解，也无法扫描到包外的spring注解类。 java.sql.SQLException: The server time zone value：数据库连接加上serverTimezone=GMT，eg.jdbc:mysql://localhost:3306/member?useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=GMT 该异常不同版本的springboot不一定都会出现，2.1.6出现单2.0.2没有该异常 持久层接口类加入spring上下文进行管理 接口类上加Mapper注解，类似service类上加Service注解 main类上加MapperScan注解，扫描持久层接口类所在的包，eg.@MapperScan(“org.moonzhou.backend.base.dao”) 自定义yml时无法被自动识别问题 @PropertySource该注解老版本支持，1.0.4之后该属性就取消了 2.0.0官方解释：YAML files cannot be loaded by using the @PropertySource annotation. So, in the case that you need to load values that way, you need to use a properties file. 使用@Configuration-@Bean，通过代码将自定义的yml文件加入spring上下文管理里，通过@Value或者@ConfigurationProperties来进行配合使用 小白不能忍 创建的配置文件为properties文件，代码最终都是人看的，yml配置跟易于开发人员进行阅读，本人建议使用yml格式进行配置。该配置需要注意： 冒号之后需要空一格，再写配置值 必须要有自定义配置的配置文件，尽量根据功能不同抽取出不同的配置文件。至少自定义的配置与框架类配置进行抽离。 http请求默认后缀配置 配置yml（也可以通过代码） 1234567spring: mvc: pathmatch: use-suffix-pattern: false use-registered-suffix-pattern: true contentnegotiation: favor-path-extension: false 代码修改，添加到main类中 123456789101112/** * 设置匹配.do后缀的请求 * * @param dispatcherServlet * @return */@Beanpublic ServletRegistrationBean servletRegistrationBean(DispatcherServlet dispatcherServlet) &#123; ServletRegistrationBean bean = new ServletRegistrationBean(dispatcherServlet); bean.addUrlMappings(&quot;*.do&quot;); return bean;&#125; 导致问题：静态资源都无法正常访问-404 退而求其次，抽取公共后缀，手动加在RequestMapping的value后面 配置热启动 父pom添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 如果想让模板页面也生效，需要修改相关模板缓存未false（这一步改为true也生效了，实操时各自看） 123spring.thymeleaf.cache=falsespring.freemarker.cache=falsespring.groovy.template.cache=false yml配置，按需配置(https://docs.spring.io/spring-boot/docs/current/reference/html/common-application-properties.html) 12345# 热启动devtools: restart: enabled: true additional-paths: src/main/java 配置idea 快捷键Ctrl+Alt+S打开设置(File-&gt;settings)，在Build，Execotion，Deployment-&gt;Compiler-&gt;勾选Build Project automatically项 快捷键Ctrl + Shift + Alt + /，选择Registry，勾选 Compiler autoMake allow when app running 上述配置结束，重启应用，当改动代码时，观察控制台输出，你会发现Spring Boot已经检测到了文件变化，并重新启动。 配置Druid数据源(https://github.com/alibaba/druid/tree/master/druid-spring-boot-starter) 添加依赖 12345 &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.18&lt;/version&gt;&lt;/dependency&gt; 修改yml数据源配置 123spring: datasource: type: com.alibaba.druid.pool.DruidDataSource 添加监控配置 123456789101112spring: datasource: druid: web-stat-filter: enabled: true url-pattern: /* web-stat-filter.exclusions: .js,.gif,.jpg,.png,.css,.ico,/druid/* stat-view-servlet: enabled: true url-pattern: /druid/* login-username: druid login-password: druid123 监控测试 http://localhost:8881/backend-base/druid/index.html 抽象代码示例 github地址：https://github.com/moon-zhou/SpringBoot_Backend_Modules.git 本地启动：http://localhost:8881/backend-base/hello/test.do","categories":[{"name":"SpringBoot2.X","slug":"SpringBoot2-X","permalink":"https://moon-zhou.github.io/categories/SpringBoot2-X/"},{"name":"Vue","slug":"SpringBoot2-X/Vue","permalink":"https://moon-zhou.github.io/categories/SpringBoot2-X/Vue/"}],"tags":[]},{"title":"Git学习-小白不能忍之三","slug":"Git学习-小白不能忍之三","date":"2019-06-23T09:23:34.000Z","updated":"2019-09-08T07:52:19.790Z","comments":true,"path":"2019/06/23/Git学习-小白不能忍之三/","link":"","permalink":"https://moon-zhou.github.io/2019/06/23/Git学习-小白不能忍之三/","excerpt":"","text":"背景 使用git命令pull/push代码时，总是需要输入用户名密码 频繁输入–》不能忍 是否可以保存账密不需要每次都输入 解决方案 git config –global credential.helper store 执行上述命令后，第一次pull或push需要输入用户名和密码，之后就不用再输入了。","categories":[{"name":"Git","slug":"Git","permalink":"https://moon-zhou.github.io/categories/Git/"}],"tags":[]},{"title":"Git学习-小白学理论","slug":"Git学习-小白学理论","date":"2019-06-23T09:23:34.000Z","updated":"2019-09-08T07:52:13.382Z","comments":true,"path":"2019/06/23/Git学习-小白学理论/","link":"","permalink":"https://moon-zhou.github.io/2019/06/23/Git学习-小白学理论/","excerpt":"文件状态（未进行commit操作之前，存在三种状态） Untracked files Changes not staged for commit Changes to be committed","text":"文件状态（未进行commit操作之前，存在三种状态） Untracked files Changes not staged for commit Changes to be committed Untracked files 新增/删除的文件（除了新增和删除实际的动作，还包括修改文件名）。通常是某些文件放到Git工作目录中，但又不能提交它们，比如保存了数据库密码的配置文件，编译文件，IDE生成的文件等。如果是需要提交的文件，则使用git add进行添加，将文件包含到待提交清单中（暂存区）。 删除这里的文件 12345678910111213# 删除 untracked filesgit clean -f # 连 untracked 的目录也一起删掉git clean -fd # 连 gitignore 的untrack 文件/目录也一起删掉 （慎用，一般这个是用来删掉编译出来的 .o之类的文件用的）git clean -xfd # 在用上述 git clean 前，墙裂建议加上 -n 参数来先看看会删掉哪些文件，防止重要文件被误删git clean -nxfdgit clean -nfgit clean -nfd 添加.gitignore #为注释 可以使用shell所使用的正则表达式来进行模式匹配 匹配模式最后跟”/“说明要忽略的是目录 使用！取反（例如目录中包含 test.a，并且gitignore文件中包含 *.[oa]，如果在文件中加入 ！test.a 表明忽略除test.a文件以外的后缀名为.a或者.o的文件） 回退：git reset –hard Changes not staged for commit 修改的文件，但是还没有放入暂存区域，也就是没生成快照。（git add放入暂存区） Changes to be committed 在暂存区域生成了快照，等待被提交。通过“git rm –cached README.txt”命令，可以将文件状态还原为未暂存状态，即回到“Untracked files”文件状态。 图示 1234567graph LR工作区-Workspace--&gt;暂存区-IndexStage暂存区-IndexStage--&gt;本地仓库-Repository本地仓库-Repository--&gt;远程仓库-Remote本地仓库-Repository--&gt;工作区-Workspace远程仓库-Remote--&gt;本地仓库-Repository远程仓库-Remote--&gt;工作区-Workspace 步骤 操作 工作区-Workspace–&gt;暂存区-IndexStage add 暂存区-IndexStage–&gt;本地仓库-Repository commit 本地仓库-Repository–&gt;远程仓库-Remote push 本地仓库-Repository–&gt;工作区-Workspace checkout 远程仓库-Remote–&gt;本地仓库-Repository clone 远程仓库-Remote–&gt;工作区-Workspace pull(fetch/merge) 注意 只有暂存区域的文件（即：文件状态为“Changes to be committed”）才会被提交，提交到本地仓库。 如果不想通过暂存区而直接提交，可以使用git commit -a命令，这个命令可以将所以已经跟踪过的文件暂存起来一并提交，而不用git add。（未跟踪的不行）提交时注意添加说明git commit -a -m “Add a description” git add既可以用来跟踪新的文件（新增、删除），亦可以将已经跟踪的文件添加到暂存区（修改）。暂存区是下一次提交的文件，因此git add也可以理解为将此文件作为下次提交的文件。 重要概念 远程跟踪分支：“远程的”标记名称（如 :origin）+ “/“ + 远程仓库里分支的真正名称（“远程名称”是一个代码仓库别名，和本地目录或URL是一个含义，你可以通过”==git remote==”命令自由定义额外的“远程名称”。但“git clone”命令==默认==使用的是“origin”这个名称。） 123456git branch -rorigin/Dev_Br_20190528origin/HEAD -&gt; origin/masterorigin/Hot_Br_20190513origin/Hot_Br_20190514origin/master 命令使用 命令 功能 git fetch 从远端的源仓库更新到本地的代码仓库，执行完命令还不会立即将下载的文件合并到你当前工作目录里，你需要执行一个“合并（merge）”操作：git merge origin/master git rebase https://www.cnblogs.com/kidsitcn/p/5339382.html 【==待整理TODO==】","categories":[{"name":"Git","slug":"Git","permalink":"https://moon-zhou.github.io/categories/Git/"}],"tags":[]},{"title":"Git学习-小白实操","slug":"Git学习-小白实操","date":"2019-06-23T09:23:34.000Z","updated":"2019-09-08T07:52:15.565Z","comments":true,"path":"2019/06/23/Git学习-小白实操/","link":"","permalink":"https://moon-zhou.github.io/2019/06/23/Git学习-小白实操/","excerpt":"配置 Git 查看当前用户（global）配置信息：git config –global –list 修改配置信息：git config –global user.name moon-zhougit config –global user.email “ayimin1989@163.com“ 删除配置：git config –global –unset XXX","text":"配置 Git 查看当前用户（global）配置信息：git config –global –list 修改配置信息：git config –global user.name moon-zhougit config –global user.email “ayimin1989@163.com“ 删除配置：git config –global –unset XXX 查看 已commit但是未push的状态查看 git status #只能查看未传送提交的次数 git cherry -v #只能查看未传送提交的描述/说明 git log master ^origin/master #则可以查看未传送提交的详细信息 代码提交步骤 git add . #提交未跟踪、修改和删除文件 git commit -m ‘commit message’ git push origin remoteBranchXXXX 后悔药系列 本地commit之后，发现提交log填写错误，通过以下操作进行回退： git commit –amend 按下字母键 c（此时进入编辑状态），可以开始修改注释信息了 修改完成之后，按下Esc (退出编辑状态)； 接着连按两次大写字母Z，保存好退出（wq） 代码回退 git reset –hard commit_id #退到 指定commit的sha码 git reset –hard HEAD^ #回退到上个版本 git reset –hard HEAD~3 #回退到前3次提交之前，以此类推，回退到n次提交之前 以上做完，需要强推到远程：git push origin HEAD –force ==强推需要注意，当前分支不能是保护分支== git add之后，发现添加错了文件，使用git reset进行回退 git reset HEAD 如果后面什么都不跟的话 就是上一次add 里面的全部撤销了 git reset HEAD XXX/XXX/XXX.java 就是对某个文件进行撤销了 修改了文件，但又不想add，想以远程分支为准。 git checkout . # 撤销对所有已修改但未提交的文件的修改，但不包括新增的文件 git checkout filename # 撤销对指定文件的修改，filename为文件名 分支操作 代码库确认git remote -v 查看分支与远程分支追踪状态git branch -vv 展示代码库下远程所有分支git branch -a 查看本地的git分支git branch 查看所有远程分支git branch -r 本地分支切换git checkout branchNameXXX 删除远程分支git push origin –delete remoteBranchName 删除本地分支git branch -d 不能在当前分支（如在master分支使用该命令，删除其他分支） 实际操作案例 一个迭代版本之后，旧分支合并master，同时删除旧分支，同时拉了新分支，如何进行操作，保持本地分支与远程分支的一致性。 查看远程分支：git branch -r 查看本地分支：git branch 或者使用git branch -a，查看本地和远程所有分支，比较出本地仓库和远程仓库的分支差异之后。进行如下操作。 获取远程仓库的新分支以及删除远程仓库已删除的分支:git fetch -p 获取远程新拉的分支（创建新分支并立即切换到新分支）：git checkout -b 或者 git checkout -b 本地分支名 origin/远程分支名 newBranchNameXXXX 拉取远程新拉分支的代码：git pull origin newBranchNameXXXX或者将本地分支与远程分支关联后直接pull： git branch –set-upstream-to=origin/RemoteBranch LocalBranch 因为已经发布，删除本地之前版本分支：git branch -D oldBranchNameXXX # 该命令不能在当前分支上删除当前分支，-D和-d有区别 其中5和6可以使用==git checkout -b localBranchName origin/remoteBranchName==(在本地新建分支，并自动切换到该本地分支。采用此种方法建立的本地分支会和远程分支建立映射关系)。同理也可以使用==git fetch origin remoteBranchName:localBranchName==（使用该方式会在本地新建分支，但是不会切换到该本地分支，需要手动checkout切换。采用此种方法建立的本地分支不会和远程分支建立映射关系。）+==git branch -u origin/remoteBranchName==（将当前分支映射到远程的指定分支，注意切换到当前分支；本地分支和远程分支建立映射时，两个名字不一定要一样） 不同分支之间进行合并：dev分支为公共的开发版本分支，ft分支为各自的编码分支，ft分支push之后，如何合并到dev分支，步骤如下： 切换到dev分支：git checkout devBranch 拉取dev分支代码：git pull 将ft分支合并到dev分支：git merge ftBranch 解决冲突：&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记冲突，删除不需要的部分即可。 解决冲突之后，重新commit-push。 demo说明： 123A-----C----E (&quot;stable&quot;) \\ B-----D-----F (&quot;new-idea&quot;) * git checkout stable # Change to work on the branch &quot;stable&quot; * git merge new-idea # Merge in &quot;new-idea&quot; * 做完上述两步得到如下结果： 123A-----C----E----G (&quot;stable&quot;) \\ / B-----D-----F (&quot;new-idea&quot;) * 要是你继续在“new idea” 和“stable”分支提交, 会得到： 123A-----C----E----G---H (&quot;stable&quot;) \\ / B-----D-----F----I (&quot;new-idea&quot;) * 因此现在A, B, C, D, E, F, G 和 H 属于 “stable”，而A, B, D, F 和 I 属于 “new-idea”。 切换分支后获取更新时的意外情况：先checkout切换分支，再pull 可能出现错误：Git pull - Please move or remove them before you can merge 如果多人提交时，别人先提交，自己本地修改了代码(相同的文件行)，然后pull时，会报error: Your local changes to the following files would be overwritten by merge: 如果你想保留刚才本地修改的代码，并把git服务器上的代码pull到本地（本地刚才修改的代码将会被暂时封存起来） git stash git pull origin master git stash pop 如果你想完全地覆盖本地的代码，只保留服务器端代码，则直接回退到上一个版本，再进行pull git reset –hard git pull origin master 如果没有冲突，先pull后push之后，代码的提交分支就会看上去很乱，不是一条干净的直线。pull完之后rebase再提交即可把分叉的提交变成一条直线。 git pull git rebase git push 如果只在一条主分支上开发，忽然意识到这可能不太合适，需要一个在一个开发分支进行相关修改，步骤如下： 主分支 1234last version from another repository | v M---N-----O----P---Q (&quot;master&quot;) 把变更后的OPQ拆到新分支上 12345678910111213141516171819202122git branch dubious-experiment M---N-----O----P---Q (&quot;master&quot; and &quot;dubious-experiment&quot;) git checkout master # Be careful with this next command: make sure &quot;git status&quot; is # clean, you&apos;re definitely on &quot;master&quot; and the # &quot;dubious-experiment&quot; branch has the commits you were working # on first... git reset --hard &lt;SHA1sum of commit N&gt; (&quot;master&quot;) M---N-------------O----P---Q (&quot;dubious-experiment&quot;) git pull # Or something that updates &quot;master&quot; from # somewhere else... M--N----R---S (&quot;master&quot;) \\ O---P---Q (&quot;dubious-experiment&quot;) https://www.jianshu.com/p/3be4029ce854https://www.oschina.net/translate/git-fetch-and-merge?cmphttps://www.cnblogs.com/flying_bat/p/3408634.html","categories":[{"name":"Git","slug":"Git","permalink":"https://moon-zhou.github.io/categories/Git/"}],"tags":[]},{"title":"github新增代码库实操","slug":"github新增代码库实操","date":"2019-06-23T09:23:34.000Z","updated":"2019-09-08T07:52:26.805Z","comments":true,"path":"2019/06/23/github新增代码库实操/","link":"","permalink":"https://moon-zhou.github.io/2019/06/23/github新增代码库实操/","excerpt":"git创建新的代码库 登录github 找到”new repository”","text":"git创建新的代码库 登录github 找到”new repository” 本地操作 创建git目录：进入目录，git init 将所有文件添加到本地工作区：git add . 提交到本地库：git commit -m 提交说明 添加本地和远程仓库的关联：git remote add localRepositoryName remoteRepositoryUrl【示例：git remote add my-project-first https://github.com/moon-zhou/VueDemo.git】 第一次不需要pull，直接push，需要设置upstream，后面就直接push，git push –set-upstream my-project-first master 后悔药系列 如果github上传时，设置的提交人名称有误 删除上一次提交，如果就一次提交，或者只有一个作者，因为换机器导致提交用户错误的，直接删除代码库，重新新建github代码库 本地删除git管理文件：rm -rf .git 修改本地的git用户名：git config –global user.name，==详情参考Git学习实操== 重新参考”本地操作”，重新走一遍","categories":[{"name":"Git","slug":"Git","permalink":"https://moon-zhou.github.io/categories/Git/"}],"tags":[]},{"title":"Git学习-小白不能忍之二","slug":"Git学习-小白不能忍之二","date":"2019-06-23T09:23:34.000Z","updated":"2019-09-08T07:52:23.247Z","comments":true,"path":"2019/06/23/Git学习-小白不能忍之二/","link":"","permalink":"https://moon-zhou.github.io/2019/06/23/Git学习-小白不能忍之二/","excerpt":"背景 代码在idea里，会被自动编译，生成很多编译代码及IDE配置文件，在git目录下总是提示需要提交，不能忍","text":"背景 代码在idea里，会被自动编译，生成很多编译代码及IDE配置文件，在git目录下总是提示需要提交，不能忍 git在idea里的使用安装gitignore 在线安装 File–settings–Plugins–Browse Repositories 离线安装 下载地址：https://plugins.jetbrains.com/plugin/7495--ignore File–settings–Plugins–Install plugin from disk 新增.gitignore文件 new–.ignore file–.gitignore file(Git) 创建完成，添加忽略git跟踪的文件 错误处理 Git Pull Failed: Authentication failed for ‘http://git.XXX.git/&#39; 处理方式一：控制面板-凭据管理器-普通凭据，找到git:http://git.XXX.com的配置，修改用户名密码 如果第一步不生效，清空idea保存的账号密码：File–Settings–Appearance&amp;Behavior–System Settings–Password(清空设置或者不保存即可) 多分支切换时提示（git checkout branchName）：Your branch and ‘origin/Hot_Br_20190513’ have diverged,and have 181 and 7 different commits each, respectively. (use “git pull” to merge the remote branch into yours) 解决方案：You will have to reset to that remote branch in order to reset your local branch to it. git fetch origin git reset –hard origin/remoteBranchName 问题原因： 本地工作区里的代码提交进度与远程仓库的进度不一致 另外的解决方案 Git出现冲突error: Your local changes to the following files would be overwritten by merge: xxx/xxx/xxx Please, commit your changes or stash them before you can merge. Aborting 出现这个问题的原因是其他人修改了xxx并提交到版本库中去了，而你本地也修改了xxx，这时候你进行git pull操作就好出现冲突了。 解决方案：通过git stash将工作区恢复到上次提交的内容，同时备份本地所做的修改 git stash git pull git stash pop 辅助命令 git stash list: 显示Git栈内的所有备份，可以利用这个列表来决定从那个地方恢复。 git stash clear: 清空Git栈。此时使用gitg等图形化工具会发现，原来stash的哪些节点都消失了。","categories":[{"name":"Git","slug":"Git","permalink":"https://moon-zhou.github.io/categories/Git/"}],"tags":[]},{"title":"Git学习-小白不能忍之一","slug":"Git学习-小白不能忍之一","date":"2019-06-23T09:23:34.000Z","updated":"2019-09-08T07:52:17.502Z","comments":true,"path":"2019/06/23/Git学习-小白不能忍之一/","link":"","permalink":"https://moon-zhou.github.io/2019/06/23/Git学习-小白不能忍之一/","excerpt":"背景 git 命令过长，记忆以及输入时不够快捷，不能忍 Git Log的进阶使用 Git查看日志，单独使用git log来操作，每一个commit信息太多，干扰信息又太多，而且各种分支的合并也看不到。优化如下： git log –graph –pretty=format:’%Cred%h%Creset - %C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset’ –abbrev-commit –date=relative","text":"背景 git 命令过长，记忆以及输入时不够快捷，不能忍 Git Log的进阶使用 Git查看日志，单独使用git log来操作，每一个commit信息太多，干扰信息又太多，而且各种分支的合并也看不到。优化如下： git log –graph –pretty=format:’%Cred%h%Creset - %C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset’ –abbrev-commit –date=relative 别名的使用：alias git config –global alias.ck checkoutgit config –global alias.br branchgit config –global alias.cm commitgit config –global alias.st status 配置之后，原来的git checkout直接使用git ck即可。==alias.xx==点后面的xx就代表了我们设置的别名。 结合别名的特性，我们可以优化第一点里的log以提高上述代码的效率。配置如下： git config –global alias.lg “log –graph –pretty=format:’%Cred%h%Creset - %C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset’ –abbrev-commit –date=relative” 常用技巧 功能 快捷键 复制 ctrl + insert 粘贴 shift + insert 看日志 回车-查看更多，q-退出查看 merge后commit linux模式：”i”进入编辑模式，”ESC”退出编辑模式，”:” + “wq”退出并保存 组合命令 原始命令 组合命令 git add git commit git commit -a -m 也可以简写为 git commit -am","categories":[{"name":"Git","slug":"Git","permalink":"https://moon-zhou.github.io/categories/Git/"}],"tags":[]},{"title":"序列化","slug":"序列化","date":"2019-06-16T09:46:34.000Z","updated":"2019-09-08T07:52:46.327Z","comments":true,"path":"2019/06/16/序列化/","link":"","permalink":"https://moon-zhou.github.io/2019/06/16/序列化/","excerpt":"问题引入 个人会员wap系统，新增实名申诉降级流程，开发过程中，涉及选择已实名账号，上传证件等多步骤操作，后端一开始就要缓存实名用户的信息，缓存的地方为session。因为我们需要进行会话保持，从而我们使用了公司的snf-web-session组件，其底层实现是将缓存在session里的数据缓存在redis中，而不是web容器里。但是在我们实际的场景里，缓存塞值的时候是没有问题，但是在取值的时候，始终是null。","text":"问题引入 个人会员wap系统，新增实名申诉降级流程，开发过程中，涉及选择已实名账号，上传证件等多步骤操作，后端一开始就要缓存实名用户的信息，缓存的地方为session。因为我们需要进行会话保持，从而我们使用了公司的snf-web-session组件，其底层实现是将缓存在session里的数据缓存在redis中，而不是web容器里。但是在我们实际的场景里，缓存塞值的时候是没有问题，但是在取值的时候，始终是null。 猜测原因 HttpRequest只能在controller层使用，不能在更下层使用。[修改后发现问题没有解决] 是否是塞值的时候有异常，断点调试时无法复现，加入try-catch后未发现异常。 发现缓存的抽象类没有实现序列化接口，猜测需要进行序列化。修改后功能正常。 什么是序列化 官方解释：将对象的状态信息转换为可以存储或传输的形式的过程 简言之：了保存在内存中的各种实例对象的状态（也就是实例变量，不是方法），并且可以把保存的对象状态再读出来（也可以理解为不同jvm之间共享实例对象的一种解决方案） 为什么序列化 当你想把的内存中的对象状态保存到一个文件中或者数据库中时候 当你想用套接字在网络上传送对象的时候 当你想通过RMI/rpc调用传输对象的时候 如何进行序列化 Java里的序列化 Serializable是Java提供的一个序列化接口，它是一个空接口，专门为对象提供标准的序列化跟反序列化操作 继承关系的序列化 父类实现Serializable时，子类被序列化，父类也会被序列化。 父类没有实现Serializable时，子类被序列化，父类不会被序列化 引用关系的序列化 如果对一个实现了Serializable的类进行序列化操作，则同时对它的引用类进行序列化操作。如果引用类没有实现Serializable接口，JVM会抛出java.io.NotSerializableExeception:此时对Person类进行序列化操作，则会同时对Tool类进行序列化操作。若Tool类没有实现Serializable接口，则会抛出异常。 12345678class Person implements Serializable&#123; private String name; private Tool tool = new Tool();&#125;class Tool implements Serializable&#123; &#125; 特殊字段（敏感数据等）不需要进行序列化：使用transient进行修饰 序列化标识ID：serialVersionUID 当你序列化的时候这个UID会被写入文件,当反序列话的时候会去读取这个ID,并与反序列化的类中的UID对比,如果相同,那么反序列化就成功,如果不同,反序列化就会失败。如果设置了UID，即使字段发生==结构变化==，也会反序列化成功。所以手动指定UID,主要就是在类结构发生变化时,减少反序列化失败的几率(如果类发生了==非常规的结构变化==,比如类名变化,成员变量的类型变化,就算是指定了UID,反序列化也会失败) 当你不指定UID的时候,系统会根据类的结构生成相应的hash值赋值给UID,但是当你的类的结构发生变化,比如增加一个字段或者减少一个字段的时候,UID就会发生变化,那么反序列话的时候两个类的UID就不一样了,就会反序列化失败 序列化与反序列化 写入文件和读取文件：ObjectOutputStream-writeObject，ObjectInputStream-readObject 自定义序列化策略 定制序列化策略：Java提供了一套有效的机制，允许在序列化和反序列化时，使用定制的方法进行相应的处理。当传输双方协定好序列化策略后，只需要在需要传输的序列化类中添加一组方法来实现这组策略，在序列化时会自动调用这些规定好的方法进行序列化和反序列化。（策略的实现及底层含义：分别是将特定的对象写入到输出流中以及从输入流中恢复特定的对象，通过这==两个方法==，用户即可实现自定义的序列化。当在实现Serializable接口的类中写了上面两个方法之后，序列化或反序列化该类时则会通过反射来调用这两个方法，从而实现自定义序列化。）示例如下： 123456789private void writeObject(ObjectOutputStream out) throws IOException &#123; out.defaultWriteObject(); out.writeInt(age);// customize &#125; private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException &#123; in.defaultReadObject(); age = in.readInt(); // customize &#125; Externalizable 该关键字序列化过程会调用类的无参构造函数-public，去创建一个新的对象，然后再将被保存对象的字段的值分别填充到新对象中 序列化的细节需要由开发者去完成，实现writeExternal()与readExternal()方法 限制序列化对象的数量：通过反序列化获取实例，则单例模式会失效。解决方案：可以让我们在序列化和反序列化时，可以根据自己的需要，写入或读取指定的实例。使用这种机制，需要在实现Serializable接口的类中添加两个方法： private Object readResolve() //如果用户在序列化类中添加了该方法，则在进行反序列化时，使用该方法返回的对象，作为反序列化对象。 private Object writeReplace() //如果用户在序列化类中添加了该方法，则在进行序列化时，序列化该类返回的对象。 12345678910111213141516171819202122232425public class Singleton implements Serializable &#123; private volatile static Singleton mInstance; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (mInstance == null) &#123; synchronized (Singleton.class) &#123; if (mInstance == null) &#123; mInstance = new Singleton(); &#125; &#125; &#125; return mInstance; &#125; private Object readResolve() &#123; return getInstance(); &#125; private Object writeReplace() &#123; return getInstance(); &#125;&#125; 注意点 通过intent传递过去的对象是经过了序列化与反序列化的,虽然传送的对象和接收的对象内容相同,但是是不同的对象,他们的引用是不同的 静态变量及方法是不会经过序列化的,所以跨进程通信的时候静态变量是传送不过去的 静态变量。因为静态变量属于类的属性，并不属于某个具体实例，因此在序列化的时候无须进行序列化，反序列化时，可以直接获取类的静态成员引用。 方法。方法只是一系列的操作集合，方法不会依赖对象，不会因为对象的不同，而操作不同，反序列化时，也可以从类中直接获取方法信息。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://moon-zhou.github.io/categories/JAVA/"}],"tags":[]},{"title":"傻瓜式学Vue-02一步一步小demo","slug":"傻瓜式学Vue-02一步一步小demo","date":"2019-06-02T14:25:34.000Z","updated":"2019-09-08T07:52:48.422Z","comments":true,"path":"2019/06/02/傻瓜式学Vue-02一步一步小demo/","link":"","permalink":"https://moon-zhou.github.io/2019/06/02/傻瓜式学Vue-02一步一步小demo/","excerpt":"学前准备 了解基本的html/js/css语法 了解前端组件的基本概念","text":"学前准备 了解基本的html/js/css语法 了解前端组件的基本概念 热身demo 动手试一下：参考上一步初始化的项目，在App.vue里尝试编写自己的内容，编写完成，在当前目录cnpm run dev测试即可。 12345678910111213141516171819202122232425&lt;!-- 第一部分 --&gt;&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;img src=&quot;./assets/logo.png&quot;&gt; &lt;h1&gt;&#123;&#123;msg&#125;&#125;&lt;/h1&gt; &lt;/div&gt;&lt;/template&gt;&lt;!-- 第二部分 --&gt;&lt;script&gt;export default &#123; data () &#123; return &#123; msg: &apos;First Vue Code Test.&apos; &#125; &#125;&#125;&lt;/script&gt;&lt;!-- 第三部分 --&gt;&lt;style&gt;body &#123; font-family: Arial, Helvetica, sans-serif;&#125;&lt;/style&gt; 此处注意点：无解释说明，记住即可 一个vue一个template标签 一个template下只有一个div标签，不能并行多个div标签 注意data方法的返回写法 玩玩组件 在/src/component下仿照APP.vue的格式创建一个vue 12345678910111213141516171819&lt;template&gt; &lt;div id=&quot;handsomeBoy&quot;&gt; &lt;h1&gt;handsome head&lt;/h1&gt; &lt;a&gt;a handsome boy &#123;&#123;author&#125;&#125;&lt;/a&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; data () &#123; return &#123; author: &apos;houxiaoxiao&apos; &#125; &#125;&#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt; 然后在App.vue 使用组件 ( 因为在 index.html里面定义了div，id=”app”所以就以这个组件作为主入口，方便 ) 引入。 在标签内的第一行写：import handsomeboy from ‘./components/HandSomeBoy.vue’ 注册。 在标签内的 data代码块后面加上components:{handsomeboy}。 使用。 在内加上 完整代码如下： HandSomeBoy.vue 12345678910111213141516171819&lt;template&gt; &lt;div id=&quot;handsomeBoy&quot;&gt; &lt;h1&gt;handsome boy component&lt;/h1&gt; &lt;a&gt;a handsome boy &#123;&#123;author&#125;&#125;&lt;/a&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; data () &#123; return &#123; author: &apos;houxiaoxiao&apos; &#125; &#125;&#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt; APP.vue 1234567891011121314151617181920212223242526272829303132333435&lt;!-- 第一部分 --&gt;&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;img src=&quot;./assets/logo.png&quot;&gt; &lt;h1&gt;&#123;&#123;msg&#125;&#125;&lt;/h1&gt; &lt;!-- 组件第三步 --&gt; &lt;hr&gt; &lt;h2&gt;handsome boy 组件&lt;/h2&gt; &lt;handsomeboy&gt;&lt;/handsomeboy&gt; &lt;/div&gt;&lt;/template&gt;&lt;!-- 第二部分 --&gt;&lt;script&gt;// 组件第一步import handsomeboy from &apos;./components/HandSomeBoy.vue&apos;export default &#123; data () &#123; return &#123; msg: &apos;First Vue Code Test.&apos; &#125; &#125;, // 组件第二步 components:&#123;handsomeboy&#125;&#125;&lt;/script&gt;&lt;!-- 第三部分 --&gt;&lt;style&gt;body &#123; font-family: Arial, Helvetica, sans-serif;&#125;&lt;/style&gt; 使用路由搭建单页应用 安装vue-router cnpm install vue-router –save 按之前的步骤，再写一个BeautifulGirl组件，代码如下： BeautifulGirl.vue 12345678910111213141516171819&lt;template&gt; &lt;div id=&quot;beautifulGirl&quot;&gt; &lt;h1&gt;beautiful girl component&lt;/h1&gt; &lt;a&gt;a beautiful girl &#123;&#123;author&#125;&#125;&lt;/a&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; data () &#123; return &#123; author: &apos;XXX&apos; &#125; &#125;&#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt; HelloWorld.vue 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113&lt;template&gt; &lt;div class=&quot;hello&quot;&gt; &lt;h1&gt;&#123;&#123; msg &#125;&#125;&lt;/h1&gt; &lt;h2&gt;Essential Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;a href=&quot;https://vuejs.org&quot; target=&quot;_blank&quot; &gt; Core Docs &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https://forum.vuejs.org&quot; target=&quot;_blank&quot; &gt; Forum &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https://chat.vuejs.org&quot; target=&quot;_blank&quot; &gt; Community Chat &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https://twitter.com/vuejs&quot; target=&quot;_blank&quot; &gt; Twitter &lt;/a&gt; &lt;/li&gt; &lt;br&gt; &lt;li&gt; &lt;a href=&quot;http://vuejs-templates.github.io/webpack/&quot; target=&quot;_blank&quot; &gt; Docs for This Template &lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Ecosystem&lt;/h2&gt; &lt;ul&gt; &lt;li&gt; &lt;a href=&quot;http://router.vuejs.org/&quot; target=&quot;_blank&quot; &gt; vue-router &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;http://vuex.vuejs.org/&quot; target=&quot;_blank&quot; &gt; vuex &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;http://vue-loader.vuejs.org/&quot; target=&quot;_blank&quot; &gt; vue-loader &lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https://github.com/vuejs/awesome-vue&quot; target=&quot;_blank&quot; &gt; awesome-vue &lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: &apos;HelloWorld&apos;, data () &#123; return &#123; msg: &apos;Welcome to Your Vue.js App&apos; &#125; &#125;&#125;&lt;/script&gt;&lt;!-- Add &quot;scoped&quot; attribute to limit CSS to this component only --&gt;&lt;style scoped&gt;h1, h2 &#123; font-weight: normal;&#125;ul &#123; list-style-type: none; padding: 0;&#125;li &#123; display: inline-block; margin: 0 10px;&#125;a &#123; color: #42b983;&#125;&lt;/style&gt; index.js 1234567891011121314151617181920import Vue from &apos;vue&apos;import Router from &apos;vue-router&apos;import HelloWorld from &apos;@/components/HelloWorld&apos;import BeautifulGirl from &apos;@/components/BeautifulGirl&apos;Vue.use(Router)export default new Router(&#123; routes: [ &#123; path: &apos;/helloworld&apos;, name: &apos;HelloWorld&apos;, component: HelloWorld &#125;, &#123; path: &apos;/beautifulgirl&apos;, name: &apos;BeautifulGirl&apos;, component: BeautifulGirl &#125; ]&#125;) App.vue 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;!-- 第一部分 --&gt;&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;img src=&quot;./assets/logo.png&quot;&gt; &lt;h1&gt;1. &#123;&#123;msg&#125;&#125;&lt;/h1&gt; &lt;!-- 组件第三步 --&gt; &lt;hr&gt; &lt;h2&gt;2. handsome boy 组件&lt;/h2&gt; &lt;handsomeboy&gt;&lt;/handsomeboy&gt; &lt;!-- 路由 --&gt; &lt;hr&gt; &lt;h2&gt;3. 路由&lt;/h2&gt; &lt;div class=&quot;nav-box&quot;&gt; &lt;p class=&quot;nav-list&quot;&gt; &lt;router-link class=&quot;nav-item&quot; to=&quot;/helloworld&quot;&gt;helloworld&lt;/router-link&gt; &lt;router-link class=&quot;nav-item&quot; to=&quot;/beautifulgirl&quot;&gt;beautifulgirl&lt;/router-link&gt; &lt;/p&gt; &lt;/div&gt; &lt;div&gt; &lt;router-view&gt;&lt;/router-view&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;!-- 第二部分 --&gt;&lt;script&gt;// 组件第一步import handsomeboy from &apos;./components/HandSomeBoy.vue&apos;export default &#123; data () &#123; return &#123; msg: &apos;First Vue Code Test.&apos; &#125; &#125;, // 组件第二步 components: &#123; handsomeboy &#125;&#125;&lt;/script&gt;&lt;!-- 第三部分 --&gt;&lt;style&gt;body &#123; font-family: Arial, Helvetica, sans-serif;&#125;&lt;/style&gt; 示例地址https://github.com/moon-zhou/VueDemo 严重参考 https://www.runoob.com/w3cnote/vue2-start-coding.html 待学习https://www.cnblogs.com/chase-star/p/10455703.html","categories":[{"name":"Vue","slug":"Vue","permalink":"https://moon-zhou.github.io/categories/Vue/"}],"tags":[]},{"title":"傻瓜式学Vue-01搭建环境、初始化项目","slug":"傻瓜式学Vue-01搭建环境、初始化项目","date":"2019-06-02T14:23:34.000Z","updated":"2019-09-08T07:52:50.742Z","comments":true,"path":"2019/06/02/傻瓜式学Vue-01搭建环境、初始化项目/","link":"","permalink":"https://moon-zhou.github.io/2019/06/02/傻瓜式学Vue-01搭建环境、初始化项目/","excerpt":"学前准备 了解node 了解win下环境变量的概念，命令行的基本操作","text":"学前准备 了解node 了解win下环境变量的概念，命令行的基本操作 环境搭建 安装node，下载地址https://nodejs.org/en/ 傻瓜式安装，注意安装目录，尽量不要在c盘。注意版本最好选10，需要升级的下载覆盖原有安装即可。 确认安装完成 node -v 配置npm的全局模块的存放路径以及cache的路径，防止安装在c盘，使用npm config ls查看配置是否生效。 配置文件D:\\DevProgram\\nodejs\\node_modules\\npm\\npmrc，添加配置如下：prefix=D:\\DevProgram\\nodejs\\node_globalcache=D:\\DevProgram\\nodejs\\node_cache或者使用命令npm config set cache “D:\\vueProject\\nodejs\\node_cache”npm config set prefix “D:\\vueProject\\nodejs\\node_global” 安装淘宝npm镜像 由于npm是国外的，使用起来比较慢，我们这里使用淘宝的cnpm镜像来安装vue.淘宝的cnpm命令管理工具可以代替默认的npm管理工具。 安装命令：npm install -g cnpm –registry=https://registry.npm.taobao.org 配置环境变量，将上面prefix的目录配置到path，完成即可使用cnpm替代npm命令 安装webpack cnpm install webpack -g 安装vue cnpm install vue -g 安装全局vue-cli脚手架 cnpm install –global vue-cli或者cnpm install vue -g验证：输入vue，出来vue的信息，及说明安装成功 新项目的创建 vue init webpack my-project-first 进入my-project-first文件夹 cnpm install cnpm run dev 访问http://localhost:8080/#/ 打包：cnpm run build 安装IDE VSCode &amp; WebStorm 导入创建的文件夹 目录结构介绍：或有些微不同 1234567891011121314151617181920212223242526272829303132333435363738394041├── README.md 项目介绍├── index.html 入口页面├── build 构建脚本目录│ ├── build-server.js 运行本地构建服务器，可以访问构建后的页面│ ├── build.js 生产环境构建脚本│ ├── dev-client.js 开发服务器热重载脚本，主要用来实现开发阶段的页面自动刷新│ ├── dev-server.js 运行本地开发服务器│ ├── utils.js 构建相关工具方法│ ├── webpack.base.conf.js wabpack基础配置│ ├── webpack.dev.conf.js wabpack开发环境配置│ └── webpack.prod.conf.js wabpack生产环境配置├── config 项目配置│ ├── dev.env.js 开发环境变量│ ├── index.js 项目配置文件│ ├── prod.env.js 生产环境变量│ └── test.env.js 测试环境变量├── mock mock数据目录│ └── hello.js├── package.json npm包配置文件，里面定义了项目的npm脚本，依赖包等信息├── src 源码目录 │ ├── main.js 入口js文件│ ├── app.vue 根组件│ ├── components 公共组件目录│ │ └── title.vue│ ├── assets 资源目录，这里的资源会被wabpack构建│ │ └── images│ │ └── logo.png│ ├── routes 前端路由│ │ └── index.js│ ├── store 应用级数据（state）│ │ └── index.js│ └── views 页面目录│ ├── hello.vue│ └── notfound.vue├── static 纯静态资源，不会被wabpack构建。└── test 测试文件目录（unit&amp;e2e） └── unit 单元测试 ├── index.js 入口脚本 ├── karma.conf.js karma配置文件 └── specs 单测case目录 └── Hello.spec.js 严重参考 https://www.jianshu.com/p/0c6678671635 https://www.cnblogs.com/zhaomeizi/p/8483597.html","categories":[{"name":"Vue","slug":"Vue","permalink":"https://moon-zhou.github.io/categories/Vue/"}],"tags":[]},{"title":"web安全交流","slug":"web安全交流","date":"2019-05-18T14:59:34.000Z","updated":"2019-09-08T07:51:56.829Z","comments":true,"path":"2019/05/18/web安全交流/","link":"","permalink":"https://moon-zhou.github.io/2019/05/18/web安全交流/","excerpt":"web安全交流 web常用攻击手段 waf的简介 实际的攻击/漏洞案例 其他","text":"web安全交流 web常用攻击手段 waf的简介 实际的攻击/漏洞案例 其他 web常用攻击手段web端目前被报的常见安全攻击 sql注入 XSS CSRF SSRF 无限制的url sql注入防御方法定义预编译的sql语句XSS(Cross Site Scripting)XSS, 即为（Cross Site Scripting）, 中文名为跨站脚本, 是发生在目标用户的浏览器层面上的，当渲染DOM树的过程成发生了不在预期内执行的JS代码时，就发生了XSS攻击。跨站脚本的重点不在‘跨站’上，而在于‘脚本’上。大多数XSS攻击的主要方式是嵌入一段远程或者第三方域上的JS代码。实际上是在目标网站的作用域下执行了这段js代码。 示例留言板(商品评价等)XSS：用户提交了一条包含XSS代码的留言到数据库。当目标用户查询留言时，那些留言的内容会从服务器解析之后加载出来。浏览器发现有XSS代码，就当做正常的HTML和JS解析执行。 危害通过document.cookie盗取cookie 使用js或css破坏页面正常的结构与样式 流量劫持（通过访问某段具有window.location.href定位到其他页面） 利用可被攻击的域受到其他域信任的特点，以受信任来源的身份请求一些平时不允许的操作，如进行不当的投票活动。防御方法输入过滤、校验 输入验证（客户端）：前端JS过滤，如检测最大长度、是否只有合法字符、格式是否符合要求、数字是否在指定的范围内。缺点就是容易被修改掉。 数据消毒（服务器端filter拦截统一处理，如图一）：过滤敏感字符（可以和SQL注入的一同过滤），如&lt; &gt; javascript等。 输出编码 HttpOnly：攻击者通过XSS漏洞执行JS中的document.cookie方法来窃取用户的cookie信息。Web应用程序在Set-Cookie时将其属性设为HttpOnly即可避免Cookie被客户端JS存取，也可以保护用户的Cookie信息不被盗取 尽量使用WAF图一 @Component(&quot;specialCharacterFilter&quot;) public class SpecialCharacterFilter extends HttpServlet implements Filter { private static final Logger LOGGER = LoggerFactory.getLogger(SpecialCharacterFilter.class); /** * serialVersionUID */ private static final long serialVersionUID = 3092325909076672931L; /** * */ protected FilterConfig config; /** * {@inheritDoc} */ public void destroy() { } /** * {@inheritDoc} */ public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) { try { if (BankSwitchSCMConfig.get(&quot;XSSSWITCH&quot;).equals(&quot;1&quot;)) { HttpServletRequest request = (HttpServletRequest) req; @SuppressWarnings({ &quot;rawtypes&quot;, &quot;unchecked&quot; }) HashMap&lt;String, String[]&gt; m = new HashMap(request.getParameterMap()); HashMap&lt;String, String[]&gt; mm = new HashMap&lt;String, String[]&gt;(); if (m.size() &gt; 0 &amp;&amp; processParameters(m, mm)) { ParameterRequestWrapper wrapRequest = new ParameterRequestWrapper(request, mm); chain.doFilter(wrapRequest, res); } else { chain.doFilter(req, res); } } else { chain.doFilter(req, res); } } catch (Exception e) { LOGGER.info(&quot;过滤器异常:{}&quot;, e); } } /** * {@inheritDoc} */ public void init(FilterConfig arg0) throws ServletException { this.config = arg0; } /** * 功能描述: &lt;br&gt; * 〈功能详细描述〉 * * @param m * @param mm * @return */ public boolean processParameters(HashMap&lt;String, String[]&gt; m, HashMap&lt;String, String[]&gt; mm) { Iterator&lt;Map.Entry&lt;String, String[]&gt;&gt; iterator = m.entrySet().iterator(); while (iterator.hasNext()) { Map.Entry&lt;String, String[]&gt; entry = iterator.next(); String key = entry.getKey(); String[] values = entry.getValue(); int len = values.length; for (int i = 0; i &lt; len; i++) { if (null != values[i]) { values[i] = values[i].trim(); // 分号|小于号|大于号|单引号 values[i] = values[i].replaceAll(&quot;;&quot;, &quot;&amp;#46;&quot;); values[i] = values[i].replaceAll(&quot;&lt;&quot;, &quot;&amp;#60;&quot;); values[i] = values[i].replaceAll(&quot;&gt;&quot;, &quot;&amp;#62;&quot;); values[i] = values[i].replaceAll(&quot;&apos;&quot;, &quot;&amp;#39;&quot;); values[i] = values[i].replaceAll(&quot;\\\\(&quot;, &quot;&amp;#40;&quot;); values[i] = values[i].replaceAll(&quot;\\\\)&quot;, &quot;&amp;#41;&quot;); } } mm.put(key, values); } return true; } }CSRF（跨站伪造请求 Cross—Site Request Forgery）原理 用户C打开浏览器，访问受信任网站A，输入用户名和密码请求登录网站A 在用户信息通过验证后，网站A产生Cookie信息并返回给浏览器，此时用户登录网站A成功，可以正常发送请求到网站A 用户未退出网站A之前，在同一浏览器中，打开一个TAB页访问网站B（这个过程可使用XSS配合，将用户引导到B网站-钓鱼网站） 网站B接收到用户请求后，返回一些攻击性代码，并发出一个请求要求访问第三方站点A 浏览器在接收到这些攻击性代码后，根据网站B的请求，在用户不知情的情况下携带Cookie信息（通过XSS获取用户cookie信息），向网站A发出请求。网站A并不知道该请求其实是由B发起的，所以会根据用户C的Cookie信息以C的权限处理该请求，导致来自网站B的恶意代码被执行检测方法抓包后去除referer重放请求，能正常请求则有可能csrf重放示例本质原因CSRF攻击是源于Web的隐式身份验证机制！Web的身份验证机制虽然可以保证一个请求是来自于某个用户的浏览器，但却无法保证该请求是用户批准发送的。CSRF攻击的一般是由服务端解决。防御方法该攻击能够成功有两个要点： 构造请求的参数都是可控的 网站没有验证请求的来源 因此防御csrf也可以从这两个方面入手 请求中增加token，token的不可控可以使得请求失败（可以提取公共组件） 限制请求来源referer（不妥，可伪造，目前门户只是做了这个校验） Referer 的值是由浏览器提供的，虽然 HTTP 协议上有明确的要求，但是每个浏览器对于 Referer 的具体实现可能有差别，并不能保证浏览器自身没有安全漏洞。使用验证 Referer 值的方法，就是把安全性都依赖于第三方（即浏览器）来保障，从理论上来讲，这样并不安全。 SSRF(服务器端请求伪造 Server-Side Request Forgery)利用漏洞伪造服务器端发起请求，从而突破客户端获取不到数据限制。是一种由攻击者构造形成由服务端发起请求的一个安全漏洞。利用一个可以发起网络请求的服务，当作跳板来攻击其他服务，最常见的例子是通过web接口请求受保护网络内的资源。通常SSRF被用来扫描内网网络、攻击内网或者本地应用程序、读取本地文件等。 原理SSRF 形成的原因大都是由于服务端提供了从其他服务器应用获取数据的功能但没有对目标地址做过滤与限制。当目标地址为服务端内网地址时，就会获取到内网的消息，从而进行服务器请求伪造攻击。比如从指定URL地址获取网页文本内容，加载指定地址的图片，下载、翻译、识图等功能。例如wooyun-2016-0198176。有道翻译对输入链接没有限制，可以直通内网。正常的流程是用户输入一个链接，然后针对这个链接进行翻译，但是如果输入的是该网站内网的一个链接，并且没有针对输入进行过滤的话，就会将内网的信息给展示出来。 常见漏洞常见 分享：通过URL地址分享网页内容 转码服务 在线翻译 图片加载与下载：通过URL地址加载或下载图片 图片、文章收藏功能 未公开的api实现以及其他调用URL的功能 从URL关键字中寻找 WAF介绍 云谛Web应用防火墙（Web Application Firewall, 简称 WAF）主要用于保障业务的正常运转。WAF可以防御注入(args，headers，cookie)、跨站脚本（XSS）、木马上传等OWASP常见攻击，并过滤海量恶意CC攻击。是应用软件的第一道防火墙，保护了网站资产的安全，网络服务的可用性。在接入WAF后，即启用Web应用防火墙。启用之后，您网站所有的流量都会先经过Web应用防火墙，恶意攻击流量在Web应用防火墙上被检测过滤，而正常流量返回给源站IP，从而确保源站IP安全、稳定、可用。参考链接 waf的功能 拦截非法请求。 业务需要，暂时下线某个功能时，代码逻辑无法控制的时候，配置waf黑名单，拒绝请求。 某个请求存在代码bug，功能不可用时，需要下线该功能。 waf的主要配置 限制单ip使用频率，不同环境次数的配置有不同的转换系数，具体环境配置时咨询waf平台。 黑名单配置（功能2/3可使用该配置） 根据攻击特点配置拦截，比如相同的UA 根据攻击参数进行拦截，比如pcToken，这个我们无法配置，需要waf平台帮忙配置。 以上都需要waf平台帮忙进行分析请求的共性，来指导我们进行相关过滤规则的配置。 实际案例攻击案例 未登录情况下，找回支付密码时，发送验证码之前，使用的是数字验证码（固定验证方式），被机器识别，大量调用发送短信验证码端口。wiki记录 pptv拉新安全问题。wiki记录 passport短信登录获取验证码攻击问题。wiki记录 登录合规改造（防重放） 任意url跳转 安全应急中心提的安全问题单 反射型XSS 其他漏洞靶场vulhub 提升网站安全圈 安全开发 门户敏感功能未监控到位，尤其是未登录状态下的功能。 敏感功能可接入风控 正确使用GET,POST和Cookie（csrf）。GET常用在查看，列举，展示等不需要改变资源属性的时候；POST常用在下达订单，改变一个资源的属性或者做其他一些事情。","categories":[{"name":"内部分享","slug":"内部分享","permalink":"https://moon-zhou.github.io/categories/内部分享/"}],"tags":[]},{"title":"代码规范第二期 backup","slug":"代码规范第二期 backup","date":"2019-05-18T14:58:34.000Z","updated":"2019-09-08T07:51:54.230Z","comments":true,"path":"2019/05/18/代码规范第二期 backup/","link":"","permalink":"https://moon-zhou.github.io/2019/05/18/代码规范第二期 backup/","excerpt":"代码规范第二期code style 规范 形而上，但是的确很重要也很实用的原则 定义你自己的代码阅读等级范围 方法视角：先实现基本方法，之后再在方法内抽取进行重构 接口/类视角：有多个待实现的方法，最后一个方法实现之后，再进行重构 大的视角来看，我们需要遵循原则，但是代码很多时候是运行在具体的场景里。因此写合适的代码， 细节上的注意点 注释会骗人（代码才是唯一）","text":"代码规范第二期code style 规范 形而上，但是的确很重要也很实用的原则 定义你自己的代码阅读等级范围 方法视角：先实现基本方法，之后再在方法内抽取进行重构 接口/类视角：有多个待实现的方法，最后一个方法实现之后，再进行重构 大的视角来看，我们需要遵循原则，但是代码很多时候是运行在具体的场景里。因此写合适的代码， 细节上的注意点 注释会骗人（代码才是唯一） 生产问题(刚刚出炉的热乎bug)不发布的情况下，产生的bug系列 上线但运行4个月无反馈的bughttp://wiki.cnXXX.com/pages/viewpage.action?pageId=33621924 跟随系统一起交接过来的bughttp://wiki.cnXXX.com/pages/viewpage.action?pageId=33622386 系统njs升级涉及代码bughttp://wiki.cnXXX.com/pages/viewpage.action?pageId=33621010 自我升级终极解决方案（唯心）：人 ==》 Later Is Never表象行为：“稍后再….”，稍后再抽个方法，稍后再重命名，稍后再重构，稍后再验证这个场景等等。这个时候就要各位小心，往往稍后再XXX是没有稍后的。 你还得练,孩子,还得练(共勉)","categories":[{"name":"内部分享","slug":"内部分享","permalink":"https://moon-zhou.github.io/categories/内部分享/"}],"tags":[]},{"title":"代码规范第二期","slug":"代码规范第二期分享","date":"2019-05-18T14:58:34.000Z","updated":"2019-09-08T07:51:51.789Z","comments":true,"path":"2019/05/18/代码规范第二期分享/","link":"","permalink":"https://moon-zhou.github.io/2019/05/18/代码规范第二期分享/","excerpt":"代码规范第二期code style 编程到底是什么样的一种活动 将需求明确到机器可以执行的细节程度,就是编程要做的事,而这种规范或者说约束,正是代码。 态度:你是专业的程序员,不要做不专业的事。经理维护进度和需求,警察维护治安,清洁工维护卫生状况,你则要维护代码。 你能分辨代码好坏,并不代表你能写出好代码。 代码大部分时候是用来维护的，而不是用来实现功能的。 在代码阅读过程中人们说脏话的频率是衡量代码质量的唯一标准。 clean code","text":"代码规范第二期code style 编程到底是什么样的一种活动 将需求明确到机器可以执行的细节程度,就是编程要做的事,而这种规范或者说约束,正是代码。 态度:你是专业的程序员,不要做不专业的事。经理维护进度和需求,警察维护治安,清洁工维护卫生状况,你则要维护代码。 你能分辨代码好坏,并不代表你能写出好代码。 代码大部分时候是用来维护的，而不是用来实现功能的。 在代码阅读过程中人们说脏话的频率是衡量代码质量的唯一标准。 clean code 小原则 定义你自己的代码阅读等级范围 明确下经常读你代码的人他们的水平在什么程度，这样我们就可以明确我们的Clean 究竟要Clean到什么程度。 多读同事的代码或者开源代码（以人为镜）。 编码规则及案例 面向接口编程，使用接口声明 不推荐方式： ArrayList list = new ArrayList(); 推荐方式： List list = new ArrayList(); DB、IO操作等需要使用结束close()的对象必须在try-catch-finally 的finally中close()，如果有多个对象需要close()，需要分别对每个对象的close()方法进行try-catch，防止一个对象关闭失败其他对象都未关闭` try {//业务处理 } catch (Exception e) {//异常处理 } finally {//资源关闭处理 }` 注释会骗人（当注释和代码实际的实现出现偏差时，代码才是唯一） 大量字符串的相加等处理应该使用StringBuilder 或StringBuffer，并且预设容量值。 大量：一般指5次“+=”以上或者在循环中进行字符串+=操作。 容量值：构造器会创建一个默认大小(通常是16)的字符数组。在使用中，如果超出这个大小，就会重新分配内存，每次自然递增(OldNum * 2) +2 个，创建一个更大的数组，并将原先的数组复制过来，再丢弃旧的数组。 注意：多线程并发使用StringBuffer，局部变量单线程使用StringBuilder。 在使用正则表达式时，利用好其预编译功能，可以有效加快正则匹配速度。说明：不要在方法体内定义：Pattern pattern = Pattern.compile(规则);` public static String filterHTMLTagInStyle(String htmlStr) {String reg_html=&quot;regex&quot;; Pattern pattern= Pattern.compile(reg_html,Pattern.CASE_INSENSITIVE); Matcher matcher=pattern.matcher(htmlStr); htmlStr=matcher.replaceAll(&quot;&quot;); //过滤html标签 return htmlStr; }` 接口类中的方法和属性不要加任何修饰符号（public 也不要加，默认），保持代码的简洁性，并加上有效的Javadoc注释。尽量不要在接口里定义变量，如果一定要定义变量，肯定是与接口方法相关，并且是整个应用的基础常量。 用户敏感数据禁止直接展示，必须对展示数据脱敏（隐位规则统一处理）。同时门户系统，对隐私信息的传输，也需要进行加密（现阶段是非对称加密）。传输的方式使用post方式，禁止get方式（安全扫描会报安全漏洞）。 用户请求传入的任何参数必须做有效性验证。 使用entrySet遍历Map类集合KV，而不是keySet方式进行遍历说明：keySet其实是遍历了2次，一次是转为Iterator对象，另一次是从hashMap中取出key所对应的value。而entrySet只是遍历了一次就把key和value都放到了entry中，效率更高。如果是JDK8，使用Map.foreach方法。 命名 如果使用到了设计模式，建议在类名中体现出具体模式,有利于阅读者快速理解架构设计思想。 正例：public class OrderFactory; 枚举类名建议带上Enum后缀，枚举成员名称需要全大写，单词间用下划线隔开。 说明：枚举其实就是特殊的常量类，且构造方法被默认强制是私有。 生产问题(刚刚出炉的热乎bug)不发布的情况下，产生的bug系列 上线但运行4个月无反馈的bughttp://wiki.cnXXX.com/pages/viewpage.action?pageId=33621924 跟随系统一起交接过来的bughttp://wiki.cnXXX.com/pages/viewpage.action?pageId=33622386 系统njs升级涉及代码bughttp://wiki.cnXXX.com/pages/viewpage.action?pageId=33621010 解决方案 code review从目前小组全员review来看，效果不是很好。可以考虑迁移git之后，从代码提交时就进行code review。 终极解决方案：人（唯心） ==》 Later Is Never表象行为：“稍后再….”，稍后再抽个方法，稍后再重命名，稍后再重构，稍后再验证这个场景等等。这个时候就要各位小心，往往稍后再XXX是没有稍后的。 你还得练,孩子,还得练(共勉)","categories":[{"name":"内部分享","slug":"内部分享","permalink":"https://moon-zhou.github.io/categories/内部分享/"}],"tags":[]},{"title":"使用hexo搭建个人博客--结合github","slug":"使用hexo搭建个人博客--结合github","date":"2019-05-18T13:49:34.000Z","updated":"2019-09-08T14:20:59.710Z","comments":true,"path":"2019/05/18/使用hexo搭建个人博客--结合github/","link":"","permalink":"https://moon-zhou.github.io/2019/05/18/使用hexo搭建个人博客--结合github/","excerpt":"环境搭建 安装node，参考傻瓜式学vue里的步骤即可。【注意使用淘宝镜像，npm安装速度可能存在比较慢的情况】","text":"环境搭建 安装node，参考傻瓜式学vue里的步骤即可。【注意使用淘宝镜像，npm安装速度可能存在比较慢的情况】 怎么与github一起操作：参考本人整理文档github新增代码库实操.md 安装hexo cnpm install -g hexo cnpm install -g hexo-cli 开始blog 初始化blog：hexo init 将md文档放到source_posts目录下 配置文档_config.yml，对它做如下修改，repository后面的内容是 git@gitbub.com:username/库地址 的形式， 生成静态文档（public目录为最终blog内容）：hexo g(根目录下时用该命令) 开启本地服务：hexo s，打开浏览器访问 http://localhost:4000 即可看到内容。 hexo d，把public下生成的最终文件发布到github上 【TODO】修改主题： 【TODO】图床问题：https://www.jianshu.com/p/950f8f13a36c 错误解决 DeprecationWarning: fs.SyncWriteStream is deprecated 原因：hexo版本过低 解决：npm install hexo-fs –save 严重参考 https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html https://www.cnblogs.com/zhongxia/p/9980353.html","categories":[{"name":"HEXO","slug":"HEXO","permalink":"https://moon-zhou.github.io/categories/HEXO/"}],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2017-06-27T14:44:34.000Z","updated":"2019-09-08T07:52:11.021Z","comments":true,"path":"2017/06/27/hello-world/","link":"","permalink":"https://moon-zhou.github.io/2017/06/27/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"Test","slug":"Test","permalink":"https://moon-zhou.github.io/categories/Test/"}],"tags":[]}]}